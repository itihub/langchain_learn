{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5c77f7c-318f-4ab3-9515-43535421b296",
   "metadata": {},
   "source": [
    "##### 环境测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eb5c67-8be6-418f-ab9c-8d1774b410d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hello world')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8023a2b-dd30-45bd-855a-75bc548ec9db",
   "metadata": {},
   "source": [
    "##### 依赖安装\n",
    "- 安装LangChain\n",
    "- 安装LangChain Community\n",
    "- 安装LangChain OpenAI\n",
    "- 安装OpenAI\n",
    "- 安装Google Generativeai\n",
    "（虚拟环境已安装langchain、langchain_community、langchain-openai、openai、google-generativeai依赖）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aef57d-348d-489b-86eb-50e0b5abefbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip uninstall langchain -y\n",
    "# %pip uninstall openai -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2f31e4-284f-4cd8-b71d-11689b65e6fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %pip install openai==0.27.8 -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4ee84e-145b-43a4-aff8-ed7ce27194d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 设置环境变量\n",
    "- 使用 os 模块设置进程环境变量\n",
    "- 设置OpenAI访问密钥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ada442-af14-45bb-81ea-070fc8a10d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "# 手动设置环境变量\n",
    "# os.environ[\"OPENAI_API_BASE_URL\"] = \"https://ai-yyds.com/v1\"\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-XXXXXXXXXXXXXXXXXXXX0bDb\"\n",
    "# os.environ[\"MODEL_NAME\"] = \"test\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d353a8-5b9e-4630-a856-4c6843a79684",
   "metadata": {},
   "source": [
    "##### 环境变量读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49804b11-f33e-480d-8d17-c8c9907b7174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Read the OPENAI_API_KEY from the environment\n",
    "api_base = os.getenv(\"OPENAI_API_BASE_URL\")\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model_name = os.getenv(\"MODEL_NAME\")\n",
    "\n",
    "\n",
    "print(\"OPENAI_BASE_URL:{}\".format(api_base))\n",
    "print(\"OPENAI_KEY:{}\".format(api_key))\n",
    "print(\"MODEL_NAME:{}\".format(model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cb9944-bbdb-496a-b3de-028f46f67f87",
   "metadata": {},
   "source": [
    "##### 检查依赖安装情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21228de4-e074-43fa-818d-24952d3996c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip show langchain\n",
    "%pip show langchain_community\n",
    "%pip show langchain-openai\n",
    "%pip show openai\n",
    "%pip show google-generativeai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb254121-b3de-49e2-a512-587ea528bb89",
   "metadata": {},
   "source": [
    "##### 使用OpenAI SDK调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62a7bb5-f618-4772-9064-226b21171572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "    # base_url=os.getenv(\"OPENAI_API_BASE_URL\"),\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "message = [\n",
    "    {\"role\": \"user\", \"content\": \"介绍下你自己\"}\n",
    "]\n",
    "\n",
    "res = client.chat.completions.create(\n",
    "    # model=os.getenv(\"MODEL_NAME\"),\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=message,\n",
    "    stream=False,\n",
    ")\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd03f87",
   "metadata": {},
   "source": [
    "##### 使用Google Gemini SDK调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c2447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "response = model.generate_content(\"介绍下你自己\")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f6ff27-9364-4a6e-9e98-b5c9d32c7ba8",
   "metadata": {},
   "source": [
    "##### 使用LangChain调用各种大型语言模型\n",
    "`langchain_openai`是LangChain框架的一个集成包，专门用于与OpenAI的各种模型进行交互。它提供了一系列工具和接口，使得开发者可以方便地在LangChain应用中使用OpenAI的语言模型、聊天模型和嵌入模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9cf4b3-e949-4f41-aa80-06d9b6497f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "api_base_url = os.getenv(\"OPENAI_API_BASE_URL\")\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# 初始化 OpenAI 模型\n",
    "llm = ChatOpenAI(\n",
    "    # base_url=api_base_url,\n",
    "    api_key=api_key,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# 使用 invoke 方法调用模型\n",
    "response = llm.invoke(\"介绍下你自己\")\n",
    "\n",
    "# 打印模型生成的文本\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906c9c53-afea-45e9-8340-ec76c941c1fe",
   "metadata": {},
   "source": [
    "##### 使用LangChain提词器模板\n",
    "- 使用```PromptTemplate.from_template```创建自定义提词器模板\n",
    "- 将提问上下文模块化，支持参数传入，提高提示词的可重用性和可维护性\n",
    "- 让LLM给孩子起具有传入参数特色的特殊的名字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8241415-5f08-4778-8ddd-00cf696e5964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 起名大师\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import os\n",
    "\n",
    "api_base = os.getenv(\"OPENAI_API_BASE_URL\")\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model_name = os.getenv(\"MODEL_NAME\")\n",
    "\n",
    "# 创建 PromptTemplate\n",
    "prompt = PromptTemplate.from_template(\"你是一个起名大师,请模仿示例起3个{county}名字,比如男孩经常被叫做{boy},女孩经常被叫做{girl}\")\n",
    "# 生成提示\n",
    "message = prompt.format(county=\"中国特色的\",boy=\"狗蛋\",girl=\"翠花\")\n",
    "\n",
    "print(message)\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    # openai_api_base=api_base,\n",
    "    openai_api_key=api_key,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    # model=model_name,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "llm.predict(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6947f7-211a-4267-b0dd-4b085f40bb21",
   "metadata": {},
   "source": [
    "### 使用LangChain输出解释器\n",
    "在 LangChain 中，输出解析器（Output Parsers）的作用是将语言模型（LLM）的原始输出转换为结构化的数据，以便在下游任务中使用。\n",
    "\n",
    "LangChain 提供了多种内置的输出解析器，以适应不同的输出格式。以下是一些常用的解析器：\n",
    "- PydanticOutputParser\n",
    "  - 将 LLM 输出解析为 Pydantic 模型，适用于结构化的 JSON 输出。\n",
    "- CommaSeparatedListOutputParser\n",
    "  - 将 LLM 输出解析为逗号分隔的列表。\n",
    "- StructuredOutputParser\n",
    "  - 将LLM的输出解析为结构化的JSON格式。\n",
    "- XMLOutputParser\n",
    "  - 将LLM的输出解析为XML格式。\n",
    "\n",
    "在使用某些解析器（如 PydanticOutputParser）之前，你需要定义输出数据的结构。可以使用 Pydantic 模型来定义结构。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39369da",
   "metadata": {},
   "source": [
    "#### 将 LLM 输出解析为逗号分隔的列表（CommaSeparatedListOutputParser）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0c4176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用langchain内置的输出解析器\n",
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "CommaSeparatedListOutputParser().parse(\"hi, bye\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4be2d37-3093-4c1f-841b-101a6c6d97ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这是我们自己实现了将文本解析为逗号分割的列表\n",
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "\n",
    "# 自定义class，继承输出解析器（Output Parsers）的基类\n",
    "# 它的主要作用是定义了输出解析器的通用接口，使得 LangChain 可以统一处理不同类型的输出解析器。\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "# 使用自定义类，格式化输出文本\n",
    "CommaSeparatedListOutputParser().parse(\"hi, bye\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3618785f-f3fa-4511-86b5-bd2abbe0f572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 起名大师，以数组格式输出\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "import os\n",
    "\n",
    "# 自定义class，继承了BaseOutputParser\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "api_base = os.getenv(\"OPENAI_API_BASE_URL\")\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model_name = os.getenv(\"MODEL_NAME\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_base=api_base,\n",
    "    openai_api_key=api_key,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,    \n",
    ")\n",
    "\n",
    "# 创建提示模板\n",
    "prompt = PromptTemplate.from_template(\"你是一个起名大师,请模仿示例起4个{county}名字,比如男孩经常被叫做{boy},女孩经常被叫做{girl}\")\n",
    "message = prompt.format(county=\"中国特色的\",boy=\"狗蛋\",girl=\"翠花\")\n",
    "\n",
    "strs = llm.invoke(message)\n",
    "\n",
    "# 创建输出解析器并解析LLM的输出结果\n",
    "CommaSeparatedListOutputParser().parse(strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd87e05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# 定义 Pydantic 模型\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"笑话设置\")\n",
    "    punchline: str = Field(description=\"笑话的妙语\")\n",
    "\n",
    "# 创建输出解析器\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "# 打印为语言模型（LLM）提供格式化输出的指令\n",
    "# parser.get_format_instructions() 方法会返回一个字符串，其中包含有关如何格式化 LLM 输出的指令，以便解析器可以正确地解析它。这些指令通常包括：\n",
    "# 输出格式的描述、字段或属性的描述\n",
    "print(parser.get_format_instructions())\n",
    "\n",
    "# 创建提示模板\n",
    "template = \"\"\"给我讲个笑话。\n",
    "\n",
    "{format_instructions}\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[],\n",
    "    # 输出格式说明\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "# 创建 LLM 链\n",
    "chain = prompt | OpenAI(temperature=0) | parser\n",
    "\n",
    "# 调用 LLM 链\n",
    "output = chain.invoke({})\n",
    "\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
