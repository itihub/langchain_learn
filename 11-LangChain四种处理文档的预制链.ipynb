{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "# 手动设置环境变量\n",
    "# os.environ[\"OPENAI_API_BASE_URL\"] = \"https://ai-yyds.com/v1\"\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-XXXXXXXXXXXXXXXXXXXX0bDb\"\n",
    "# os.environ[\"MODEL_NAME\"] = \"test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文档处理预制链（Document Processing Prebuilt Chains）\n",
    "在 LangChain 中，文档处理预制链（Document Processing Prebuilt Chains）主要用于处理和操作文档数据，以便进行后续的语言模型（LLM）处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `load_summarize_chain` (加载摘要链)\n",
    "+ 功能：\n",
    "  + 用于对文档进行摘要提取。\n",
    "  + 它支持多种摘要提取方法，例如 stuff、map_reduce、refine 和 map_rerank。\n",
    "+ 使用方法：\n",
    "  + 首先，你需要加载文档数据，并将其转换为 LangChain 的 Document 对象。\n",
    "  + 然后，你可以使用 load_summarize_chain 函数加载摘要链，并指定所需的摘要提取方法。\n",
    "  + 最后，你可以调用链的 run 方法，传入文档列表，以生成摘要。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### 提取方法：stuff\n",
    "stuff（填充）\n",
    "+ 含义：\n",
    "  + 这是最简单的方法。它将所有文档内容“填充”到一个提示（prompt）中，然后一次性传递给语言模型（LLM）进行摘要。\n",
    "+ 特点：\n",
    "  + 简单快捷，适用于文档内容较短的情况。\n",
    "  + 当文档内容过长时，可能会超出 LLM 的上下文窗口限制，导致信息丢失或摘要效果不佳。\n",
    "+ 适用场景：\n",
    "  + 处理短篇文档或已知文档内容不会超过 LLM 上下文窗口的情况。\n",
    "\n",
    "最常见的文档链，将文档直接塞进prompt中，为LLM回答问题提供上下文资料，适合小文档场景"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt_template = \"\"\"对以下文字做简洁的总结:\n",
    "{text}\n",
    "简洁的总结:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "llm = ChatOpenAI(\n",
    "    base_url=os.getenv(\"OPENAI_API_BASE_URL\"),\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0\n",
    ")\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "stuff_chain = StuffDocumentsChain(\n",
    "    llm_chain=llm_chain,\n",
    "    document_variable_name=\"text\",\n",
    ")\n",
    "\n",
    "loader = PyPDFLoader(\"./sources/loader.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "print(stuff_chain.run(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用预封装好的load_summarize_chain\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "loader = PyPDFLoader(\"./sources/loader.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url=os.getenv(\"OPENAI_API_BASE_URL\"),\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "chain = load_summarize_chain(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "chain.run(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 提取方法：map_reduce\n",
    "map_reduce（映射归约）\n",
    "+ 含义：\n",
    "  + 该方法将文档分割成较小的块，然后对每个块分别进行摘要（映射阶段）。\n",
    "  + 最后，将所有块的摘要合并成最终的摘要（归约阶段）。\n",
    "+ 特点：\n",
    "  + 适用于处理大型文档，可以有效地处理超出 LLM 上下文窗口的内容。\n",
    "  + 摘要质量可能不如 stuff 方法，因为每个块的摘要都是独立的，可能会丢失一些上下文信息。\n",
    "+ 适用场景：\n",
    "  + 处理长篇文档、书籍、报告等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map reduce先将每个文档或文档块分别投喂给LLM，并得到结果集（Map步骤），然后通过一个文档合并链，获得一个输出结果（Reduce步骤）\n",
    "![Alt Text](./images/map.png)\n",
    "![Alt Text](./images/reduce.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import MapReduceDocumentsChain\n",
    "from langchain.chains import ReduceDocumentsChain\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# load pdf\n",
    "loader = PyPDFLoader(\"./sources/loader.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "# split text\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "# print(split_docs)\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url=os.getenv(\"OPENAI_API_BASE_URL\"),\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# map chain\n",
    "map_template = \"\"\"对以下文字做简洁的总结:\n",
    "\"{content}\"\n",
    "简洁的总结:\"\"\"\n",
    "map_prompt = PromptTemplate.from_template(map_template)\n",
    "map_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=map_prompt,\n",
    ")\n",
    "\n",
    "# reduce chain\n",
    "reduce_template = \"\"\"以下是一个摘要集合:\n",
    "{doc_summaries}\n",
    "将上述摘要与所有关键细节进行总结.\n",
    "总结:\"\"\"\n",
    "reduce_prompt = PromptTemplate.from_template(reduce_template)\n",
    "reduce_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=reduce_prompt,\n",
    ")\n",
    "\n",
    "stuff_chain = StuffDocumentsChain(\n",
    "    llm_chain=reduce_chain,\n",
    "    document_variable_name=\"doc_summaries\",\n",
    ")\n",
    "\n",
    "reduce_final_chain = ReduceDocumentsChain(\n",
    "    combine_documents_chain=stuff_chain,\n",
    "    # 超过4000个token就会切入到下一个stuff_chain\n",
    "    collapse_documents_chain=stuff_chain,\n",
    "    token_max=4000,\n",
    ")\n",
    "\n",
    "# map reduce chain\n",
    "map_reduce_chain = MapReduceDocumentsChain(\n",
    "    llm_chain=map_chain,\n",
    "    document_variable_name=\"content\",\n",
    "    reduce_documents_chain=reduce_final_chain,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = map_reduce_chain.run(split_docs)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 提取方法：refine\n",
    "refine（精炼）\n",
    "+ 含义：\n",
    "  + 该方法首先对第一个文档块生成摘要，然后将后续文档块与之前的摘要一起传递给 LLM，逐步“精炼”摘要。\n",
    "  + 这种方法保留了更多的上下文信息。\n",
    "+ 特点：\n",
    "  + 相比 map_reduce 方法，可以生成更高质量的摘要。\n",
    "  + 处理速度较慢，因为需要多次调用 LLM。\n",
    "+ 适用场景：\n",
    "  + 需要高质量摘要，且可以容忍较长处理时间的情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "# 加载PDF文档\n",
    "loader = PyPDFLoader(\"./sources/loader.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "# 文档分割split\n",
    "text_split = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "split_docs = text_split.split_documents(docs)\n",
    "\n",
    "prompt_template = \"\"\"对以下文字做简洁的总结:\n",
    "{text}\n",
    "简洁的总结:\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "refine_template = (\n",
    "    \"你的任务是产生最终摘要\\n\"\n",
    "    \"我们已经提供了一个到某个特定点的现有回答:{existing_answer}\\n\"\n",
    "    \"我们有机会通过下面的一些更多上下文来完善现有的回答(仅在需要时使用).\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"{text}\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"根据新的上下文，用中文完善原始回答.\\n\"\n",
    "    \"如果上下文没有用处,返回原始回答.\"\n",
    ")\n",
    "refine_prompt = PromptTemplate.from_template(refine_template)\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url=os.getenv(\"OPENAI_API_BASE_URL\"),\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "chain = load_summarize_chain(\n",
    "    llm=llm,\n",
    "    chain_type=\"refine\",\n",
    "    question_prompt=prompt,\n",
    "    refine_prompt=refine_prompt,\n",
    "    return_intermediate_steps=True,\n",
    "    input_key=\"documents\",\n",
    "    output_key=\"output_text\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain({\"documents\":split_docs}, return_only_outputs=True)\n",
    "print(result[\"output_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n\".join(result[\"intermediate_steps\"][:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 提取方法：map_rerank\n",
    "map_rerank（映射重排序）\n",
    "+ 含义：\n",
    "  + 该方法首先对每个文档块生成摘要（映射阶段）。\n",
    "  + 然后，它会尝试评估哪些摘要是最相关的（重新排序阶段）。\n",
    "  + 最后，它会返回得分最高的摘要。\n",
    "+ 特点：\n",
    "  + 此方法需要它返回单个最佳摘要。\n",
    "  + 依赖于LLM评估文档的相关性。\n",
    "+ 适用场景：\n",
    "  + 当你需要从一组文档中找到最相关的摘要时。\n",
    "\n",
    "先将每个文档或文档块投喂给LLM,并对每个文档或文档块生成问题的答案进行打分，然后将打分最高的文档或文档块作为最终答案返回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url=os.getenv(\"OPENAI_API_BASE_URL\"),\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# load\n",
    "loader = PyPDFLoader(\"./sources/loader.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "# split\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=500, chunk_overlap=0\n",
    ")\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "\n",
    "chain = load_qa_with_sources_chain(\n",
    "    llm=llm,\n",
    "    chain_type=\"map_rerank\", \n",
    "    # 元数据增加source字段\n",
    "    metadata_keys=['source'], \n",
    "    # 打印中间执行步骤\n",
    "    return_intermediate_steps=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is this document talk about?answer by chinese\"\n",
    "result = chain({\"input_documents\":split_docs,\"question\":query})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RetrievalQA (检索问答链)\n",
    "+ 功能：\n",
    "  + 用于从文档中检索相关信息，并回答用户的问题。\n",
    "  + 它结合了文档检索和问答生成功能。\n",
    "+ 使用方法：\n",
    "  + 首先，你需要加载文档数据，并创建一个向量存储（Vector Store），用于存储文档的嵌入向量。\n",
    "  + 然后，你需要创建一个检索器（Retriever），用于从向量存储中检索相关文档。\n",
    "  + 最后，你可以使用 RetrievalQA 类创建检索问答链，并调用其 run 方法，传入用户的问题，以生成答案。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MapReduceDocumentsChain (MapReduce文档链)\n",
    "+ 功能：\n",
    "  + 用于处理大型文档，将其分割成小块，并并行处理。\n",
    "  + 它支持 MapReduce 模式，可以提高处理效率。\n",
    "+ 使用方法：\n",
    "  + 首先，你需要加载文档数据，并将其分割成小块。\n",
    "  + 然后，你需要创建 MapReduce 文档链，并指定所需的 LLM 和提示模板。\n",
    "  + 最后，你可以调用链的 run 方法，传入文档块列表，以生成最终结果。\n",
    "+ 使用场景：\n",
    "  + 当文档过大，无法一次性加载到内存中，可以使用该链。\n",
    "  + 需要并行处理文档时，可以使用该链。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
