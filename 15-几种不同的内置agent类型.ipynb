{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "# Read the OPENAI_API_KEY from the environment\n",
    "api_base = os.getenv(\"OPENAI_API_BASE_URL\")\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model_name = os.getenv(\"MODEL_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_row', 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 几种不同的agent类型\n",
    "在 LangChain 中，代理（Agents）是一种能够根据用户输入和可用工具，动态决定采取哪些行动的系统。LangChain 提供了多种类型的代理，每种代理都有不同的特点和适用场景。\n",
    "\n",
    "以下是一些常见的 LangChain 代理类型及其使用方法：\n",
    "\n",
    "- ZERO_SHOT_REACT_DESCRIPTION\n",
    "  - **类型**： AgentType.ZERO_SHOT_REACT_DESCRIPTION\n",
    "  - **描述**： 这是最基础的 ReAct（Reason + Act）Agent 类型。它使用一个零样本（zero-shot）提示模板，引导 LLM 进行推理（Reasoning）和行动（Action）。\n",
    "  - **工作原理**： Agent 会根据用户输入，生成一系列的思考（Thought）、行动（Action）和观察（Observation）的迭代过程，最终得到答案。\n",
    "  - **适用场景**： 适用于需要进行复杂推理和多步骤操作的任务，但可能需要多次迭代。\n",
    "  - **特点**： 不依赖于之前的对话历史，每次交互都是独立的。\n",
    "- CHAT_ZERO_SHOT_REACT_DESCRIPTION\n",
    "  - **类型**： AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION\n",
    "  - **描述**： 类似于 ZERO_SHOT_REACT_DESCRIPTION，但专门为聊天模型（Chat Models）设计。\n",
    "  - **工作原理**： 使用聊天模型的消息格式，以更适合对话的方式进行推理和行动。\n",
    "  - **适用场景**： 同样适用于复杂推理和多步骤操作，但与聊天模型的兼容性更好。\n",
    "  - **特点**： 同样不依赖于之前的对话历史，但使用了聊天模型的输入输出格式。\n",
    "- CONVERSATIONAL_REACT_DESCRIPTION\n",
    "  - **类型**：AgentType.CONVERSATIONAL_REACT_DESCRIPTION\n",
    "  - **描述**：这是一个对话型 ReAct Agent，它能够记住之前的对话历史，并根据上下文进行推理和行动。\n",
    "  - **工作原理**： Agent 会将对话历史记录作为上下文传递给 LLM，从而能够进行更连贯的对话。\n",
    "  - **适用场景**： 适用于聊天机器人、对话系统等需要进行自然语言交互的场景。\n",
    "  - **特点**： 具有对话记忆功能，能够进行更自然的对话。\n",
    "- CHAT_CONVERSATIONAL_REACT_DESCRIPTION\n",
    "  - **类型**：AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION\n",
    "  - **描述**：类似于 CONVERSATIONAL_REACT_DESCRIPTION，但专门为聊天模型设计。\n",
    "  - **工作原理**：使用聊天模型的消息格式，并结合对话历史记录进行推理和行动。\n",
    "  - **适用场景**：适用于聊天机器人、对话系统等，与聊天模型的兼容性更好。\n",
    "  - **特点**：具有对话记忆功能，并使用聊天模型的输入输出格式。\n",
    "- OPENAI_FUNCTIONS\n",
    "  - **类型**：AgentType.OPENAI_FUNCTIONS\n",
    "  - **描述**：专门为 OpenAI 的函数调用功能设计的 Agent。\n",
    "  - **工作原理**：利用 OpenAI 的函数调用 API，允许 LLM 调用外部函数（工具），并将函数返回的结果作为上下文。\n",
    "  - **适用场景**：当你需要模型精确的调用工具函数，并且模型支持OpenAI function calling的时候使用。\n",
    "  - **特点**：使用函数调用，使得Agent调用工具的逻辑更加清晰，易于维护，可靠性更高。\n",
    "- STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION\n",
    "  - **类型**: AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION\n",
    "  - **描述**: 专为聊天模型设计的，并且输出的结果是结构化数据。\n",
    "  - **工作原理**: 提示模型以结构化数据的方式输出，并且不依赖于之前的对话历史。\n",
    "  - **适用场景**: 需要LLM输出结构化数据的时候使用。\n",
    "  - **特点**: 输出结果为结构化数据，方便程序解析。\n",
    "\n",
    "总结\n",
    "- `ZERO_SHOT_REACT_DESCRIPTION` 和 `CHAT_ZERO_SHOT_REACT_DESCRIPTION` 是基础的 ReAct Agent，不依赖对话历史。\n",
    "- `CONVERSATIONAL_REACT_DESCRIPTION` 和 `CHAT_CONVERSATIONAL_REACT_DESCRIPTION` 是对话型 ReAct Agent，具有对话记忆功能。\n",
    "- `OPENAI_FUNCTIONS` 专门为 OpenAI 函数调用设计，能更加精准的调用工具函数。\n",
    "- `STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION` 专为聊天模型设计，并且输出结构化数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZERO_SHOT_REACT_DESCRIPTION\n",
    "零样本增强式生成，即在没有示例的情况下可以自主的进行对话的类型。https://blog.csdn.net/zcyzcyjava/article/details/127006287 [零样本、单样本、少样本]\n",
    "\n",
    "+ **使用场景**：\n",
    "  + 适用于需要进行复杂推理和多步骤操作的任务，例如回答复杂问题、执行多步骤任务等。\n",
    "  + 当不需要依赖之前的对话历史，每次交互都是独立的场景。\n",
    "+ **使用方式**：\n",
    "  + 定义一组工具（Tools），这些工具可以是任何 Python 函数，用于执行特定任务。\n",
    "  + 使用 initialize_agent 函数创建一个 Agent 实例，指定 LLM、工具列表和 AgentType.ZERO_SHOT_REACT_DESCRIPTION。\n",
    "  + 将用户输入传递给 Agent 的 run 方法，Agent 将自动进行推理和行动，并返回结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import (\n",
    "    load_tools,\n",
    "    initialize_agent,\n",
    "    AgentType,\n",
    ")\n",
    "\n",
    "# 这里用到了serpapi工具，需要配置SERPAPI_API_KEY\n",
    "\n",
    "llm = OpenAI(\n",
    "    temperature=0,\n",
    "    model=model_name,\n",
    ")\n",
    "\n",
    "# 定义一组工具\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(agent)\n",
    "# 打印agent的提示词\n",
    "print(agent.agent.llm_chain.prompt.template)\n",
    "\n",
    "# 使用\n",
    "# agent.invoke(\"现在美国总统是谁？他的年龄除以2是多少？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHAT_ZERO_SHOT_REACT_DESCRIPTION\n",
    "+ **使用场景**：\n",
    "  + 与 ZERO_SHOT_REACT_DESCRIPTION 类似，但更适合与聊天模型一起使用。\n",
    "  + 适用于需要利用聊天模型的对话能力，但不需要对话历史的场景。\n",
    "+ **使用方式**：\n",
    "  + 与 ZERO_SHOT_REACT_DESCRIPTION 类似，但使用聊天模型（Chat Models）作为 LLM。\n",
    "  + 使用聊天模型的消息格式进行输入输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import (\n",
    "    load_tools,\n",
    "    initialize_agent,\n",
    "    AgentType,\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")\n",
    "\n",
    "tools = load_tools([\"serpapi\",\"llm-math\"],llm=llm)\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(agent)\n",
    "\n",
    "print(agent.agent.llm_chain.prompt.messages[0].prompt.template)\n",
    "\n",
    "# agent.invoke(\"现在美国总统是谁？他的年龄除以2是多少？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONVERSATIONAL_REACT_DESCRIPTION \n",
    "一个对话型的agent，这个agent要求与memory一起使用\n",
    "+ **使用场景**：\n",
    "  + 适用于聊天机器人、对话系统等需要进行自然语言交互的场景。\n",
    "  + 当需要 Agent 记住之前的对话内容，并根据上下文进行推理和行动时。\n",
    "+ **使用方式**：\n",
    "  + 与 ZERO_SHOT_REACT_DESCRIPTION 类似，但 Agent 会维护对话历史记录。\n",
    "  + 将对话历史记录作为上下文传递给 LLM，以便进行更连贯的对话。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import (\n",
    "    load_tools,\n",
    "    initialize_agent,\n",
    "    AgentType,\n",
    ")\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "#记忆组件\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    ")\n",
    "\n",
    "llm = OpenAI(\n",
    "    temperature=0,\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    ")\n",
    "\n",
    "tools = load_tools([\"serpapi\",\"llm-math\"], llm=llm)\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    memory=memory,#记忆组件\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(agent)\n",
    "\n",
    "print(agent.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\"hi i am tomie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\"what is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\"有什么好吃的泰国菜可以推荐给我吗?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\"这些我都没吃过！我名字的最后一个字母是什么？1998年的世界杯谁夺冠了？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\"中国陕西西安现在的气温多少？截止目前我们聊了什么？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHAT_CONVERSATIONAL_REACT_DESCRIPTION \n",
    "+ **使用场景**：\n",
    "  + 与 CONVERSATIONAL_REACT_DESCRIPTION 类似，但更适合与聊天模型一起使用。\n",
    "  + 适用于需要利用聊天模型的对话能力，并且需要对话历史的场景。\n",
    "+ **使用方式**：\n",
    "  + 与 CONVERSATIONAL_REACT_DESCRIPTION 类似，但使用聊天模型（Chat Models）作为 LLM。\n",
    "  + 使用聊天模型的消息格式进行输入输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import (\n",
    "    load_tools,\n",
    "    initialize_agent,\n",
    "    AgentType,\n",
    ")\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "#记忆组件\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model=\"gpt-4-1106-preview\",\n",
    ")\n",
    "\n",
    "tools = load_tools([\"serpapi\",\"llm-math\"],llm=llm)\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    memory=memory,#记忆组件\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(agent)\n",
    "\n",
    "print(agent.agent.llm_chain.prompt.messages[0].prompt.template)\n",
    "\n",
    "print(agent.agent.llm_chain.prompt.messages[2].prompt.template)\n",
    "\n",
    "print(agent.agent.llm_chain.prompt.messages[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(input=\"hi i am tony\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(input=\"what is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(input=\"有什么好吃的泰国菜给我推荐一下？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(input=\"我都没吃过！我名字的最后一个字母是什么？1998年的世界杯谁夺冠了？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPENAI_FUNCTIONS\n",
    "使用openai的函数调用来实现的，只支持openai模型。\n",
    "+ **使用场景**：\n",
    "  + 当使用的LLM支持OpenAI function calling。\n",
    "  + 适用于需要精准的调用工具函数的时候。\n",
    "+ **使用方式**：\n",
    "  + 定义一组工具（Tools），这些工具需要符合OpenAI function calling 的规范。\n",
    "  + 使用 initialize_agent 函数创建一个 Agent 实例，指定 LLM、工具列表和 AgentType.OPENAI_FUNCTIONS。\n",
    "  + Agent会智能的判断是否需要调用工具函数，以及如何调用工具函数，最后返回结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import (\n",
    "    load_tools,\n",
    "    initialize_agent,\n",
    "    AgentType,\n",
    ")\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "#记忆组件\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model=\"gpt-4-1106-preview\",\n",
    ")\n",
    "\n",
    "tools = load_tools([\"serpapi\",\"llm-math\"],llm=llm)\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.OPENAI_FUNCTIONS,\n",
    "    memory=memory,#记忆组件\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(agent)\n",
    "\n",
    "print(agent.agent.prompt.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(input=\"今天比特币的价格是多少？它的价格开平方是多少？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION\n",
    "+ **使用场景**：\n",
    "  + 当需要LLM返回结构化数据的时候。\n",
    "+ **使用方式**：\n",
    "  + 定义一组工具（Tools）。\n",
    "  + 使用 initialize_agent 函数创建一个 Agent 实例，指定 LLM、工具列表和 AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION。\n",
    "  + Agent会返回结构化的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import (\n",
    "    load_tools,\n",
    "    initialize_agent,\n",
    "    AgentType,\n",
    ")\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "#记忆组件\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model=\"gpt-4-1106-preview\",\n",
    ")\n",
    "\n",
    "tools = load_tools([\"serpapi\",\"llm-math\"],llm=llm)\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    memory=memory,#记忆组件\n",
    "    handle_parsing_errors=True,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(agent)\n",
    "\n",
    "print(agent.agent.llm_chain.prompt.messages[0].prompt.template)\n",
    "\n",
    "print(agent.agent.llm_chain.prompt.messages[1].prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.invoke({\"input\":\"what is langchain?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchains",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
