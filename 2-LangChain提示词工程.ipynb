{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LangChain Prompts模板的输入工程\n",
    "使用prompts模板实现更加高级和灵活的提示词工程\n",
    "\n",
    "优秀的提示词的特点：\n",
    "- 【立角色】：引导AI进入具体场景，赋予其行家身份\n",
    "- 【述问题】：告诉AI你的困惑和问题，以及背景信息\n",
    "- 【定目标】：告诉AI你的需求，希望达成的目标\n",
    "- 【补要求】：告诉AI回答时注意什么，或者如何回复\n",
    "\n",
    "提示词模板：\n",
    "1. 将提示词提炼成模板的形式\n",
    "2. 实现提示词的复用、版本管理、动态变化等\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PromptTemplate 字符串模板\n",
    "LangChain支持ChatModels和LLMModels，可以使用字符串模板来生成对话。\n",
    "提供了PromptTemplate类来处理字符串模板。\n",
    "提供了ChatPromptTemplate类来处理对话模板。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 字符串模板\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 创建字符串模板\n",
    "prompt = PromptTemplate.from_template(\"你是一个{name}，帮我起1个具有{county}特色的{sex}名字。\")\n",
    "prompt.format(name=\"算命大师\", county=\"法国\", sex=\"女孩\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ChatPromptTemplate 对话模板\n",
    "可以指定消息的角色，例如 \"system\"（系统）、\"human\"（人类）或 \"ai\"（AI）\n",
    "这使得你可以更精确地控制聊天对话的上下文和行为"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对话模板具有结构，ChatModels\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 有不同的角色，系统、人类、AI\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"你是一个起名大师，你的名字叫{name}\"),\n",
    "        (\"human\", \"你好{name}，你感觉如何？\"),\n",
    "        (\"ai\", \"你好！我的状态非常好！\"),\n",
    "        (\"human\", \"你叫什么名字呢？\"),\n",
    "        (\"ai\", \"你好！我叫{name}。\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 参数传递给模板\n",
    "chat_template.format_messages(name=\"陈大师\", user_input=\"你的爸爸是谁呢？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接引入SystemMessage、HumanMessage、AIMessage消息类创建消息\n",
    "# 与上方是等价的，但是编写方式更加灵活\n",
    "# 它表示一个具体的、已生成的消息。它不涉及提示模板或变量替换。\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "system = SystemMessage(\n",
    "    content=\"你是一个起名大师\",\n",
    "    # 附加参数\n",
    "    additional_kwargs={\"大师姓名\": \"陈瞎子\"}\n",
    ")\n",
    "\n",
    "human = HumanMessage(\n",
    "    content=\"请问大师叫什么？\"\n",
    ")\n",
    "\n",
    "ai = AIMessage(\n",
    "    content=\"我叫陈瞎子\"\n",
    ")\n",
    "\n",
    "[system, human, ai]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ChatMessagePromptTemplate 聊天消息提示模板\n",
    "允许你指定任意角色名称，适用于支持自定义角色的聊天模型。\n",
    "这使得它比 HumanMessagePromptTemplate、AIMessagePromptTemplate 和 SystemMessagePromptTemplate 等固定角色更通用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import AIMessagePromptTemplate\n",
    "from langchain_core.prompts import SystemMessagePromptTemplate\n",
    "from langchain_core.prompts import HumanMessagePromptTemplate\n",
    "from langchain_core.prompts import ChatMessagePromptTemplate\n",
    "\n",
    "# 定义模板\n",
    "prompt = \"愿{subject}与你同在！\"\n",
    "\n",
    "# AIMessagePromptTemplate 默认的AI角色\n",
    "# SystemMessagePromptTemplate 默认的system角色\n",
    "# HumanMessagePromptTemplate 默认的human角色\n",
    "\n",
    "# 自定义角色模板，指定模板。使用role来设定对话角色\n",
    "chat_message_prompt = ChatMessagePromptTemplate.from_template(role=\"天行者\", template=prompt)\n",
    "# 动态参数\n",
    "chat_message_prompt.format(subject=\"原力\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 自定义模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现函数大师应用：可以根据函数名称，去查找函数代码，并给出中文的代码说明\n",
    "\n",
    "from langchain_core.prompts import StringPromptTemplate\n",
    "\n",
    "# 定义一个简单的函数作为示例效果\n",
    "def hello_world():\n",
    "    \"\"\"\n",
    "    一个简单的hello world函数\n",
    "    \"\"\"\n",
    "    print(\"hello world!\")\n",
    "    return \"hello world!\"\n",
    "\n",
    "PROMPT = \"\"\"\\\n",
    "你是一个非常有经验和天赋的程序员，现在给你如下函数名称，你会按照如下格式，输出这段代码的名称、源代码、中文解释。\n",
    "函数名称：{function_name}\n",
    "源代码：\n",
    "{source_code}\n",
    "代码解释：\n",
    "\"\"\"\n",
    "\n",
    "# 引入通过函数名获取源代码的工具包\n",
    "import inspect\n",
    "\n",
    "def get_source_code(function_name):\n",
    "    \"\"\"\n",
    "    获取函数的源代码\n",
    "    \"\"\"\n",
    "    # 获取函数对象\n",
    "    function = globals().get(function_name)\n",
    "    # 获取函数源代码\n",
    "    source_code = inspect.getsource(function)\n",
    "    return source_code\n",
    "\n",
    "# 自定义的Prompt模板，继承StringPromptTemplate\n",
    "class CustPrompt(StringPromptTemplate):\n",
    "    \"\"\"\n",
    "    自定义的Prompt模板\n",
    "    \"\"\"\n",
    "    def format(self, **kwargs):\n",
    "        \"\"\"\n",
    "        格式化函数\n",
    "        \"\"\"\n",
    "        # 获取函数名称\n",
    "        function_name = kwargs.get(\"function_name\")\n",
    "        # 获取函数源代码\n",
    "        source_code = get_source_code(function_name)\n",
    "        # 生成提示词模板\n",
    "        prompt = PROMPT.format(\n",
    "            function_name=function_name, \n",
    "            source_code=source_code\n",
    "        )\n",
    "        return prompt\n",
    "\n",
    "# 使用自定义模板时，首先创建 CustPrompt 类的实例，并传入一个包含函数名称的字典作为 input_variables。\n",
    "cust_prompt = CustPrompt(input_variables=[\"function_name\"])\n",
    "# 然后，调用 format 方法，并传入实际的函数对象 hello_world，生成最终的提示词模板。\n",
    "pm = cust_prompt.format(function_name=hello_world.__name__)\n",
    "\n",
    "print(pm)\n",
    "\n",
    "# 和LLM连接起来，让其解释代码\n",
    "from langchain_openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "api_base = os.getenv(\"OPENAI_API_BASE_URL\")\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model_name = os.getenv(\"MODEL_NAME\")\n",
    "\n",
    "llm = OpenAI(\n",
    "    openai_api_base=api_base,\n",
    "    openai_api_key=api_key,\n",
    "    model=model_name,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "msg = llm.invoke(pm)\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 使用F-string与jinja2来实现提示词模板格式化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f-string是python内置的一种模板引擎\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# f-string模板使用\n",
    "f_string_template = \"\"\"\n",
    "给我讲一个关于{name}的{what}故事。\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(f_string_template)\n",
    "prompt.format(name=\"翠花\", what=\"悲伤\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 安装jinja2依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jinja2是一个灵活、搞笑的Python模板引擎，可以方便的生成各种标记格式的文档。\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# jinja2模板使用\n",
    "jinja2_template = \"给我将一个关于{{name}}的{{what}}故事。\"\n",
    "\n",
    "# 创建PromptTemplate实例，传入模板并且指定模板类型为jinja2\n",
    "prompt = PromptTemplate.from_template(jinja2_template, template_format=\"jinja2\")\n",
    "prompt.format(name=\"翠花\", what=\"悲伤\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 组合式提示词模板\n",
    "+ Final prompt：最终返回的提示词模板\n",
    "+ Pipeline prompts：组成提示词管道的模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts.pipeline import PipelinePromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 组合模板：三层提示词设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 三层提示词示例(最终生成的效果)\n",
    "PROMPT = \"\"\"\n",
    "你是一个非常开朗的男孩，你是中国人，住在一个非常美丽的城市。\n",
    "你总是穿蓝色衣服，戴着绿色手表。\n",
    "你从不说自己是一个人工智能。\n",
    "\"\"\"\n",
    "\n",
    "# Final Prompt 由一些列变量组成\n",
    "full_template = \"\"\"{character}\n",
    "{behavior}\n",
    "{prohibit}\"\"\"\n",
    "\n",
    "full_prompt = PromptTemplate.from_template(full_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 第一层基本性格设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_template = \"\"\"你是{person}，你有着{xingge}.\"\"\"\n",
    "character_prompt = PromptTemplate.from_template(character_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 第二层行为设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_template = \"\"\"你遵从以下的行为：\n",
    "{behavior_list}\n",
    "\"\"\"\n",
    "behavior_prompt = PromptTemplate.from_template(behavior_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 第三层不允许的行为"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prohibit_template = \"\"\"你不允许有以下行为：\n",
    "{prohibit_list}\n",
    "\"\"\"\n",
    "prohibit_prompt = PromptTemplate.from_template(prohibit_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 将三层提示词组合起来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prompts = [\n",
    "    (\"character\", character_prompt),\n",
    "    (\"behavior\", behavior_prompt),\n",
    "    (\"prohibit\", prohibit_prompt)\n",
    "]\n",
    "\n",
    "# 创建PipelinePromptTemplate实例，将多个提示模板连接在一起\n",
    "pipeline_prompt = PipelinePromptTemplate(final_prompt=full_prompt, pipeline_prompts=input_prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 打印下组合后模板里的可传递参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_prompt.input_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 调整组合后的提示词模板（传递参数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PipelinePromptTemplate实例格式化提示\n",
    "pm = pipeline_prompt.format(\n",
    "    person=\"埃隆马斯克\",\n",
    "    xingge=\"钢铁般的意志，你是世界首富，精通物理、天文、商业，你是商业奇才，你的终极梦想是移民火星。\",\n",
    "    behavior_list=\"1.你喜欢冒险 \\n 2.你非常崇拜爱因斯坦 \\n 3.你总是乐于助人，回答用户各种问题。\",\n",
    "    prohibit_list=\"1.你不可以说自己是一个人工智能或者机器人 \\n 2.当你不知道答案的时候，可以说让我再想想。\"\n",
    ")\n",
    "\n",
    "print(pm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 序列化：使用文件来管理提示词模板\n",
    "+ 将提示词模板以文件形式保存\n",
    "+ 便于共享\n",
    "+ 便于版本管理\n",
    "+ 便于存储\n",
    "+ 支持常见格式 （json/yaml/txt）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引入包\n",
    "from langchain_core.prompts import load_prompt\n",
    "\n",
    "# 加载提示词模板文件\n",
    "\n",
    "# 加载yaml格式的prompt模板文件\n",
    "prompt = load_prompt(path=\"simple_prompt.yaml\", encoding=\"utf-8\")\n",
    "# 格式化提示词\n",
    "print(prompt.format(name=\"小黑\", what=\"悲伤\"))\n",
    "\n",
    "# 加载json格式的prompt模板文件\n",
    "prompt2 = load_prompt(path=\"simple_prompt.json\", encoding=\"utf-8\")\n",
    "# 格式化提示词\n",
    "print(prompt2.format(name=\"小红\", what=\"搞笑\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 支持加载文件格式的模板,并且对prompt的最终解析结果进行自定义格式化\n",
    "from langchain.output_parsers import RegexParser\n",
    "\n",
    "# 定义 Prompt 并包含定义解析方式\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\", \"student_answer\"],\n",
    "    template=\"Given the following question and student answer, provide a correct answer and score the student answer.\\nQuestion: {question}\\nStudent Answer: {student_answer}\\nCorrect Answer:\",\n",
    "    output_parser=RegexParser(\n",
    "        regex=\"(.*?)\\\\nScore: (.*)\",  # 正则匹配\n",
    "        output_keys=[\"answer\", \"score\"],  # 输出的key\n",
    "    )\n",
    ")\n",
    "\n",
    "# 解析输出\n",
    "parsed_output = prompt.output_parser.parse(\"George Washington was born in 1732 and died in 1799.\\nScore: 1/2\")\n",
    "print(parsed_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用提示词模板文件实现与上面相同功能\n",
    "import json\n",
    "from langchain_core.prompts import load_prompt\n",
    "\n",
    "# 该方式目前版本不支持这样使用 已过时\n",
    "# 加载json格式的prompt模板文件\n",
    "# prompt = load_prompt(path=\"prompt_with_output_parser.json\", encoding=\"utf-8\")\n",
    "# parsed_output = prompt.output_parser.parse(\n",
    "#     \"George Washington was born in 1732 and died in 1799.\\nScore: 1/2\"\n",
    "# )\n",
    "# print(parsed_output)\n",
    "\n",
    "# 读取 JSON 文件内容\n",
    "with open(\"prompt_with_output_parser.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    prompt_data = json.load(f)\n",
    "\n",
    "# 创建正则解析器 (RegexParser)\n",
    "output_parser_config = prompt_data[\"output_parser\"]\n",
    "output_parser = RegexParser(\n",
    "    regex=output_parser_config[\"regex\"],\n",
    "    output_keys=output_parser_config[\"output_keys\"]\n",
    ")\n",
    "\n",
    "# 创建提示词模板 (PromptTemplate)\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=prompt_data[\"input_variables\"],\n",
    "    template=prompt_data[\"template\"]\n",
    ")\n",
    "\n",
    "# 提供输入数据\n",
    "question = \"What is 2+2?\"\n",
    "student_answer = \"4\"\n",
    "\n",
    "# 格式化提示并运行\n",
    "formatted_prompt = prompt_template.format(question=question, student_answer=student_answer)\n",
    "print(\"Formatted Prompt:\", formatted_prompt)\n",
    "\n",
    "# 模拟 LLM 输出\n",
    "llm_output = \"George Washington was born in 1732 and died in 1799.\\nScore: 1/2\"\n",
    "\n",
    "# 使用 output_parser 解析 LLM 输出\n",
    "parsed_output = output_parser.parse(llm_output)\n",
    "print(\"Parsed Output:\", parsed_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
