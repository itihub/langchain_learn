{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 检索增强生成技术RAG\n",
    "RAG（检索增强生成）技术主要针对大型语言模型（LLMs）的以下几个缺点进行了改进：\n",
    "- 知识更新滞后：\n",
    "  - 大型语言模型通常基于大量历史数据进行训练，这导致它们的知识库存在时间上的滞后。对于最新的事件、信息或知识，模型可能无法提供准确的回答。\n",
    "  - RAG通过引入外部知识库，允许模型在生成响应时动态检索最新信息，从而弥补了这一缺陷。\n",
    "- 幻觉问题（Hallucination）\n",
    "  - 大型语言模型有时会生成看似合理但实际上不正确或不存在的信息，即“幻觉”。这可能是因为模型在训练数据中没有足够的证据支持其生成的答案，或者因为模型过度依赖于模式匹配。\n",
    "  - RAG通过将检索到的真实信息作为生成的基础，降低了模型产生幻觉的风险，提高了生成内容的可靠性。\n",
    "- 领域知识不足：\n",
    "  - 虽然大型语言模型在通用知识方面表现出色，但在特定领域或专业领域，它们的知识可能有限。\n",
    "  - RAG允许模型访问特定领域的知识库，从而增强其在这些领域的专业性，使其能够提供更准确和深入的回答。\n",
    "- 缺乏信息来源：\n",
    "  - 大型语言模型生成的文本通常缺乏明确的信息来源，这使得用户难以验证信息的真实性和可靠性。\n",
    "  - RAG可以提供检索到的文档或信息的链接，使用户能够追溯信息的来源，提高生成内容的可信度。\n",
    "总结来说，RAG技术通过将信息检索与文本生成相结合，有效地解决了大型语言模型在知识更新、幻觉问题、领域知识和信息来源方面的不足，提高了生成文本的质量和可靠性。\n",
    "\n",
    "RAG（Retrieval-Augmented Generation，检索增强生成）是一种将信息检索与文本生成相结合的技术，用于提高大型语言模型（LLMs）生成文本的质量和准确性。简单来说，RAG允许LLMs在生成回答之前，先从外部知识库中检索相关信息，然后利用这些信息来增强其生成的内容。\n",
    "\n",
    "以下是RAG的核心概念和工作原理：\n",
    "核心概念：\n",
    "- 检索（Retrieval）：\n",
    "  RAG系统首先根据用户的查询，从一个或多个外部知识库中检索相关文档或信息片段。\n",
    "  这些知识库可以是向量数据库、传统数据库、网页、文档集合等。\n",
    "- 增强（Augmentation）：\n",
    "  检索到的信息被整合到LLM的输入提示（prompt）中，作为额外的上下文。\n",
    "  这使得LLM能够访问其训练数据之外的最新或特定领域的信息。\n",
    "- 生成（Generation）：\n",
    "  LLM利用增强后的提示，生成包含检索到的相关信息的回答或文本。\n",
    "\n",
    "工作原理：\n",
    "- 用户查询：\n",
    "  用户向RAG系统提出一个问题或请求。\n",
    "- 信息检索：\n",
    "  系统使用检索模型（例如，基于向量相似度的检索）在知识库中查找与查询相关的文档。\n",
    "- 上下文增强：\n",
    "  检索到的文档被添加到LLM的输入提示中，为LLM提供额外的上下文信息。\n",
    "- 文本生成：\n",
    "  LLM根据增强后的提示，生成包含检索到的信息的回答或文本。\n",
    "\n",
    "RAG的优势：\n",
    "- 提高准确性：\n",
    "  通过访问外部知识，RAG可以减少LLM生成不准确或过时信息的风险。\n",
    "- 增强知识：\n",
    "  RAG允许LLM访问其训练数据中没有的特定领域或最新信息。\n",
    "- 提高可信度：\n",
    "  RAG可以提供信息来源，增加生成文本的可信度。\n",
    "- 减少幻觉：\n",
    "  通过检索实际的知识，来减少大型语言模型，自己“创造”信息的可能性。\n",
    "\n",
    "RAG的应用场景：\n",
    "- 问答系统：提供基于特定知识库的准确回答。\n",
    "- 内容创作：生成包含最新信息的文章、报告等。\n",
    "- 客户服务：提供基于产品文档或知识库的客户支持。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LangChain中的RAG的实现\n",
    "在 LangChain 中实现 RAG关键组件\n",
    "- 文档加载器（Document Loaders）：LangChain 提供了多种文档加载器，用于从各种数据源加载文档\n",
    "- 文本分割器（Text Splitters）：加载的文档通常很长，需要分割成更小的块，以便嵌入模型和语言模型处理\n",
    "- 嵌入模型（Embeddings）：嵌入模型将文本转换为向量，以便计算文本之间的相似度。\n",
    "- 向量数据库（Vector Stores）：向量数据库用于存储和检索嵌入向量。\n",
    "- 检索器（Retrievers）：检索器将查询转换为嵌入向量，并在向量数据库中查找最相似的文本块。\n",
    "- 语言模型（Language Models）：语言模型将检索到的文本块和用户查询作为输入，生成回答。\n",
    "- 链（Chains）：LangChain 的链允许你将多个组件组合在一起，形成一个工作流程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 文档加载器（loader）：让大模型具备实时学习能力\n",
    "- CSV loader：加载csv格式的文件\n",
    "- File directory：根据目录加载\n",
    "- Html loader：加载html格式的文件\n",
    "- Json loader：加载json格式的文件\n",
    "- Markdown loader：加载Markdown格式的文件\n",
    "- Pdf loader：加载pdf格式的文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 加载Markdown文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './sources/loader.md'}, page_content='# 我是一个markdown加载示例\\n- 第一项目\\n- 第二个项目\\n- 第三个项目\\n\\n## 第一个项目\\nAI研习社最厉害专业的AI研究基地\\n\\n## 第二个项目\\nAIGC打造未来AI应用天地\\n\\n## 第三个项目\\nAI研习社是一个非常牛逼的AI媒体')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用loader来加载Markdown文本\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(file_path=\"./sources/loader.md\", encoding=\"utf-8\")\n",
    "loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 加载SCV文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': '北京', 'row': 0}, page_content='\\ufeffProject: AI GC培训\\nDES: 培训课程\\nPrice: 500\\nPeople: 100\\nLocation: 北京'), Document(metadata={'source': '西安', 'row': 1}, page_content='\\ufeffProject: AI工程师认证\\nDES: 微软AI认证\\nPrice: 6000\\nPeople: 200\\nLocation: 西安'), Document(metadata={'source': '深圳', 'row': 2}, page_content='\\ufeffProject: AI应用大会\\nDES: AI应用创新大会\\nPrice: 200门票\\nPeople: 300\\nLocation: 深圳'), Document(metadata={'source': '香港', 'row': 3}, page_content='\\ufeffProject: AI 应用咨询服务\\nDES: AI与场景结合\\nPrice: 1000/小时\\nPeople: 50\\nLocation: 香港'), Document(metadata={'source': '上海', 'row': 4}, page_content='\\ufeffProject: AI项目可研\\nDES: 可行性报告\\nPrice: 20000\\nPeople: 60\\nLocation: 上海')]\n"
     ]
    }
   ],
   "source": [
    "# 使用loader来加载CSV文本\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "\n",
    "# loader = CSVLoader(file_path='./sources/loader.csv', encoding=\"utf-8\")\n",
    "# 加载指定列\n",
    "loader = CSVLoader(file_path='./sources/loader.csv', source_column=\"Location\", encoding=\"utf-8\")\n",
    "data = loader.load()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 加载Excel文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unstructured[xlsx]\n",
      "  Using cached unstructured-0.16.25-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting chardet (from unstructured[xlsx])\n",
      "  Using cached chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting filetype (from unstructured[xlsx])\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting python-magic (from unstructured[xlsx])\n",
      "  Using cached python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting lxml (from unstructured[xlsx])\n",
      "  Using cached lxml-5.3.1-cp313-cp313-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting nltk (from unstructured[xlsx])\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured[xlsx]) (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured[xlsx]) (4.13.3)\n",
      "Collecting emoji (from unstructured[xlsx])\n",
      "  Using cached emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured[xlsx]) (0.6.7)\n",
      "Collecting python-iso639 (from unstructured[xlsx])\n",
      "  Using cached python_iso639-2025.2.18-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting langdetect (from unstructured[xlsx])\n",
      "  Using cached langdetect-1.0.9.tar.gz (981 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting numpy<2 (from unstructured[xlsx])\n",
      "  Using cached numpy-1.26.4.tar.gz (15.8 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): still running...\n",
      "  Preparing metadata (pyproject.toml): still running...\n",
      "  Preparing metadata (pyproject.toml): still running...\n",
      "  Preparing metadata (pyproject.toml): still running...\n",
      "  Preparing metadata (pyproject.toml): still running...\n",
      "  Preparing metadata (pyproject.toml): still running...\n",
      "  Preparing metadata (pyproject.toml): still running...\n",
      "  Preparing metadata (pyproject.toml): still running...\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting rapidfuzz (from unstructured[xlsx])\n",
      "  Downloading rapidfuzz-3.12.2-cp313-cp313-win_amd64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: backoff in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured[xlsx]) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured[xlsx]) (4.12.2)\n",
      "Collecting unstructured-client (from unstructured[xlsx])\n",
      "  Downloading unstructured_client-0.31.1-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: wrapt in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured[xlsx]) (1.17.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured[xlsx]) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured[xlsx]) (7.0.0)\n",
      "Collecting python-oxmsg (from unstructured[xlsx])\n",
      "  Downloading python_oxmsg-0.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting html5lib (from unstructured[xlsx])\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting openpyxl (from unstructured[xlsx])\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pandas (from unstructured[xlsx])\n",
      "  Downloading pandas-2.2.3-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Collecting xlrd (from unstructured[xlsx])\n",
      "  Downloading xlrd-2.0.1-py2.py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting networkx (from unstructured[xlsx])\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from beautifulsoup4->unstructured[xlsx]) (2.6)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from dataclasses-json->unstructured[xlsx]) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from dataclasses-json->unstructured[xlsx]) (0.9.0)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from html5lib->unstructured[xlsx]) (1.17.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from html5lib->unstructured[xlsx]) (0.5.1)\n",
      "Requirement already satisfied: click in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from nltk->unstructured[xlsx]) (8.1.8)\n",
      "Collecting joblib (from nltk->unstructured[xlsx])\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from nltk->unstructured[xlsx]) (2024.11.6)\n",
      "Collecting et-xmlfile (from openpyxl->unstructured[xlsx])\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from pandas->unstructured[xlsx]) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->unstructured[xlsx])\n",
      "  Downloading pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->unstructured[xlsx])\n",
      "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting olefile (from python-oxmsg->unstructured[xlsx])\n",
      "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from requests->unstructured[xlsx]) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from requests->unstructured[xlsx]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from requests->unstructured[xlsx]) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from requests->unstructured[xlsx]) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from tqdm->unstructured[xlsx]) (0.4.6)\n",
      "Collecting aiofiles>=24.1.0 (from unstructured-client->unstructured[xlsx])\n",
      "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting cryptography>=3.1 (from unstructured-client->unstructured[xlsx])\n",
      "  Downloading cryptography-44.0.2-cp39-abi3-win_amd64.whl.metadata (5.7 kB)\n",
      "Collecting eval-type-backport>=0.2.0 (from unstructured-client->unstructured[xlsx])\n",
      "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured-client->unstructured[xlsx]) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured-client->unstructured[xlsx]) (1.6.0)\n",
      "Requirement already satisfied: pydantic>=2.10.3 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured-client->unstructured[xlsx]) (2.10.6)\n",
      "Collecting pypdf>=4.0 (from unstructured-client->unstructured[xlsx])\n",
      "  Downloading pypdf-5.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured-client->unstructured[xlsx]) (1.0.0)\n",
      "Collecting typing-inspection>=0.4.0 (from unstructured-client->unstructured[xlsx])\n",
      "  Downloading typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from cryptography>=3.1->unstructured-client->unstructured[xlsx]) (1.17.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from httpx>=0.27.0->unstructured-client->unstructured[xlsx]) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from httpx>=0.27.0->unstructured-client->unstructured[xlsx]) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured[xlsx]) (0.14.0)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured[xlsx]) (24.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from pydantic>=2.10.3->unstructured-client->unstructured[xlsx]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from pydantic>=2.10.3->unstructured-client->unstructured[xlsx]) (2.27.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured[xlsx]) (1.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured[xlsx]) (2.22)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured[xlsx]) (1.3.1)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
      "   ---------------------------------------- 0.0/590.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 590.6/590.6 kB 6.6 MB/s eta 0:00:00\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Downloading lxml-5.3.1-cp313-cp313-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 1.6/3.8 MB 11.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 9.3 MB/s eta 0:00:00\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 7.7 MB/s eta 0:00:00\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 9.2 MB/s eta 0:00:00\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading pandas-2.2.3-cp313-cp313-win_amd64.whl (11.5 MB)\n",
      "   ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/11.5 MB 8.3 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.7/11.5 MB 8.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.8/11.5 MB 9.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.6/11.5 MB 9.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.0/11.5 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.3/11.5 MB 9.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.5/11.5 MB 8.8 MB/s eta 0:00:00\n",
      "Downloading python_iso639-2025.2.18-py3-none-any.whl (167 kB)\n",
      "Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Downloading python_oxmsg-0.0.2-py3-none-any.whl (31 kB)\n",
      "Downloading rapidfuzz-3.12.2-cp313-cp313-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 9.0 MB/s eta 0:00:00\n",
      "Downloading unstructured-0.16.25-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.8/1.8 MB 8.5 MB/s eta 0:00:00\n",
      "Downloading unstructured_client-0.31.1-py3-none-any.whl (166 kB)\n",
      "Downloading xlrd-2.0.1-py2.py3-none-any.whl (96 kB)\n",
      "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading cryptography-44.0.2-cp39-abi3-win_amd64.whl (3.2 MB)\n",
      "   ---------------------------------------- 0.0/3.2 MB ? eta -:--:--\n",
      "   -------------------------- ------------- 2.1/3.2 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.2/3.2 MB 9.7 MB/s eta 0:00:00\n",
      "Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
      "Downloading pypdf-5.3.1-py3-none-any.whl (302 kB)\n",
      "Downloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Downloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Downloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
      "Building wheels for collected packages: numpy, langdetect\n",
      "  Building wheel for numpy (pyproject.toml): started\n",
      "  Building wheel for numpy (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for numpy: filename=numpy-1.26.4-cp313-cp313-win_amd64.whl size=6139174 sha256=c26ff658cfd44f10cf72ca87d620f8b08e366e2b9fe1c1c387f6569f7e906fde\n",
      "  Stored in directory: c:\\users\\jizhe\\appdata\\local\\pip\\cache\\wheels\\8b\\2d\\9f\\b6b46373f328e2ef50388915d351ccacbedac929459b5459bf\n",
      "  Building wheel for langdetect (pyproject.toml): started\n",
      "  Building wheel for langdetect (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993313 sha256=48be19bb7d7726c540a0e8e92678fb81b8baef23e15a2757f24b80442de7422d\n",
      "  Stored in directory: c:\\users\\jizhe\\appdata\\local\\pip\\cache\\wheels\\eb\\87\\25\\2dddf1c94e1786054e25022ec5530bfed52bad86d882999c48\n",
      "Successfully built numpy langdetect\n",
      "Installing collected packages: pytz, filetype, xlrd, tzdata, typing-inspection, rapidfuzz, python-magic, python-iso639, pypdf, olefile, numpy, networkx, lxml, langdetect, joblib, html5lib, eval-type-backport, et-xmlfile, emoji, chardet, aiofiles, python-oxmsg, pandas, openpyxl, nltk, cryptography, unstructured-client, unstructured\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.3\n",
      "    Uninstalling numpy-2.2.3:\n",
      "      Successfully uninstalled numpy-2.2.3\n",
      "Successfully installed aiofiles-24.1.0 chardet-5.2.0 cryptography-44.0.2 emoji-2.14.1 et-xmlfile-2.0.0 eval-type-backport-0.2.2 filetype-1.2.0 html5lib-1.1 joblib-1.4.2 langdetect-1.0.9 lxml-5.3.1 networkx-3.4.2 nltk-3.9.1 numpy-1.26.4 olefile-0.47 openpyxl-3.1.5 pandas-2.2.3 pypdf-5.3.1 python-iso639-2025.2.18 python-magic-0.4.27 python-oxmsg-0.0.2 pytz-2025.1 rapidfuzz-3.12.2 typing-inspection-0.4.0 tzdata-2025.1 unstructured-0.16.25 unstructured-client-0.31.1 xlrd-2.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\jizhe\\.virtualenvs\\lang-chain-wYHJBg1W\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\jizhe\\.virtualenvs\\lang-chain-wYHJBg1W\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "# 安装依赖包，才能实现对excel文件的解析\n",
    "%pip install \"unstructured[xlsx]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'sources\\\\fake.xlsx'}, page_content='名称 宏图科技发展有限公司 注册地址 江苏省南京市雨花台区软件大道101号 成立日期 40679 法定代表人 李强 注册资本 人民币5000万元 员工人数 约200人 联系电话 025-88888888 电子邮箱 info@hongtutech.cn 资产总额 人民币1.2亿元，较上年同期下降30% 负债总额 人民币1.8亿元，较上年同期上升50%，资不抵债 营业收入 人民币3000万元，较上年同期下降60% 净利润 亏损人民币800万元，去年同期为盈利人民币200万元 现金流量 公司现金流量紧张，现金及现金等价物余额为人民币500万元，难以支撑日常运营')]\n"
     ]
    }
   ],
   "source": [
    "# 使用loader来加载Excel文本\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "# 某个目录下，有excel文件，我们需要把这个目录下所有的excel文件都加载进来\n",
    "# 使用DirectoryLoader不会加载该目录下的.html和.rst文件\n",
    "loader = DirectoryLoader(\"./sources\", glob=\"*.xlsx\")\n",
    "xlsx = loader.load()\n",
    "print(xlsx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 加载HTML文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unstructured in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (0.16.25)\n",
      "Requirement already satisfied: chardet in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured) (5.2.0)\n",
      "Requirement already satisfied: filetype in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured) (1.2.0)\n",
      "Requirement already satisfied: python-magic in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured) (0.4.27)\n",
      "Requirement already satisfied: lxml in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured) (5.3.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured) (3.9.1)\n",
      "Requirement already satisfied: requests in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured) (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured) (4.13.3)\n",
      "Requirement already satisfied: emoji in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured) (2.14.1)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured) (0.6.7)\n",
      "Requirement already satisfied: python-iso639 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured) (2025.2.18)\n",
      "Requirement already satisfied: langdetect in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured) (1.0.9)\n",
      "Requirement already satisfied: numpy<2 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured) (1.26.4)\n",
      "Requirement already satisfied: rapidfuzz in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured) (3.12.2)\n",
      "Requirement already satisfied: backoff in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured) (4.12.2)\n",
      "Requirement already satisfied: unstructured-client in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured) (0.31.1)\n",
      "Requirement already satisfied: wrapt in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured) (1.17.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured) (7.0.0)\n",
      "Requirement already satisfied: python-oxmsg in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured) (0.0.2)\n",
      "Requirement already satisfied: html5lib in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured) (1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from beautifulsoup4->unstructured) (2.6)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from dataclasses-json->unstructured) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from dataclasses-json->unstructured) (0.9.0)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from html5lib->unstructured) (1.17.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from html5lib->unstructured) (0.5.1)\n",
      "Requirement already satisfied: click in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from nltk->unstructured) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from nltk->unstructured) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from nltk->unstructured) (2024.11.6)\n",
      "Requirement already satisfied: olefile in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from python-oxmsg->unstructured) (0.47)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from requests->unstructured) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from requests->unstructured) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from requests->unstructured) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from requests->unstructured) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from tqdm->unstructured) (0.4.6)\n",
      "Requirement already satisfied: aiofiles>=24.1.0 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured-client->unstructured) (24.1.0)\n",
      "Requirement already satisfied: cryptography>=3.1 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured-client->unstructured) (44.0.2)\n",
      "Requirement already satisfied: eval-type-backport>=0.2.0 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured-client->unstructured) (0.2.2)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured-client->unstructured) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured-client->unstructured) (1.6.0)\n",
      "Requirement already satisfied: pydantic>=2.10.3 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured-client->unstructured) (2.10.6)\n",
      "Requirement already satisfied: pypdf>=4.0 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured-client->unstructured) (5.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured-client->unstructured) (2.9.0.post0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured-client->unstructured) (1.0.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from unstructured-client->unstructured) (0.4.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from cryptography>=3.1->unstructured-client->unstructured) (1.17.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured) (0.14.0)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured) (24.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from pydantic>=2.10.3->unstructured-client->unstructured) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from pydantic>=2.10.3->unstructured-client->unstructured) (2.27.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured) (1.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured) (2.22)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 安装依赖包\n",
    "%pip install unstructured "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': './sources/loader.html'}, page_content='首发于自然语言处理算法与实践\\n\\n切换模式\\n\\nRAG:将检索与生成方式相结合来做生成任务\\n\\n烛之文\\u200b\\n\\na worker in NLP\\n\\n1、前言\\n\\n在上一篇<kNN-NER：利用knn近邻算法来做命名实体识别>提及到文中提出kNN-NER框架是一种检索式增强的方法（retrieval augmented methods），就去查看有关retrieval augmented的paper，了解其核心思想，觉得检索式增强的方法很适合许多业务场景使用，因其以一种简捷的方式将外部知识融于模型中去。今天就分享一篇来自Facebook AI Research的paper<Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks>，论文提出一种检索式增强生成方法，应用于知识密集型的NLP任务（如问答生成），该篇论文被2020年NeurIPS 会议接收。\\n\\n文中说到，以BERT之类的大规模预训练模型将很多事实知识信息存入模型中，可以看着是pre-trained parametric类型，尽管以fine-tuned方式在下游任务取得显著的成效，但这类方法仍存在无法精准地获取和操作知识的缺陷。而在上述提及的问题上，传统知识检索的方法能很好的应对，这类方法可以看着是non-parametric memory类型。于是，论文提出检索式增强生成方法（retrieval-augmented generation，RAG），主要思想就是将pre-trained parametric与non-parametric memory结合起来做语言生成任务，将两类模型集成起来提高任务处理效果。\\n\\n2、RAG方法\\n\\n上图为论文提出RAG模型的整体示意图。主要包括两大模块：一个检索器（Retriever， p_\\\\eta(z|x) ） + 一个生成器（Generator， p_\\\\theta(y_i|x,z,y_{1:i-1}) ）。前者包括query encoder和document index，分别负责query的编码和文档的索引；后者是一个seq2seq的生成模型。在检索中，使用的是最大内积搜索的方法（MIPS）来检索top-K相关文档。\\n\\n最后，把检索器输出的信息当成额外的文本信息，通过边际化的方式（marginalize）融于生成器中，生成最终的序列。在融合过程中，论文提出两种不同的方式：RAG-Sequence Model和RAG-Token Model，主要区别在于前者利用同一篇文档来生成所有序列；后者是用检索到的所有文档来生成序列。其计算方式如下：\\n\\n关于检索器 p_\\\\eta(z|x) ，由输入query x经过encoder得到编码向量q(x)，另外将知识库里的文档事先通过编码器得到文档编码向量d(z)，然后q(x)与d(z)做最大内积搜索到top-K相关文档，输出作为 p_\\\\eta(z|x) 。\\n\\n关于生成器 p_\\\\theta(y_i|x,z,y_{1:i-1}) ，论文中是用BART-large作为训练模型，然后将query x和检索到的z输入其中得到生成的序列文本。\\n\\n在解码过程中，RAG-Token Model可视为一个标准的自回归生成模型，按常规的beam search方式就可以解码；而在RAG-Sequence Model中，因为每个文档都生成一个序列，不能正常的beam search方式来解码。文中是对每个文档按beam search解码出一个序列，得到解码序列集合，针对每个生成序列，用其生成概率与 p_\\\\eta(z|x) 点乘得到一个概率score，取最大值对应的序列为最终输出。\\n\\n3、实验\\n\\n论文在四类Knowledge-Intensive 任务上进行实验，具体包括开放问答（Open-domain Question Answering ）、摘要式问答（Abstractive Question Answering） 、开放问题生成（Jeopardy Question Generation）、事实判断（Fact Verification ），并使用维基百科（包含2100万个文档）作为检索库。\\n\\n上表显示：在Open-domain Question Answering 任务上，论文提出的两个方法在4个数据集都取得新的最佳结果。\\n\\n上表显示，在Jeopardy Question Generation任务（Jeopardy数据集）上，RAG-Tok取得最优结果，且RAG都超过BART的表现；\\n\\n在Abstractive Question Answering任务（MSMARCO数据集）上，RAG模型都优于BART模型，但接近已有的最佳模型，其原因是论文在实验中没有利用数据集中包含文档 gold access信息；\\n\\n在Fact Verification任务上（FVR3,FVR2数据集） 上，对于3-way分类（FVR3），RAG比最优模型差4.3%，然而这类最优模型都是基于复杂的pipeline方法，需要大量的中间特征工程，而RAG不需要这些特征工程就可以达到接近的效果。\\n\\n此外，论文显示对比BART，RAG模型生成的文本更符合事实，更准确，且多样化。\\n\\n4、结语\\n\\n本次分享基于检索增强方式将外部知识融于生成任务中一个新的框架——RAG。对比T5 和 BART这类擅长处理生成任务的模型来说，RAG更新外部知识是不需要重新预训练，成本低；而对比pipeline方法，RAG利用外部知识并不需要构造负责的特征工程。总的来说，RAG方法可作为外部知识融合框架的一种有效实例。\\n\\n有兴趣可关注笔者公众号：自然语言处理算法与实践\\n\\n编辑于 2022-04-06 10:47\\n\\n深度学习（Deep Learning）\\n\\n机器学习\\n\\n检索数据库\\n\\n文章被以下专栏收录\\n\\n自然语言处理算法与实践')]\n"
     ]
    }
   ],
   "source": [
    "# 使用loader来加载html文件\n",
    "# UnstructuredHTMLLoader 使用 unstructured 库来加载 HTML 文件。它能够处理更复杂的 HTML 结构，并提取出更干净的文本内容。\n",
    "from langchain_community.document_loaders import UnstructuredHTMLLoader\n",
    "\n",
    "# 把html源代码加载进来\n",
    "loader = UnstructuredHTMLLoader(\"./sources/loader.html\")\n",
    "data = loader.load()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': './sources/loader.html', 'title': 'RAG:将检索与生成方式相结合来做生成任务 - 知乎'}, page_content='RAG:将检索与生成方式相结合来做生成任务 - 知乎首发于自然语言处理算法与实践切换模式写文章登录/注册RAG:将检索与生成方式相结合来做生成任务烛之文\\u200ba worker in NLP1、前言在上一篇<kNN-NER：利用knn近邻算法来做命名实体识别>提及到文中提出kNN-NER框架是一种检索式增强的方法（retrieval augmented methods），就去查看有关retrieval augmented的paper，了解其核心思想，觉得检索式增强的方法很适合许多业务场景使用，因其以一种简捷的方式将外部知识融于模型中去。今天就分享一篇来自Facebook AI Research的paper<Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks>，论文提出一种检索式增强生成方法，应用于知识密集型的NLP任务（如问答生成），该篇论文被2020年NeurIPS 会议接收。文中说到，以BERT之类的大规模预训练模型将很多事实知识信息存入模型中，可以看着是pre-trained parametric类型，尽管以fine-tuned方式在下游任务取得显著的成效，但这类方法仍存在无法精准地获取和操作知识的缺陷。而在上述提及的问题上，传统知识检索的方法能很好的应对，这类方法可以看着是non-parametric memory类型。于是，论文提出检索式增强生成方法（retrieval-augmented generation，RAG），主要思想就是将pre-trained parametric与non-parametric memory结合起来做语言生成任务，将两类模型集成起来提高任务处理效果。2、RAG方法上图为论文提出RAG模型的整体示意图。主要包括两大模块：一个检索器（Retriever， p_\\\\eta(z|x) ） + 一个生成器（Generator， p_\\\\theta(y_i|x,z,y_{1:i-1}) ）。前者包括query encoder和document index，分别负责query的编码和文档的索引；后者是一个seq2seq的生成模型。在检索中，使用的是最大内积搜索的方法（MIPS）来检索top-K相关文档。最后，把检索器输出的信息当成额外的文本信息，通过边际化的方式（marginalize）融于生成器中，生成最终的序列。在融合过程中，论文提出两种不同的方式：RAG-Sequence Model和RAG-Token Model，主要区别在于前者利用同一篇文档来生成所有序列；后者是用检索到的所有文档来生成序列。其计算方式如下：关于检索器 p_\\\\eta(z|x) ，由输入query x经过encoder得到编码向量q(x)，另外将知识库里的文档事先通过编码器得到文档编码向量d(z)，然后q(x)与d(z)做最大内积搜索到top-K相关文档，输出作为 p_\\\\eta(z|x) 。关于生成器 p_\\\\theta(y_i|x,z,y_{1:i-1}) ，论文中是用BART-large作为训练模型，然后将query x和检索到的z输入其中得到生成的序列文本。在解码过程中，RAG-Token Model可视为一个标准的自回归生成模型，按常规的beam search方式就可以解码；而在RAG-Sequence Model中，因为每个文档都生成一个序列，不能正常的beam search方式来解码。文中是对每个文档按beam search解码出一个序列，得到解码序列集合，针对每个生成序列，用其生成概率与 p_\\\\eta(z|x) 点乘得到一个概率score，取最大值对应的序列为最终输出。3、实验论文在四类Knowledge-Intensive 任务上进行实验，具体包括开放问答（Open-domain Question Answering ）、摘要式问答（Abstractive Question Answering） 、开放问题生成（Jeopardy Question Generation）、事实判断（Fact Verification ），并使用维基百科（包含2100万个文档）作为检索库。上表显示：在Open-domain Question Answering 任务上，论文提出的两个方法在4个数据集都取得新的最佳结果。上表显示，在Jeopardy Question Generation任务（Jeopardy数据集）上，RAG-Tok取得最优结果，且RAG都超过BART的表现；在Abstractive Question Answering任务（MSMARCO数据集）上，RAG模型都优于BART模型，但接近已有的最佳模型，其原因是论文在实验中没有利用数据集中包含文档 gold access信息；在Fact Verification任务上（FVR3,FVR2数据集） 上，对于3-way分类（FVR3），RAG比最优模型差4.3%，然而这类最优模型都是基于复杂的pipeline方法，需要大量的中间特征工程，而RAG不需要这些特征工程就可以达到接近的效果。此外，论文显示对比BART，RAG模型生成的文本更符合事实，更准确，且多样化。4、结语本次分享基于检索增强方式将外部知识融于生成任务中一个新的框架——RAG。对比T5 和 BART这类擅长处理生成任务的模型来说，RAG更新外部知识是不需要重新预训练，成本低；而对比pipeline方法，RAG利用外部知识并不需要构造负责的特征工程。总的来说，RAG方法可作为外部知识融合框架的一种有效实例。有兴趣可关注笔者公众号：自然语言处理算法与实践编辑于 2022-04-06 10:47深度学习（Deep Learning）机器学习检索数据库\\u200b赞同 16\\u200b\\u200b添加评论\\u200b分享\\u200b喜欢\\u200b收藏\\u200b申请转载\\u200b文章被以下专栏收录自然语言处理算法与实践')]\n"
     ]
    }
   ],
   "source": [
    "# BSHTMLLoader 使用 BeautifulSoup 库来解析 HTML 文件。它更适用于简单的 HTML 结构，并且可以方便地提取特定元素的内容。\n",
    "from langchain_community.document_loaders import BSHTMLLoader\n",
    "\n",
    "# 只把html中文本加载进来\n",
    "bs_loader = BSHTMLLoader(file_path=\"./sources/loader.html\", open_encoding=\"utf-8\")\n",
    "data = bs_loader.load()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 加载Json文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jq in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (1.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 使用loader来加载json，需要先安装依赖\n",
    "%pip install jq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'C:\\\\Users\\\\jizhe\\\\Projects\\\\python-project\\\\lang-chain\\\\simple_prompt.json', 'seq_num': 1}, page_content='给我讲一个关于{name}的{what}故事')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import JSONLoader\n",
    "\n",
    "# 只把html中文本加载进来，jq_schema参数允许你使用 jq 查询语言来提取 JSON 文件中的特定内容。\n",
    "loader = JSONLoader(file_path=\"simple_prompt.json\", jq_schema=\".template\", text_content=False)\n",
    "data = loader.load()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 加载PDF文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in c:\\users\\jizhe\\.virtualenvs\\lang-chain-wyhjbg1w\\lib\\site-packages (5.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 解析pdf文件的依赖包\n",
    "%pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'producer': 'macOS 版本14.1.1（版号23B81） Quartz PDFContext', 'creator': '文本编辑', 'creationdate': \"D:20231122121354Z00'00'\", 'title': '蒂法介绍', 'moddate': \"D:20231122121354Z00'00'\", 'source': './sources/loader.pdf', 'total_pages': 5, 'page': 0, 'page_label': '1'}, page_content='蒂法介绍\\n蒂法· 洛克哈特（⽇语：ティファ・ロックハート，Tifa Rokkuhāto，英语：Tifa \\nLockhart）为电⼦游戏《最终幻想VII》及《最终幻想VII补完计划》相关作品中的虚构⻆\\n⾊，由野村哲也创作和设计，此后也在多个游戏中客串登场。\\n2014年东京电玩展上，星名美津纪cosplay《最终幻想VII 降临之⼦》中的蒂法· 洛克哈特\\n蒂法是克劳德的⻘梅⽵⻢，两⼈同为尼布鲁海姆出身。在⽶德加经营作为反抗组织“雪崩”根\\n据地的酒馆“第七天堂”，并且是⼩有名⽓的招牌店员。擅⻓格⽃，以拳套为武器。本传7年前\\n克劳德离开故乡从军时，曾许下约定“如果有危机时⼀定会保护她”。与爱丽丝相识之后，两\\n⼈成为好友。第⼀个察觉克劳德记忆混乱的⼈，后来协助精神崩溃的克劳德重新找回真正的⾃\\n⼰。本传的⼤战结束后，依⼤家的期待在战后新⽣的⽶德加再次开设第七天堂（原第七天堂因\\n第柒区圆盘崩塌遭压毁），同时也照顾⼀群受到星痕症候群折磨的孩⼦们。\\n蒂法被《纽约时报》称为“⽹络⼀代”的海报⼥郎，与劳拉· 克罗夫特相⽐，她是电⼦游戏中坚\\n强、独⽴和有吸引⼒的⼥性⻆⾊的典型代表。媒体普遍称赞其实⼒和外表，并称她为游戏世界\\n中最好的⼥性⻆⾊之⼀。\\n在《最终幻想VII》本传中，蒂法年龄20岁、身⾼167cm、⽣⽇5⽉3⽇、⾎型B型、出⽣地尼\\n布尔海姆。\\n登场\\n《最终幻想VII》\\n蒂法在《最终幻想VII》原版中⾸次亮相，是克劳德的⻘梅⽵⻢、第七天堂酒吧的看板娘、极\\n端环境组织“雪崩”成员，该组织反抗巨型企业“神罗”因其⼤量抽取魔晄⽤作动⼒能源。在注\\n意到克劳德的性格改变后，她说服克劳德加⼊雪崩，以密切关注他，并且跟随他追寻游戏中的\\n对⼿萨菲罗斯。她⽆法阻⽌克劳德被萨菲罗斯操纵，在他的精神崩溃后，她帮助克劳德康复，\\n并且两⼈意识到彼此间的相互感觉，最后与伙伴们⼀同击败了萨菲罗斯。[2]\\n在闪回中可知，⼉时的蒂法⼀直是村中⼩孩的⼈⽓王。在⺟亲过世后，思念⺟亲的蒂法决定沿\\n着⼩路⾛到他们故乡尼布尔海姆附近的⼀座⼭上，认为这样就能⻅到过世的⺟亲，原本跟着蒂\\n法的其他⼩孩都在半路上因害怕⽽放弃，唯独克劳德仍坚定的在后⾯跟随，希望能在危机时保\\n护蒂法。然⽽，他们俩都从⼭上跌落受伤，蒂法昏迷了⼀个星期，她的⽗亲认为克劳德对此负\\n有责任[3]，甚为严令禁⽌克劳德再接近蒂法，但蒂法反⽽从此更在意克劳德，两⼈成为要好\\n的玩伴。为了使⾃⼰变得更强⼤，克劳德最终选择离开尼布尔海姆，加⼊神罗，想要成为神罗\\n的精英战⼠“神罗战⼠”（SOLDIER），但后来透露他主要是为了吸引蒂法的注意⼒。离开之\\n前，蒂法与克劳德约定，当蒂法处于困境之中时，克劳德会回来救她。从克劳德离开之后，蒂\\n法便开始留意神罗战⼠的消息，因为神罗战⼠都成为声名远播的知名⼈物，如果克劳德成为神\\n罗战⼠，他的活跃也会⽴刻传回尼布尔海姆。数年后，在萨菲罗斯摧毁了尼布尔海姆之后，克\\n劳德为了救蒂法，被萨菲罗斯刺⾄重伤。蒂法被她的武术教练赞⼲带到安全地带，幸存下来，\\n最终到达⽶德加并遇⻅了“雪崩”的领导⼈巴雷特· 华莱⼠。病愈后，蒂法加⼊了“雪崩”，为\\n了给家乡被毁⼀事报仇。⼀天，她在⽕⻋站遇到了从魔晄炉中逃出来、精神⼀⽚混乱的克劳\\n德，蒂法说服了他为巴雷特⼯作，以保证克劳德的安全以及和克劳德保持紧密关系。这是游戏\\n开始的地⽅。\\n在原版《最终幻想VII》中蒂法与爱丽丝关系友好，但会在某些时候争⻛吃醋，例如在神罗总\\n部营救爱丽丝时，蒂法及巴雷特等⼀⾏失⼿被擒，若克劳德选择关⼼爱丽丝的话蒂法的对话中\\n明显带有妒忌。在重制版中虽然删去这段情节，但保留了这种关系。\\n在《最终幻想VII》的初稿中，蒂法是背景⼈物。她在“雪崩”中的作⽤是在幕后⽀持，在执\\n⾏任务后为所有⼈加油⿎劲，并且对克劳德有特别的关⼼。据推测，她的背上有⼀块⼤的疤'), Document(metadata={'producer': 'macOS 版本14.1.1（版号23B81） Quartz PDFContext', 'creator': '文本编辑', 'creationdate': \"D:20231122121354Z00'00'\", 'title': '蒂法介绍', 'moddate': \"D:20231122121354Z00'00'\", 'source': './sources/loader.pdf', 'total_pages': 5, 'page': 1, 'page_label': '2'}, page_content='痕，是由克劳德造成的，并在事件发⽣时因巨⼤冲击⽽部分失忆。[4]原版策划者之⼀的加藤\\n正⼈提出了⼀个旨在暗示蒂法和克劳德发⽣性关系的场景，但被北濑佳范⽤⼀个变淡的⾊调所\\n取代。野岛⼀成在接受采访时说，没有⼀个开发团队⼈员认为当时的场景会成为⼀个问题。\\n[5]\\n《最终幻想VII补完计划》\\n2005年，蒂法出现在CG电影《最终幻想VII 降临之⼦》中，故事发⽣在原版游戏剧情结束\\n两年后。在其中，她试图给予克劳德情感上的⽀持，敦促克劳德放下他对⾃⼰施加的不必要的\\n罪恶感。此外，她还照顾巴雷特的养⼥玛琳和克劳德在爱丽丝的教堂发⻔⼝救下的孩⼦丹泽\\n尔。在电影中，她与萨菲罗斯的其中⼀个思念体罗兹战⽃，后来她帮助与被召唤的⽣物巴哈姆\\n特战⽃。编剧野岛⼀成将她在视频中的⻆⾊描述为“⾮常像任何被男⼈抛弃的⼥⼈”，并表示\\n尽管他们不希望她显得笨拙，但他们也想描绘出从她受到克劳德的情感伤害出发。[6]在视频\\n的初稿中，她原本计划在当时的短⽚中扮演更重要的⻆⾊，该短⽚仅以蒂法，克劳德和⼏个孩\\n⼦为主。\\n蒂法也在前传游戏《最终幻想VII 危机之前》和《最终幻想VII 核⼼危机》以及OVA《最终\\n幻想VII 最终命令》中登场。每次登场时，她的出现都与尼布尔海姆的毁灭有关。[2]官⽅\\n⼩说《通向微笑之路》中有专⻔的《蒂法篇》，讲述了原版游戏和降临之⼦两段之间的故事。\\n从蒂法的⻆度出发，详细讲述了她如何在Edge City创建⼀个新的第七天堂酒吧，并试图坚\\n持⾃⼰和克劳德的正常家庭观念，尽管克劳德逐渐开始逃避与他⼈接触。蒂法还短暂出现在游\\n戏《最终幻想VII 地狱⽝的挽歌》中，该游戏的剧情在降临之⼦故事⼀年后发⽣，她在游戏\\n中帮助主⻆⽂森特· 瓦伦丁捍卫星球，抵抗怪物欧⽶茄和“兵器”。她后来出现在游戏的结尾\\n中，讨论着⽂森特的失踪。[2]\\n其他登场\\n在《最终幻想VII补完计划》之外，蒂法还出现在格⽃游戏《神佑擂台》中，作为可解锁的⻆\\n⾊和可选的Boss。[7]她后来出现在电⼦棋盘游戏《富豪街》中。在《王国之⼼II》中，她\\n穿着⾃⼰在降临之⼦中的服装，寻找克劳德，然后与该系列的怪物“⽆⼼”战⽃。她原本计划\\n出现在原版《王国之⼼》的最终合辑中，但由于时间限制，⼯作⼈员选择改⽤萨菲罗斯。[8]\\n蒂法也是格⽃游戏《最终幻想 纷争012》中的玩家⻆⾊之⼀，该游戏的⻆⾊来⾃各种《最终\\n幻想》游戏。[9]她身着《最终幻想VII》中的服装，但该玩家还可以使⽤她在《降临之⼦》\\n中的服装和在尼布尔海姆出场时展示的第三种服装。[10][11]游戏的第⼀版展示内容是在天\\n野喜孝的美术原型基础上展现的另⼀种形式。[12]在《⼩⼩⼤星球2》中，蒂法是可下载的\\n⻆⾊模型。[13]\\n韩国歌⼿Ivy在2007年的歌曲“ਬ\\u0d11\\u0a44ਬ\\u0d11\\u0a44”（《诱惑奏鸣曲》）MV中描绘了⻆⾊。因为重现\\n了《降临之⼦》中的战⽃场⾯，在史克威尔艾尼克斯提出版权诉讼后，该视频被禁⽌在韩国电\\n视上播出。[14] 2015年，蒂法作为可玩⻆⾊被添加到iOS游戏《最终幻想 记录者》中。\\n[15]\\n创作与发展\\n蒂法在《最终幻想VII 核⼼危机》中的形象。\\n蒂法由野村哲也设计，最初版本的《最终幻想VII》中没有蒂法，因为最初该游戏只有三个可\\n玩⻆⾊。主⻆克劳德、爱丽丝和巴雷特。但是，在给游戏总监北濑佳范打电话时，有⼈建议游\\n戏中的某个主⻆应该死掉，在对究竟是巴雷特还是爱丽丝需要死掉进⾏⼤量讨论之后，制⽚⼈\\n选择了爱丽丝。[3]野村哲也后来开玩笑说这是他的主意，以便使他能够将蒂法引⼊游戏中。\\n[16]⽆论如何，北濑佳范喜欢有两个的⼥主⼈公，并且在他们之间摇摆不定，将其称之为是'), Document(metadata={'producer': 'macOS 版本14.1.1（版号23B81） Quartz PDFContext', 'creator': '文本编辑', 'creationdate': \"D:20231122121354Z00'00'\", 'title': '蒂法介绍', 'moddate': \"D:20231122121354Z00'00'\", 'source': './sources/loader.pdf', 'total_pages': 5, 'page': 2, 'page_label': '3'}, page_content='《最终幻想》系列中的新事物。[5]野村哲也将蒂法的⻆⾊在《降临之⼦》中的表现分为多个\\n⽅⾯，称她“像⺟亲，爱⼈，战⽃中的亲密盟友”，“不仅在情感上，⽽且在身体上也⾮常坚\\n强”。[6]\\n蒂法被设计为该系列以前的游戏中出现的“Monk”级别的⻆⾊。她有⼀头乌⿊的⻓发，像⼀头\\n海豚的尾巴，穿着简单单调的服装，包括⽩⾊的上⾐和⿊⾊的超短裙。她还穿着红⾊的靴⼦和\\n⼿套，⿊⾊的袖⼦从⼿腕延伸到肘部。她的裙⼦被⼀对狭窄的⿊⾊吊带裤撑起，⼤⾯积的⾦属\\n护罩覆盖了她的左肘。她身⾼约167厘⽶[17]，三围为92-60-88厘⽶。[4]最初，野村哲也\\n很难决定选择搭配迷你裙还是搭配⻓裤。为了征求意⻅，他在史克威尔的办公室传递了草图，\\n⼤多数⼯作⼈员都认同超短裙设计。[16]这与爱丽丝的标志形成鲜明对⽐，爱丽丝的⻓裙是\\n她的标志。服装在游戏中被解释为赋予了她⾏动⾃由的能⼒，这是由于她的近距离战⽃的亲和\\n⼒，⽽裙⼦据称“相当短，具有相当⼤的曝光度”[4]。开发者还指出，由于她的身材，她穿\\n着其他便⾐的外观也令⼈愉悦。[4]\\n在制作《最终幻想VII 降临之⼦》时，联合导演野末武志难以为蒂法的身材构建出⼀个“平\\n衡，但⼜展现了她的⼥性特质”的框架。在这⼀点上，她的服装也进⾏了重新设计，着重于表\\n达这些品质，同时仍然令⼈赏⼼悦⽬。⽩⾊背⼼覆盖⿊⾊背⼼，⽩⾊缎带背⼼包裹着她的左⼆\\n头肌，粉红丝带包裹着她的脚。⿊⾊系扣裙⼦遮盖了她的⼤腿，并且在下⾯穿了短裤，⽤⼀块\\n类似于⼤⾐的布从裙⼦的腰带后部延伸到脚踝。她不再使⽤吊带撑起裙⼦，只在电影的战⽃场\\n景中戴着⼿套。她的发型被更改为在她的背部中部结束，从原来的设计中删除了海豚的尾巴。\\n[6]造成这种变化的原因是，难以为她的原始头发设置动画效果，以及由于其⿊⾊和亮光⽽引\\n起的问题。另外，瞳孔的颜⾊亦由红⾊改为深褐⾊。\\n蒂法在《最终幻想VII 重制版》中的形象。\\n开发《最终幻想VII 重制版》时，史克威尔修改了蒂法的原始外观，以使她的外观更加逼\\n真，因为⼯作⼈员意识到她的设计不适合战⽃场景。她因此得到了⿊⾊运动内⾐并贴合她的身\\n体，给她⼀种运动的感觉。[18]在这个版本中的蒂法虽然保留着“海豚尾巴”发型，但原版中\\n其末端如海豚尾鳍已变为更⾃然的垂直模样。另外,在第三章中,玩家可选三种服饰中的⼀种\\n让蒂法在以后的篇章穿上。除了“成熟⻛”、“格⽃家⻛”及“异国⻛”外，开发团队亦考虑过\\n“⼥仆⻛”、“警察服”、“舞蹈家⻛”、“陆⾏⻦⻛”等[19]。由于克劳德与蒂法和爱丽丝之间\\n存在的特殊关系，开发团队观察到粉丝认为史克威尔更偏爱这两个⼥主⻆。以往，史克威尔表\\n示爱丽丝可能是游戏的真正主⻆，⽽蒂法对于帮助克劳德这个⻆⾊的发展很重要。最终，史克\\n威尔表示蒂法和爱丽丝都是这次重制版中的⼥主⻆。[20]\\n野村哲也表示，他喜欢⼥演员伊藤步，并希望与她在《降临之⼦》中合作。在爱丽丝的配⾳演\\n员已经决定之后，野村让伊藤步为蒂法配⾳，觉得她的“沙哑的声⾳”将与坂本真绫配⾳的轻\\n声细语的爱丽丝形成很好的对⽐。[6]野村哲也还指出，在完成蒂法的更新设计后，制⽚⼈对\\n她的最终细节进⾏了辩论，但伊藤步饰演⻆⾊后，便选择将配⾳演员的许多特征融合到⻆⾊的\\n最终形象中。[6]\\n英国配⾳演员瑞秋· 莱· 寇克（Rachael Leigh Cook）在《王国之⼼II》的⼀次采访中\\n说，她喜欢玩蒂法，并形容她“身体和情感上都很强壮，但也⾮常敏感”，并且“⾮常多维”。\\n[21]在给⻆⾊配⾳时，寇克听取了伊藤步的配⾳。在《降临之⼦》制作之后，寇克感谢野村\\n哲也所创作的视频并表示⾮常喜欢。[22]布⾥特· 巴伦（Britt Baron）代替她参加了《最\\n终幻想VII 重制版》的配⾳。[23]蒂法幼年时候由Glory Curda配⾳。[24]\\n评价\\n⾃登场以来，蒂法受到评论家和粉丝的极⼤好评。在2000年，GameSpot的读者将她评为电\\n⼦游戏中的第五好的⼥性⻆⾊，该⽹站的编辑指出他们对此表示同意。[25] 2004年，'), Document(metadata={'producer': 'macOS 版本14.1.1（版号23B81） Quartz PDFContext', 'creator': '文本编辑', 'creationdate': \"D:20231122121354Z00'00'\", 'title': '蒂法介绍', 'moddate': \"D:20231122121354Z00'00'\", 'source': './sources/loader.pdf', 'total_pages': 5, 'page': 3, 'page_label': '4'}, page_content=\"《Play》杂志在《游戏⼥孩》年度期刊的第⼀期中介绍了蒂法，并称她为“近代史上最受崇\\n拜的⼥性。”2007年，蒂法被《电击PlayStation》评为在原版PlayStation平台上有史\\n以来第⼋好的⼈物，也是《最终幻想VII》中排名第三的⻆⾊。[26]同年，Tom's \\nHardware将她列为视频游戏历史上50个最伟⼤的⼥性⻆⾊之⼀，并称她为“周围⼈物中更丰\\n富，更复杂的⼥性⻆⾊之⼀。”[27]在2008年，UGO将她列为电⼦游戏史上最伟⼤的⼥性⻆\\n⾊之⼀，排在第五位，并表示对她的偏好超过了爱丽丝，并补充说：“ 蒂法的服装是轻描淡\\n写的奇迹-但正是她的天⽣丽质和令⼈难忘的性格使她在榜单上名列前茅。”[28]同年，\\nChip杂志将她列为“游戏⼥孩”第⼗名。[29]2009年，IGN将蒂法列为游戏中⼗⼤最佳⼥主\\n⻆之⼀，并称她为“毫⽆疑问的最终幻想宇宙中的传奇⼥主⻆。”[30] Fami通在2010年进\\n⾏的⼀项⺠意调查将她评为第19⼤最受⽇本玩家欢迎的视频游戏⻆⾊。[31]在2013年，\\nComplex将她列为电⼦游戏历史上第13⼤⼥主⻆。[32]\\n2001年，随着劳拉· 克罗夫特的推出，Beaumont Enterprise列举了蒂法作为视频游戏中\\n强⼤⼥性⻆⾊的榜样。2008年，Joystiq将她列为他们希望在史克威尔艾尼克斯的跨界格⽃\\n游戏《最终幻想 纷争》中看到的《最终幻想》系列中20个⻆⾊中的佼佼者，并将她描述为该\\n系列“最伟⼤的⼥主⻆”之⼀。[33]IGN在2008年将蒂法列⼊有史以来第13部最佳的《最终\\n幻想》⻆⾊之⼀，描述她是史克威尔试图“赋予《最终幻想》⻆⾊真实的性感”的尝试，以及\\n“可以在紧要关头照顾好⾃⼰”的⼈；在后续的读者选择榜单中，蒂法排名第⼀，⼯作⼈员在\\n将其在榜单上的位置归因于她的胸部时重复了先前的评论。[34]在2009年IGN的⼀篇⽂章\\n中，仅关注《最终幻想VII》中的⻆⾊，她排在第四位，并评论说，尽管她的性感提⾼了她的\\n知名度，但“ 蒂法推动了坚强，独⽴的RPG⼥主⻆的传统。”[35]其他杂志也称赞蒂法的性\\n格特征。Mania Entertainment在2010年“了不起的视频游戏⼥性”名单中，蒂法排名第\\n⼗，并指出，虽然《最终幻想》系列的后续游戏引⼊了其他令⼈难忘的⼥性⻆⾊，但“蒂法是\\n我们的第⼀个《最终幻想》⼥孩，并在我们⼼中有特殊的地位”。[36] 2013年，\\n《Complex》的Gus Turner将蒂法列为有史以来⼗⼆⼤最终幻想⻆⾊之⼀，并指出“除了劳\\n拉和萨姆斯· 艾仁之外，蒂法也代表了游戏中最独⽴，最有能⼒的⼥性之⼀。” [37]\\n许多评论都认为蒂法⾮常性感。 1998年，《纽约时报》将她列为“⽹络⼀代”的炙⼿可热的\\n海报⼥郎。[38]同年，《电⼦游戏⽉刊》授予她1997年的“最热⻔游戏宝⻉”，称她“⽐例匀\\n称”，并称赞她是劳拉的另⼀可⾏选择。 UGO在2008年“电⼦游戏热⻔榜”中将她排在第24\\n位，并补充说他们⽆法“克服之后的每个游戏版本中她的表现都更好”。[39]同年，\\nGameDaily在“最热游戏辣妹”名单中将她排在第31位，分享了UGO对她的偏爱，并赞扬了她\\n的外表和战⽃能⼒。[40]MSN也有类似的看法，当他们将“这个充满爱⼼，关怀，超级性感的\\n⼥孩”列⼊“游戏界最热⻔的辣妹”名单中时，她名列第六，并指出她在该系列中的存在“有些\\n微妙，给与了她更像是⼀种情感上的暗示。”⽽且没有她，这个系列就不会那么特别。\\n[41]Manolith在2009年“最热⻔”⼥性视频游戏主⻆名单中将她排名第⼆。[42] 2010\\n年，VideoGamer.com将她列为“⼗⼤电⼦游戏⼥神”，[43]⽽AfterEllen的塞拉· 沃恩\\n（Sarah Warn）将她评为“第九⼤最热”⼥性电⼦游戏⻆⾊。[44]2011年，Complex将她\\n列为“游戏中最漂亮的⼥性⻆⾊”第16名，[45]⽽UGO仅因她在《神佑擂台》中的出现⽽将她\\n列为“格⽃游戏中最优秀的⼥性”中的第13位。[46]同年，GameFront将她的胸部排在“电⼦\\n游戏史上最伟⼤的胸部”名单的第九位，称她为“存在的危机版劳拉；” [47]她也被\\nVillage Voice Media列⼊“不可思议的胸部名单”，但评论说她“不仅仅具有性感。”\\n[48]2012年，Complex将她列为整体上“第⼆热⻔”视频游戏⻆⾊，[49]MSN将她列为“电\\n⼦游戏史上最热⻔的20位⼥性”之⼀，并补充说“她是历史上最著名的游戏⼥孩之⼀，并且具\\n有永恒的吸引⼒。” [50]2013年，《每⽇纪事报》的Scott Marley将她排在“最有魅⼒的\\n⼥性电⼦游戏⻆⾊”第⼆位，[51]⽽CheatCodes.com则宣布她是有史以来“最热⻔的⼥性\"), Document(metadata={'producer': 'macOS 版本14.1.1（版号23B81） Quartz PDFContext', 'creator': '文本编辑', 'creationdate': \"D:20231122121354Z00'00'\", 'title': '蒂法介绍', 'moddate': \"D:20231122121354Z00'00'\", 'source': './sources/loader.pdf', 'total_pages': 5, 'page': 4, 'page_label': '5'}, page_content='电⼦游戏⻆⾊”。[52]同样，《La NuevaEspaña》在2014年将“性感，独⽴和坚强”的蒂\\n法列为男⼥最性感的⼗⼤电⼦游戏⻆⾊中，[53]⽽《ThanhNiên》在2015年将她评为最性\\n感的⼥性电⼦游戏⻆⾊。[54]\\n姓名由来\\n蒂法（Tifa）的英⽂名字来源于⼀个古希伯来语单词“Tiferet” ，⽽姓⽒洛克哈特\\n（Lockhart）则是英语单词Lock和Hard的结合；Tiferet是⽣命之树的⼀个成分（⽣命之\\n树⼤概可以分为三⽀柱、⼗个原质、四个世界、⼆⼗⼆路径等基本结构），象征着爱情、美丽\\n和⾃我牺牲，从游戏⾥可以看出，这⼏点都符合Tifa的情况。')]\n"
     ]
    }
   ],
   "source": [
    "# loader加载pdf\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"./sources/loader.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "print(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LangChain文档转换\n",
    "- 文档切割器和按字符分割\n",
    "- 代码文档分割器\n",
    "- 按token分割文档\n",
    "- 文档总结、精炼、翻译\n",
    "  \n",
    "文档转换器原理\n",
    "1. 将文档分成小的，有意义的块（句子）\n",
    "2. 将小的块组合成一个更大的块，直到到达一定的大小\n",
    "3. 一旦到达一定的大小，接着开始创建与下一个块重叠的部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='蒂法介绍' metadata={'start_index': 1}\n",
      "page_content='蒂法·洛克哈特(日语:ティファ・ロックハート，Tifa Rokkuhāto，英语:Tifa' metadata={'start_index': 6}\n",
      "page_content='Lockhart)为电子游戏《最终幻想VII》及《最终幻想VII补完计划》相关作品中的虚构⻆' metadata={'start_index': 52}\n",
      "page_content='色，由􏰀村哲也创作和设计，此后也在多个游戏中客串登场。' metadata={'start_index': 99}\n",
      "page_content='2014年东京电玩展上，星名美津纪cosplay《最终幻想VII 降临之子》中的蒂法·洛克哈特' metadata={'start_index': 127}\n",
      "page_content='蒂法是克劳德的⻘梅竹⻢，两人同为尼布鲁海姆出身。在米德加经营作为反抗组织“雪崩”根' metadata={'start_index': 175}\n",
      "page_content='据地的酒馆“第七天堂”，并且是小有名气的招牌店员。擅⻓格斗，以拳套为武器。本传7年前' metadata={'start_index': 217}\n",
      "page_content='克劳德离开故乡从军时，曾许下约定“如果有危机时一定会保护她”。与爱丽丝相识之后，两' metadata={'start_index': 260}\n",
      "page_content='人成为好友。第一个察觉克劳德记忆混乱的人，后来协助精神崩溃的克劳德􏰁新找回真正的自' metadata={'start_index': 302}\n",
      "page_content='己。本传的大战结束后，依大家的期待在战后新生的米德加再次开设第七天堂(原第七天堂因' metadata={'start_index': 344}\n",
      "page_content='第柒区圆盘崩塌遭压毁)，同时也照顾一群受到星痕症候群折磨的孩子们。' metadata={'start_index': 386}\n",
      "page_content='蒂法被《纽约时报》称为“网络一代”的海报女郎，与劳拉·克罗夫特相比，她是电子游戏中坚' metadata={'start_index': 420}\n",
      "page_content='强、􏰂立和有吸引力的女性⻆色的典型代表。媒体普遍称赞其实力和外表，并称她为游戏世界' metadata={'start_index': 463}\n",
      "page_content='中最好的女性⻆色之一。' metadata={'start_index': 505}\n",
      "page_content='在《最终幻想VII》本传中，蒂法年龄20岁、身高167cm、生日5月3日、血型B型、出生地尼' metadata={'start_index': 517}\n",
      "page_content='布尔海姆。' metadata={'start_index': 564}\n",
      "page_content='登场' metadata={'start_index': 570}\n",
      "page_content='《最终幻想VII》' metadata={'start_index': 573}\n",
      "page_content='蒂法在《最终幻想VII》原版中首次亮相，是克劳德的⻘梅竹⻢、第七天堂酒吧的看板娘、极' metadata={'start_index': 583}\n",
      "page_content='端环境组织“雪崩”成员，该组织反抗巨型企业“神罗”因其大􏰃抽取魔晄用作动力能源。在注' metadata={'start_index': 626}\n",
      "page_content='意到克劳德的性格改变后，她说服克劳德加入雪崩，以密切关注他，并且跟随他追寻游戏中的' metadata={'start_index': 669}\n",
      "page_content='对手萨菲罗斯。她无法阻止克劳德被萨菲罗斯操纵，在他的精神崩溃后，她帮助克劳德康复，' metadata={'start_index': 711}\n",
      "page_content='并且两人意识到彼此间的相互感觉，最后与伙伴们一同击败了萨菲罗斯。[2]' metadata={'start_index': 753}\n",
      "page_content='在闪回中可知，儿时的蒂法一直是村中小孩的人气王。在母亲过世后，思念母亲的蒂法决定沿' metadata={'start_index': 789}\n",
      "page_content='着小路走到他们故乡尼布尔海姆附近的一座山上，认为这样就能⻅到过世的母亲，原本跟着蒂' metadata={'start_index': 831}\n",
      "page_content='法的其他小孩都在半路上因害怕而放弃，唯􏰂克劳德仍坚定的在后面跟随，希望能在危机时保' metadata={'start_index': 873}\n",
      "page_content='护蒂法。然而，他们俩都从山上跌落受伤，蒂法昏迷了一个星期，她的父亲认为克劳德对此负' metadata={'start_index': 915}\n",
      "page_content='有责任[3]，甚为严令禁止克劳德再接近蒂法，但蒂法反而从此更在意克劳德，两人成为要好' metadata={'start_index': 957}\n",
      "page_content='的玩伴。为了使自己变得更强大，克劳德最终选择离开尼布尔海姆，加入神罗，想要成为神罗' metadata={'start_index': 1000}\n",
      "page_content='的精英战士“神罗战士”(SOLDIER)，但后来透露他主要是为了吸引蒂法的注意力。离开之' metadata={'start_index': 1042}\n",
      "page_content='前，蒂法与克劳德约定，当蒂法处于困境之中时，克劳德会回来救她。从克劳德离开之后，蒂' metadata={'start_index': 1087}\n",
      "page_content='法便开始留意神罗战士的消息，因为神罗战士都成为声名远播的知名人物，如果克劳德成为神' metadata={'start_index': 1129}\n",
      "page_content='罗战士，他的活跃也会立刻传回尼布尔海姆。数年后，在萨菲罗斯摧毁了尼布尔海姆之后，克' metadata={'start_index': 1171}\n",
      "page_content='劳德为了救蒂法，被萨菲罗斯刺至􏰁伤。蒂法被她的武术教练赞干带到安全地带，幸存下来，' metadata={'start_index': 1213}\n",
      "page_content='最终到达米德加并遇⻅了“雪崩”的领导人巴雷特·华莱士。病愈后，蒂法加入了“雪崩”，为' metadata={'start_index': 1255}\n",
      "page_content='了给家乡被毁一事报仇。一天，她在火⻋站遇到了从魔晄炉中逃出来、精神一片混乱的克劳' metadata={'start_index': 1298}\n",
      "page_content='德，蒂法说服了他为巴雷特工作，以保证克劳德的安全以及和克劳德保持紧密关系。这是游戏 开始的地方。' metadata={'start_index': 1339}\n",
      "page_content='开始的地方。 在原版《最终幻想VII》中蒂法与爱丽丝关系友好，但会在某些时候争⻛吃醋，例如在神罗总' metadata={'start_index': 1381}\n",
      "page_content='部营救爱丽丝时，蒂法及巴雷特等一行失手被擒，若克劳德选择关心爱丽丝的话蒂法的对话中' metadata={'start_index': 1431}\n",
      "page_content='明显带有妒忌。在􏰁制版中虽然删去这段情节，但保留了这种关系。' metadata={'start_index': 1473}\n",
      "page_content='在《最终幻想VII》的初稿中，蒂法是背景人物。她在“雪崩”中的作用是在幕后支持，在执' metadata={'start_index': 1504}\n",
      "page_content='行任务后为所有人加油鼓劲，并且对克劳德有特别的关心。据推测，她的背上有一块大的疤' metadata={'start_index': 1547}\n",
      "page_content='痕，是由克劳德造成的，并在事件发生时因巨大冲击而部分失忆。[4]原版策划者之一的加藤' metadata={'start_index': 1590}\n",
      "page_content='正人提出了一个旨在暗示蒂法和克劳德发生性关系的场景，但被北濑佳范用一个变淡的色调所' metadata={'start_index': 1633}\n",
      "page_content='取代。􏰀岛一成在接受采访时说，没有一个开发团队人员认为当时的场景会成为一个问题。 [5]' metadata={'start_index': 1675}\n",
      "page_content='《最终幻想VII补完计划》' metadata={'start_index': 1720}\n",
      "page_content='2005年，蒂法出现在CG电影《最终幻想VII 降临之子》中，故事发生在原版游戏剧情结束' metadata={'start_index': 1734}\n",
      "page_content='两年后。在其中，她试图给予克劳德情感上的支持，敦促克劳德放下他对自己施加的不必要的' metadata={'start_index': 1779}\n",
      "page_content='罪恶感。此外，她还照顾巴雷特的养女玛琳和克劳德在爱丽丝的教堂发⻔口救下的孩子丹泽' metadata={'start_index': 1821}\n",
      "page_content='尔。在电影中，她与萨菲罗斯的其中一个思念体罗兹战斗，后来她帮助与被召唤的生物巴哈姆' metadata={'start_index': 1862}\n",
      "page_content='特战斗。编剧􏰀岛一成将她在视频中的⻆色描述为“非常像任何被男人抛弃的女人”，并表示' metadata={'start_index': 1904}\n",
      "page_content='尽管他们不希望她显得笨拙，但他们也想描绘出从她受到克劳德的情感伤害出发。[6]在视频' metadata={'start_index': 1946}\n",
      "page_content='的初稿中，她原本计划在当时的短片中扮演更􏰁要的⻆色，该短片仅以蒂法，克劳德和几个孩 子为主。' metadata={'start_index': 1989}\n",
      "page_content='蒂法也在前传游戏《最终幻想VII 危机之前》和《最终幻想VII 核心危机》以及OVA《最终' metadata={'start_index': 2036}\n",
      "page_content='核心危机》以及OVA《最终 幻想VII' metadata={'start_index': 2068}\n",
      "page_content='幻想VII 最终命令》中登场。每次登场时，她的出现都与尼布尔海姆的毁灭有关。[2]官方' metadata={'start_index': 2082}\n",
      "page_content='小说《通向微笑之路》中有专⻔的《蒂法篇》，讲述了原版游戏和降临之子两段之间的故事。' metadata={'start_index': 2126}\n",
      "page_content='从蒂法的⻆度出发，详细讲述了她如何在Edge City创建一个新的第七天堂酒吧，并试图坚' metadata={'start_index': 2168}\n",
      "page_content='持自己和克劳德的正常家庭观念，尽管克劳德逐渐开始逃避与他人接触。蒂法还短暂出现在游' metadata={'start_index': 2213}\n",
      "page_content='戏《最终幻想VII 地狱犬的挽歌》中，该游戏的剧情在降临之子故事一年后发生，她在游戏' metadata={'start_index': 2255}\n",
      "page_content='中帮助主⻆文森特·瓦伦丁捍卫星球，抵抗怪物欧米茄和“兵器”。她后来出现在游戏的结尾' metadata={'start_index': 2298}\n",
      "page_content='中，讨论着文森特的失踪。[2]' metadata={'start_index': 2340}\n",
      "page_content='其他登场 在《最终幻想VII补完计划》之外，蒂法还出现在格斗游戏《神佑擂台》中，作为可解锁的⻆' metadata={'start_index': 2356}\n",
      "page_content='色和可选的Boss。[7]她后来出现在电子棋盘游戏《富豪街》中。在《王国之心II》中，她' metadata={'start_index': 2404}\n",
      "page_content='穿着自己在降临之子中的服装，寻找克劳德，然后与该系列的怪物“无心”战斗。她原本计划' metadata={'start_index': 2449}\n",
      "page_content='出现在原版《王国之心》的最终合辑中，但由于时间限制，工作人员选择改用萨菲罗斯。[8]' metadata={'start_index': 2491}\n",
      "page_content='蒂法也是格斗游戏《最终幻想 纷争012》中的玩家⻆色之一，该游戏的⻆色来自各种《最终' metadata={'start_index': 2534}\n",
      "page_content='幻想》游戏。[9]她身着《最终幻想VII》中的服装，但该玩家还可以使用她在《降临之子》' metadata={'start_index': 2577}\n",
      "page_content='中的服装和在尼布尔海姆出场时展示的第三种服装。[10][11]游戏的第一版展示内容是在天' metadata={'start_index': 2621}\n",
      "page_content='􏰀喜孝的美术原型基础上展现的另一种形式。[12]在《小小大星球2》中，蒂法是可下载的' metadata={'start_index': 2666}\n",
      "page_content='⻆色模型。[13]' metadata={'start_index': 2709}\n",
      "page_content='韩国歌手Ivy在2007年的歌曲“유혹의유혹의”(《诱惑奏鸣曲》)MV中描绘了⻆色。因为􏰁现' metadata={'start_index': 2719}\n",
      "page_content='了《降临之子》中的战斗场面，在史克威尔艾尼克斯提出版权诉讼后，该视频被禁止在韩国电' metadata={'start_index': 2766}\n",
      "page_content='视上播出。[14] 2015年，蒂法作为可玩⻆色被添加到iOS游戏《最终幻想 记录者》中。' metadata={'start_index': 2808}\n",
      "page_content='记录者》中。 [15]' metadata={'start_index': 2847}\n"
     ]
    }
   ],
   "source": [
    "### 递归地按字符分割文本，并尝试保持语义完整性。\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 加载要切分的文档\n",
    "with open(file=\"./sources/test.txt\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=50, # 切分的文本块大小，一般通过长度函数计算\n",
    "    chunk_overlap=20, # 表示相邻文本块之间的重叠部分长度，一般通过长度函数计算\n",
    "    length_function=len, # 计算文本块的长度函数，也可以传递tokenize函数\n",
    "    add_start_index=True, # 是否在元数据中包含每个块的起始索引\n",
    ")\n",
    "\n",
    "documents = text_splitter.create_documents([text])\n",
    "for text in documents:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 125, which is longer than the specified 50\n",
      "Created a chunk of size 72, which is longer than the specified 50\n",
      "Created a chunk of size 72, which is longer than the specified 50\n",
      "Created a chunk of size 63, which is longer than the specified 50\n",
      "Created a chunk of size 52, which is longer than the specified 50\n",
      "Created a chunk of size 96, which is longer than the specified 50\n",
      "Created a chunk of size 51, which is longer than the specified 50\n",
      "Created a chunk of size 66, which is longer than the specified 50\n",
      "Created a chunk of size 105, which is longer than the specified 50\n",
      "Created a chunk of size 84, which is longer than the specified 50\n",
      "Created a chunk of size 78, which is longer than the specified 50\n",
      "Created a chunk of size 72, which is longer than the specified 50\n",
      "Created a chunk of size 66, which is longer than the specified 50\n",
      "Created a chunk of size 92, which is longer than the specified 50\n",
      "Created a chunk of size 58, which is longer than the specified 50\n",
      "Created a chunk of size 67, which is longer than the specified 50\n",
      "Created a chunk of size 73, which is longer than the specified 50\n",
      "Created a chunk of size 52, which is longer than the specified 50\n",
      "Created a chunk of size 61, which is longer than the specified 50\n",
      "Created a chunk of size 77, which is longer than the specified 50\n",
      "Created a chunk of size 82, which is longer than the specified 50\n",
      "Created a chunk of size 61, which is longer than the specified 50\n",
      "Created a chunk of size 52, which is longer than the specified 50\n",
      "Created a chunk of size 60, which is longer than the specified 50\n",
      "Created a chunk of size 51, which is longer than the specified 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='蒂法介绍\n",
      "蒂法·洛克哈特(日语:ティファ・ロックハート，Tifa Rokkuhāto，英语:Tifa Lockhart)为电子游戏《最终幻想VII》及《最终幻想VII补完计划》相关作品中的虚构⻆ 色，由􏰀村哲也创作和设计，此后也在多个游戏中客串登场' metadata={'start_index': 1}\n",
      "page_content='2014年东京电玩展上，星名美津纪cosplay《最终幻想VII 降临之子》中的蒂法·洛克哈特 蒂法是克劳德的⻘梅竹⻢，两人同为尼布鲁海姆出身' metadata={'start_index': 127}\n",
      "page_content='在米德加经营作为反抗组织“雪崩”根 据地的酒馆“第七天堂”，并且是小有名气的招牌店员' metadata={'start_index': 199}\n",
      "page_content='擅⻓格斗，以拳套为武器。本传7年前 克劳德离开故乡从军时，曾许下约定“如果有危机时一定会保护她”' metadata={'start_index': 242}\n",
      "page_content='与爱丽丝相识之后，两 人成为好友' metadata={'start_index': 291}\n",
      "page_content='第一个察觉克劳德记忆混乱的人，后来协助精神崩溃的克劳德􏰁新找回真正的自 己' metadata={'start_index': 308}\n",
      "page_content='本传的大战结束后，依大家的期待在战后新生的米德加再次开设第七天堂(原第七天堂因 第柒区圆盘崩塌遭压毁)，同时也照顾一群受到星痕症候群折磨的孩子们' metadata={'start_index': 346}\n",
      "page_content='蒂法被《纽约时报》称为“网络一代”的海报女郎，与劳拉·克罗夫特相比，她是电子游戏中坚 强、􏰂立和有吸引力的女性⻆色的典型代表' metadata={'start_index': 420}\n",
      "page_content='媒体普遍称赞其实力和外表，并称她为游戏世界 中最好的女性⻆色之一' metadata={'start_index': 483}\n",
      "page_content='在《最终幻想VII》本传中，蒂法年龄20岁、身高167cm、生日5月3日、血型B型、出生地尼 布尔海姆' metadata={'start_index': 517}\n",
      "page_content='登场\n",
      "《最终幻想VII》 蒂法在《最终幻想VII》原版中首次亮相，是克劳德的⻘梅竹⻢、第七天堂酒吧的看板娘、极 端环境组织“雪崩”成员，该组织反抗巨型企业“神罗”因其大􏰃抽取魔晄用作动力能源' metadata={'start_index': 570}\n",
      "page_content='在注 意到克劳德的性格改变后，她说服克劳德加入雪崩，以密切关注他，并且跟随他追寻游戏中的 对手萨菲罗斯' metadata={'start_index': 666}\n",
      "page_content='她无法阻止克劳德被萨菲罗斯操纵，在他的精神崩溃后，她帮助克劳德康复， 并且两人意识到彼此间的相互感觉，最后与伙伴们一同击败了萨菲罗斯' metadata={'start_index': 718}\n",
      "page_content='[2] 在闪回中可知，儿时的蒂法一直是村中小孩的人气王' metadata={'start_index': 785}\n",
      "page_content='在母亲过世后，思念母亲的蒂法决定沿 着小路走到他们故乡尼布尔海姆附近的一座山上，认为这样就能⻅到过世的母亲，原本跟着蒂 法的其他小孩都在半路上因害怕而放弃，唯􏰂克劳德仍坚定的在后面跟随，希望能在危机时保 护蒂法' metadata={'start_index': 813}\n",
      "page_content='然而，他们俩都从山上跌落受伤，蒂法昏迷了一个星期，她的父亲认为克劳德对此负 有责任[3]，甚为严令禁止克劳德再接近蒂法，但蒂法反而从此更在意克劳德，两人成为要好 的玩伴' metadata={'start_index': 919}\n",
      "page_content='为了使自己变得更强大，克劳德最终选择离开尼布尔海姆，加入神罗，想要成为神罗 的精英战士“神罗战士”(SOLDIER)，但后来透露他主要是为了吸引蒂法的注意力' metadata={'start_index': 1004}\n",
      "page_content='离开之 前，蒂法与克劳德约定，当蒂法处于困境之中时，克劳德会回来救她' metadata={'start_index': 1083}\n",
      "page_content='从克劳德离开之后，蒂 法便开始留意神罗战士的消息，因为神罗战士都成为声名远播的知名人物，如果克劳德成为神 罗战士，他的活跃也会立刻传回尼布尔海姆' metadata={'start_index': 1118}\n",
      "page_content='数年后，在萨菲罗斯摧毁了尼布尔海姆之后，克 劳德为了救蒂法，被萨菲罗斯刺至􏰁伤' metadata={'start_index': 1191}\n",
      "page_content='蒂法被她的武术教练赞干带到安全地带，幸存下来， 最终到达米德加并遇⻅了“雪崩”的领导人巴雷特·华莱士' metadata={'start_index': 1231}\n",
      "page_content='病愈后，蒂法加入了“雪崩”，为 了给家乡被毁一事报仇' metadata={'start_index': 1282}\n",
      "page_content='一天，她在火⻋站遇到了从魔晄炉中逃出来、精神一片混乱的克劳 德，蒂法说服了他为巴雷特工作，以保证克劳德的安全以及和克劳德保持紧密关系' metadata={'start_index': 1309}\n",
      "page_content='这是游戏 开始的地方' metadata={'start_index': 1376}\n",
      "page_content='在原版《最终幻想VII》中蒂法与爱丽丝关系友好，但会在某些时候争⻛吃醋，例如在神罗总 部营救爱丽丝时，蒂法及巴雷特等一行失手被擒，若克劳德选择关心爱丽丝的话蒂法的对话中 明显带有妒忌' metadata={'start_index': 1388}\n",
      "page_content='在􏰁制版中虽然删去这段情节，但保留了这种关系。 在《最终幻想VII》的初稿中，蒂法是背景人物' metadata={'start_index': 1480}\n",
      "page_content='她在“雪崩”中的作用是在幕后支持，在执 行任务后为所有人加油鼓劲，并且对克劳德有特别的关心' metadata={'start_index': 1527}\n",
      "page_content='据推测，她的背上有一块大的疤\n",
      "\n",
      " 痕，是由克劳德造成的，并在事件发生时因巨大冲击而部分失忆' metadata={'start_index': 1573}\n",
      "page_content='[4]原版策划者之一的加藤 正人提出了一个旨在暗示蒂法和克劳德发生性关系的场景，但被北濑佳范用一个变淡的色调所 取代' metadata={'start_index': 1619}\n",
      "page_content='􏰀岛一成在接受采访时说，没有一个开发团队人员认为当时的场景会成为一个问题' metadata={'start_index': 1678}\n",
      "page_content='[5]\n",
      "《最终幻想VII补完计划》\n",
      "2005年，蒂法出现在CG电影《最终幻想VII 降临之子》中，故事发生在原版游戏剧情结束 两年后' metadata={'start_index': 1716}\n",
      "page_content='在其中，她试图给予克劳德情感上的支持，敦促克劳德放下他对自己施加的不必要的 罪恶感' metadata={'start_index': 1783}\n",
      "page_content='此外，她还照顾巴雷特的养女玛琳和克劳德在爱丽丝的教堂发⻔口救下的孩子丹泽 尔' metadata={'start_index': 1825}\n",
      "page_content='在电影中，她与萨菲罗斯的其中一个思念体罗兹战斗，后来她帮助与被召唤的生物巴哈姆 特战斗' metadata={'start_index': 1864}\n",
      "page_content='编剧􏰀岛一成将她在视频中的⻆色描述为“非常像任何被男人抛弃的女人”，并表示 尽管他们不希望她显得笨拙，但他们也想描绘出从她受到克劳德的情感伤害出发' metadata={'start_index': 1908}\n",
      "page_content='[6]在视频 的初稿中，她原本计划在当时的短片中扮演更􏰁要的⻆色，该短片仅以蒂法，克劳德和几个孩 子为主' metadata={'start_index': 1982}\n",
      "page_content='蒂法也在前传游戏《最终幻想VII 危机之前》和《最终幻想VII 核心危机》以及OVA《最终 幻想VII 最终命令》中登场' metadata={'start_index': 2036}\n",
      "page_content='每次登场时，她的出现都与尼布尔海姆的毁灭有关' metadata={'start_index': 2097}\n",
      "page_content='[2]官方 小说《通向微笑之路》中有专⻔的《蒂法篇》，讲述了原版游戏和降临之子两段之间的故事' metadata={'start_index': 2120}\n",
      "page_content='从蒂法的⻆度出发，详细讲述了她如何在Edge City创建一个新的第七天堂酒吧，并试图坚 持自己和克劳德的正常家庭观念，尽管克劳德逐渐开始逃避与他人接触' metadata={'start_index': 2168}\n",
      "page_content='蒂法还短暂出现在游 戏《最终幻想VII 地狱犬的挽歌》中，该游戏的剧情在降临之子故事一年后发生，她在游戏 中帮助主⻆文森特·瓦伦丁捍卫星球，抵抗怪物欧米茄和“兵器”' metadata={'start_index': 2245}\n",
      "page_content='她后来出现在游戏的结尾 中，讨论着文森特的失踪' metadata={'start_index': 2328}\n",
      "page_content='[2]\n",
      "其他登场 在《最终幻想VII补完计划》之外，蒂法还出现在格斗游戏《神佑擂台》中，作为可解锁的⻆ 色和可选的Boss' metadata={'start_index': 2352}\n",
      "page_content='[7]她后来出现在电子棋盘游戏《富豪街》中' metadata={'start_index': 2414}\n",
      "page_content='在《王国之心II》中，她 穿着自己在降临之子中的服装，寻找克劳德，然后与该系列的怪物“无心”战斗' metadata={'start_index': 2436}\n",
      "page_content='她原本计划 出现在原版《王国之心》的最终合辑中，但由于时间限制，工作人员选择改用萨菲罗斯' metadata={'start_index': 2485}\n",
      "page_content='[8] 蒂法也是格斗游戏《最终幻想 纷争012》中的玩家⻆色之一，该游戏的⻆色来自各种《最终 幻想》游戏' metadata={'start_index': 2530}\n",
      "page_content='[9]她身着《最终幻想VII》中的服装，但该玩家还可以使用她在《降临之子》 中的服装和在尼布尔海姆出场时展示的第三种服装' metadata={'start_index': 2583}\n",
      "page_content='[10][11]游戏的第一版展示内容是在天 􏰀喜孝的美术原型基础上展现的另一种形式' metadata={'start_index': 2644}\n",
      "page_content='[12]在《小小大星球2》中，蒂法是可下载的 ⻆色模型' metadata={'start_index': 2686}\n",
      "page_content='[13] 韩国歌手Ivy在2007年的歌曲“유혹의유혹의”(《诱惑奏鸣曲》)MV中描绘了⻆色' metadata={'start_index': 2714}\n",
      "page_content='因为􏰁现 了《降临之子》中的战斗场面，在史克威尔艾尼克斯提出版权诉讼后，该视频被禁止在韩国电 视上播出' metadata={'start_index': 2761}\n",
      "page_content='[14] 2015年，蒂法作为可玩⻆色被添加到iOS游戏《最终幻想 记录者》中。 [15]' metadata={'start_index': 2813}\n"
     ]
    }
   ],
   "source": [
    "# 按字符分割文本\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# 加载要切分的文档\n",
    "with open(file=\"./sources/test.txt\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"。\", # 切割的标识字符，默认是\"\\n\\n\"\n",
    "    chunk_size=50, # 切分的每个文本块的最大长度（以字符数为单位）\n",
    "    chunk_overlap=20, # 切分的文本相邻块之间的重叠部分长度\n",
    "    length_function=len, # 长度函数，也可以传递tokenize函数\n",
    "    add_start_index=True, # 是否添加开始索引\n",
    "    is_separator_regex=False, # 是否使用正则表达式\n",
    ")\n",
    "\n",
    "documents = text_splitter.create_documents([text])\n",
    "for text in documents:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={}, page_content='def hello_world():\\n    print(\"hello world\")'), Document(metadata={}, page_content='# 调用函数\\nhello_world()')]\n",
      "page_content='def hello_world():\n",
      "    print(\"hello world\")'\n",
      "page_content='# 调用函数\n",
      "hello_world()'\n"
     ]
    }
   ],
   "source": [
    "# 代码文档切割\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, Language\n",
    "\n",
    "# 支持解析的编程语言\n",
    "# [print(e.value) for e in Language]\n",
    "\n",
    "# 要切割的代码文档示例\n",
    "PYTHON_CODE = \"\"\"\n",
    "def hello_world():\n",
    "    print(\"hello world\")\n",
    "\n",
    "# 调用函数\n",
    "hello_world()\n",
    "\"\"\"\n",
    "\n",
    "py_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON,\n",
    "    chunk_size=50,\n",
    "    chunk_overlap=10,\n",
    ")\n",
    "\n",
    "python_docs = py_splitter.create_documents([PYTHON_CODE])\n",
    "print(python_docs)\n",
    "for docs in python_docs:\n",
    "    print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={}, page_content='蒂法介绍\\n蒂法·洛克哈特(日语:ティファ・ロックハート，Tifa Rokkuhāto，英语:Tifa Lockhart)为电子游戏《最终幻想VII》及《最终幻想VII补完计划》相关作品中的虚构⻆ 色，由\\U0010fc00村哲也创作和设计，此后也在多个游戏中客串登场。 2014年东京电玩展上，星名美津纪cosplay《最终幻想VII 降临之子》中的蒂法·洛克哈特 蒂法是克劳德的⻘梅竹⻢，两人同为尼布鲁海姆出身。在米德加经营作为反抗组织“雪崩”根 据地的酒馆“第七天堂”，并且是小有名气的招牌店员。擅⻓格斗，以拳套为武器。本传7年前 克劳德离开故乡从军时，曾许下约定“如果有危机时一定会保护她”。与爱丽丝相识之后，两 人成为好友。第一个察觉克劳德记忆混乱的人，后来协助精神崩溃的克劳德\\U0010fc01新找回真正的自 己。本传的大战结束后，依大家的期待在战后新生的米德加再次开设第七天堂(原第七天堂因 第柒区圆盘崩塌遭压毁)，同时也照顾一群受到星痕症候群折磨的孩子们。 蒂法被《纽约时报》称为“网络一代”的海报女郎，与劳拉·克罗夫特相比，她是电子游戏中坚 强、\\U0010fc02立和有吸引力的女性⻆色的典型代表。媒体普遍称赞其实力和外表，并称她为游戏世界 中最好的女性⻆色之一。 在《最终幻想VII》本传中，蒂法年龄20岁、身高167cm、生日5月3日、血型B型、出生地尼 布尔海姆。\\n登场\\n《最终幻想VII》 蒂法在《最终幻想VII》原版中首次亮相，是克劳德的⻘梅竹⻢、第七天堂酒吧的看板娘、极 端环境组织“雪崩”成员，该组织反抗巨型企业“神罗”因其大\\U0010fc03抽取魔晄用作动力能源。在注 意到克劳德的性格改变后，她说服克劳德加入雪崩，以密切关注他，并且跟随他追寻游戏中的 对手萨菲罗斯。她无法阻止克劳德被萨菲罗斯操纵，在他的精神崩溃后，她帮助克劳德康复， 并且两人意识到彼此间的相互感觉，最后与伙伴们一同击败了萨菲罗斯。[2] 在闪回中可知，儿时的蒂法一直是村中小孩的人气王。在母亲过世后，思念母亲的蒂法决定沿 着小路走到他们故乡尼布尔海姆附近的一座山上，认为这样就能⻅到过世的母亲，原本跟着蒂 法的其他小孩都在半路上因害怕而放弃，唯\\U0010fc02克劳德仍坚定的在后面跟随，希望能在危机时保 护蒂法。然而，他们俩都从山上跌落受伤，蒂法昏迷了一个星期，她的父亲认为克劳德对此负 有责任[3]，甚为严令禁止克劳德再接近蒂法，但蒂法反而从此更在意克劳德，两人成为要好 的玩伴。为了使自己变得更强大，克劳德最终选择离开尼布尔海姆，加入神罗，想要成为神罗 的精英战士“神罗战士”(SOLDIER)，但后来透露他主要是为了吸引蒂法的注意力。离开之 前，蒂法与克劳德约定，当蒂法处于困境之中时，克劳德会回来救她。从克劳德离开之后，蒂 法便开始留意神罗战士的消息，因为神罗战士都成为声名远播的知名人物，如果克劳德成为神 罗战士，他的活跃也会立刻传回尼布尔海姆。数年后，在萨菲罗斯摧毁了尼布尔海姆之后，克 劳德为了救蒂法，被萨菲罗斯刺至\\U0010fc01伤。蒂法被她的武术教练赞干带到安全地带，幸存下来， 最终到达米德加并遇⻅了“雪崩”的领导人巴雷特·华莱士。病愈后，蒂法加入了“雪崩”，为 了给家乡被毁一事报仇。一天，她在火⻋站遇到了从魔晄炉中逃出来、精神一片混乱的克劳 德，蒂法说服了他为巴雷特工作，以保证克劳德的安全以及和克劳德保持紧密关系。这是游戏 开始的地方。 在原版《最终幻想VII》中蒂法与爱丽丝关系友好，但会在某些时候争⻛吃醋，例如在神罗总 部营救爱丽丝时，蒂法及巴雷特等一行失手被擒，若克劳德选择关心爱丽丝的话蒂法的对话中 明显带有妒忌。在\\U0010fc01制版中虽然删去这段情节，但保留了这种关系。 在《最终幻想VII》的初稿中，蒂法是背景人物。她在“雪崩”中的作用是在幕后支持，在执 行任务后为所有人加油鼓劲，并且对克劳德有特别的关心。据推测，她的背上有一块大的疤'), Document(metadata={}, page_content='痕，是由克劳德造成的，并在事件发生时因巨大冲击而部分失忆。[4]原版策划者之一的加藤 正人提出了一个旨在暗示蒂法和克劳德发生性关系的场景，但被北濑佳范用一个变淡的色调所 取代。\\U0010fc00岛一成在接受采访时说，没有一个开发团队人员认为当时的场景会成为一个问题。 [5]\\n《最终幻想VII补完计划》\\n2005年，蒂法出现在CG电影《最终幻想VII 降临之子》中，故事发生在原版游戏剧情结束 两年后。在其中，她试图给予克劳德情感上的支持，敦促克劳德放下他对自己施加的不必要的 罪恶感。此外，她还照顾巴雷特的养女玛琳和克劳德在爱丽丝的教堂发⻔口救下的孩子丹泽 尔。在电影中，她与萨菲罗斯的其中一个思念体罗兹战斗，后来她帮助与被召唤的生物巴哈姆 特战斗。编剧\\U0010fc00岛一成将她在视频中的⻆色描述为“非常像任何被男人抛弃的女人”，并表示 尽管他们不希望她显得笨拙，但他们也想描绘出从她受到克劳德的情感伤害出发。[6]在视频 的初稿中，她原本计划在当时的短片中扮演更\\U0010fc01要的⻆色，该短片仅以蒂法，克劳德和几个孩 子为主。\\n蒂法也在前传游戏《最终幻想VII 危机之前》和《最终幻想VII 核心危机》以及OVA《最终 幻想VII 最终命令》中登场。每次登场时，她的出现都与尼布尔海姆的毁灭有关。[2]官方 小说《通向微笑之路》中有专⻔的《蒂法篇》，讲述了原版游戏和降临之子两段之间的故事。 从蒂法的⻆度出发，详细讲述了她如何在Edge City创建一个新的第七天堂酒吧，并试图坚 持自己和克劳德的正常家庭观念，尽管克劳德逐渐开始逃避与他人接触。蒂法还短暂出现在游 戏《最终幻想VII 地狱犬的挽歌》中，该游戏的剧情在降临之子故事一年后发生，她在游戏 中帮助主⻆文森特·瓦伦丁捍卫星球，抵抗怪物欧米茄和“兵器”。她后来出现在游戏的结尾 中，讨论着文森特的失踪。[2]\\n其他登场 在《最终幻想VII补完计划》之外，蒂法还出现在格斗游戏《神佑擂台》中，作为可解锁的⻆ 色和可选的Boss。[7]她后来出现在电子棋盘游戏《富豪街》中。在《王国之心II》中，她 穿着自己在降临之子中的服装，寻找克劳德，然后与该系列的怪物“无心”战斗。她原本计划 出现在原版《王国之心》的最终合辑中，但由于时间限制，工作人员选择改用萨菲罗斯。[8] 蒂法也是格斗游戏《最终幻想 纷争012》中的玩家⻆色之一，该游戏的⻆色来自各种《最终 幻想》游戏。[9]她身着《最终幻想VII》中的服装，但该玩家还可以使用她在《降临之子》 中的服装和在尼布尔海姆出场时展示的第三种服装。[10][11]游戏的第一版展示内容是在天 \\U0010fc00喜孝的美术原型基础上展现的另一种形式。[12]在《小小大星球2》中，蒂法是可下载的 ⻆色模型。[13] 韩国歌手Ivy在2007年的歌曲“유혹의유혹의”(《诱惑奏鸣曲》)MV中描绘了⻆色。因为\\U0010fc01现 了《降临之子》中的战斗场面，在史克威尔艾尼克斯提出版权诉讼后，该视频被禁止在韩国电 视上播出。[14] 2015年，蒂法作为可玩⻆色被添加到iOS游戏《最终幻想 记录者》中。 [15]')]\n"
     ]
    }
   ],
   "source": [
    "# 按token来分割文档\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# 加载要切分的文档\n",
    "with open(file=\"./sources/test.txt\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=4000, # 切分的每个文本块的最大长度（以字符数为单位）\n",
    "    chunk_overlap=30, # 切分的文本相邻块之间的重叠部分长度\n",
    ")\n",
    "\n",
    "documents = text_splitter.create_documents([text])\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 文档的总结、精炼、翻译\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting doctran\n",
      "  Downloading doctran-0.0.14-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting lxml<5.0.0,>=4.9.2 (from doctran)\n",
      "  Downloading lxml-4.9.4.tar.gz (3.6 MB)\n",
      "     ---------------------------------------- 0.0/3.6 MB ? eta -:--:--\n",
      "     ----- ---------------------------------- 0.5/3.6 MB 3.2 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 1.6/3.6 MB 4.3 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 2.6/3.6 MB 4.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 3.6/3.6 MB 5.0 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting openai<0.28.0,>=0.27.8 (from doctran)\n",
      "  Downloading openai-0.27.10-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting presidio-analyzer<3.0.0,>=2.2.33 (from doctran)\n",
      "  Downloading presidio_analyzer-2.2.357-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting presidio-anonymizer<3.0.0,>=2.2.33 (from doctran)\n",
      "  Downloading presidio_anonymizer-2.2.357-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting pydantic<2.0.0,>=1.10.9 (from doctran)\n",
      "  Downloading pydantic-1.10.21-cp313-cp313-win_amd64.whl.metadata (155 kB)\n",
      "Collecting spacy<4.0.0,>=3.5.4 (from doctran)\n",
      "  Downloading spacy-3.8.2.tar.gz (1.3 MB)\n",
      "     ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "     ---------------------------------------- 1.3/1.3 MB 9.3 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × pip subprocess to install build dependencies did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [571 lines of output]\n",
      "      Ignoring numpy: markers 'python_version < \"3.9\"' don't match your environment\n",
      "      Collecting setuptools\n",
      "        Using cached setuptools-76.0.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "      Collecting cython<3.0,>=0.25\n",
      "        Downloading Cython-0.29.37-py2.py3-none-any.whl.metadata (3.1 kB)\n",
      "      Collecting cymem<2.1.0,>=2.0.2\n",
      "        Downloading cymem-2.0.11-cp313-cp313-win_amd64.whl.metadata (8.8 kB)\n",
      "      Collecting preshed<3.1.0,>=3.0.2\n",
      "        Downloading preshed-3.0.9.tar.gz (14 kB)\n",
      "        Installing build dependencies: started\n",
      "        Installing build dependencies: finished with status 'done'\n",
      "        Getting requirements to build wheel: started\n",
      "        Getting requirements to build wheel: finished with status 'done'\n",
      "        Preparing metadata (pyproject.toml): started\n",
      "        Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "      Collecting murmurhash<1.1.0,>=0.28.0\n",
      "        Using cached murmurhash-1.0.12-cp313-cp313-win_amd64.whl.metadata (2.2 kB)\n",
      "      Collecting thinc<8.4.0,>=8.3.0\n",
      "        Downloading thinc-8.3.2.tar.gz (193 kB)\n",
      "        Installing build dependencies: started\n",
      "        Installing build dependencies: still running...\n",
      "        Installing build dependencies: still running...\n",
      "        Installing build dependencies: still running...\n",
      "        Installing build dependencies: still running...\n",
      "        Installing build dependencies: still running...\n",
      "        Installing build dependencies: still running...\n",
      "        Installing build dependencies: still running...\n",
      "        Installing build dependencies: still running...\n",
      "        Installing build dependencies: still running...\n",
      "        Installing build dependencies: still running...\n",
      "        Installing build dependencies: still running...\n",
      "        Installing build dependencies: still running...\n",
      "        Installing build dependencies: still running...\n",
      "        Installing build dependencies: still running...\n",
      "        Installing build dependencies: still running...\n",
      "        Installing build dependencies: still running...\n",
      "        Installing build dependencies: still running...\n",
      "        Installing build dependencies: still running...\n",
      "        Installing build dependencies: still running...\n",
      "        Installing build dependencies: still running...\n",
      "        Installing build dependencies: still running...\n",
      "        Installing build dependencies: still running...\n",
      "        Installing build dependencies: still running...\n",
      "        Installing build dependencies: finished with status 'done'\n",
      "        Getting requirements to build wheel: started\n",
      "        Getting requirements to build wheel: finished with status 'done'\n",
      "        Preparing metadata (pyproject.toml): started\n",
      "        Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "      Collecting numpy<2.1.0,>=2.0.0\n",
      "        Using cached numpy-2.0.2-cp313-cp313-win_amd64.whl\n",
      "      Collecting blis<1.1.0,>=1.0.0 (from thinc<8.4.0,>=8.3.0)\n",
      "        Using cached blis-1.0.2-cp313-cp313-win_amd64.whl.metadata (7.8 kB)\n",
      "      Collecting wasabi<1.2.0,>=0.8.1 (from thinc<8.4.0,>=8.3.0)\n",
      "        Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "      Collecting srsly<3.0.0,>=2.4.0 (from thinc<8.4.0,>=8.3.0)\n",
      "        Downloading srsly-2.5.1-cp313-cp313-win_amd64.whl.metadata (20 kB)\n",
      "      Collecting catalogue<2.1.0,>=2.0.4 (from thinc<8.4.0,>=8.3.0)\n",
      "        Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "      Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.0)\n",
      "        Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "      Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from thinc<8.4.0,>=8.3.0)\n",
      "        Using cached pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "      Collecting packaging>=20.0 (from thinc<8.4.0,>=8.3.0)\n",
      "        Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "      Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->thinc<8.4.0,>=8.3.0)\n",
      "        Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "      Collecting pydantic-core==2.27.2 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->thinc<8.4.0,>=8.3.0)\n",
      "        Using cached pydantic_core-2.27.2-cp313-cp313-win_amd64.whl.metadata (6.7 kB)\n",
      "      Collecting typing-extensions>=4.12.2 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->thinc<8.4.0,>=8.3.0)\n",
      "        Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "      Collecting colorama>=0.4.6 (from wasabi<1.2.0,>=0.8.1->thinc<8.4.0,>=8.3.0)\n",
      "        Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "      Using cached setuptools-76.0.0-py3-none-any.whl (1.2 MB)\n",
      "      Using cached Cython-0.29.37-py2.py3-none-any.whl (989 kB)\n",
      "      Using cached cymem-2.0.11-cp313-cp313-win_amd64.whl (39 kB)\n",
      "      Using cached murmurhash-1.0.12-cp313-cp313-win_amd64.whl (24 kB)\n",
      "      Using cached blis-1.0.2-cp313-cp313-win_amd64.whl (6.4 MB)\n",
      "      Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "      Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "      Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "      Using cached pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "      Using cached pydantic_core-2.27.2-cp313-cp313-win_amd64.whl (2.0 MB)\n",
      "      Downloading srsly-2.5.1-cp313-cp313-win_amd64.whl (630 kB)\n",
      "         ---------------------------------------- 0.0/630.6 kB ? eta -:--:--\n",
      "         ---------------- ----------------------- 262.1/630.6 kB ? eta -:--:--\n",
      "         ---------------------------------------- 630.6/630.6 kB 2.9 MB/s eta 0:00:00\n",
      "      Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "      Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "      Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "      Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "      Building wheels for collected packages: preshed, thinc\n",
      "        Building wheel for preshed (pyproject.toml): started\n",
      "        Building wheel for preshed (pyproject.toml): finished with status 'done'\n",
      "        Created wheel for preshed: filename=preshed-3.0.9-cp313-cp313-win_amd64.whl size=120340 sha256=da62c2a803b2862dc4f81082b91aea59c77eb76d7351b26d0763b5be738c2868\n",
      "        Stored in directory: c:\\users\\jizhe\\appdata\\local\\pip\\cache\\wheels\\84\\04\\fe\\6f80443888530d8de3b35873cdc78cb5eaae6d269d08f095e4\n",
      "        Building wheel for thinc (pyproject.toml): started\n",
      "        Building wheel for thinc (pyproject.toml): finished with status 'error'\n",
      "        error: subprocess-exited-with-error\n",
      "      \n",
      "        脳 Building wheel for thinc (pyproject.toml) did not run successfully.\n",
      "        鈹\\x82 exit code: 1\n",
      "        鈺扳攢> [462 lines of output]\n",
      "            Cythonizing sources\n",
      "            running bdist_wheel\n",
      "            running build\n",
      "            running build_py\n",
      "            creating build\\lib.win-amd64-cpython-313\\thinc\n",
      "            copying thinc\\about.py -> build\\lib.win-amd64-cpython-313\\thinc\n",
      "            copying thinc\\api.py -> build\\lib.win-amd64-cpython-313\\thinc\n",
      "            copying thinc\\compat.py -> build\\lib.win-amd64-cpython-313\\thinc\n",
      "            copying thinc\\config.py -> build\\lib.win-amd64-cpython-313\\thinc\n",
      "            copying thinc\\initializers.py -> build\\lib.win-amd64-cpython-313\\thinc\n",
      "            copying thinc\\loss.py -> build\\lib.win-amd64-cpython-313\\thinc\n",
      "            copying thinc\\model.py -> build\\lib.win-amd64-cpython-313\\thinc\n",
      "            copying thinc\\mypy.py -> build\\lib.win-amd64-cpython-313\\thinc\n",
      "            copying thinc\\optimizers.py -> build\\lib.win-amd64-cpython-313\\thinc\n",
      "            copying thinc\\schedules.py -> build\\lib.win-amd64-cpython-313\\thinc\n",
      "            copying thinc\\types.py -> build\\lib.win-amd64-cpython-313\\thinc\n",
      "            copying thinc\\util.py -> build\\lib.win-amd64-cpython-313\\thinc\n",
      "            copying thinc\\__init__.py -> build\\lib.win-amd64-cpython-313\\thinc\n",
      "            creating build\\lib.win-amd64-cpython-313\\thinc\\backends\n",
      "            copying thinc\\backends\\cupy_ops.py -> build\\lib.win-amd64-cpython-313\\thinc\\backends\n",
      "            copying thinc\\backends\\mps_ops.py -> build\\lib.win-amd64-cpython-313\\thinc\\backends\n",
      "            copying thinc\\backends\\ops.py -> build\\lib.win-amd64-cpython-313\\thinc\\backends\n",
      "            copying thinc\\backends\\_cupy_allocators.py -> build\\lib.win-amd64-cpython-313\\thinc\\backends\n",
      "            copying thinc\\backends\\_custom_kernels.py -> build\\lib.win-amd64-cpython-313\\thinc\\backends\n",
      "            copying thinc\\backends\\_param_server.py -> build\\lib.win-amd64-cpython-313\\thinc\\backends\n",
      "            copying thinc\\backends\\__init__.py -> build\\lib.win-amd64-cpython-313\\thinc\\backends\n",
      "            creating build\\lib.win-amd64-cpython-313\\thinc\\extra\n",
      "            copying thinc\\extra\\__init__.py -> build\\lib.win-amd64-cpython-313\\thinc\\extra\n",
      "            creating build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\add.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\array_getitem.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\bidirectional.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\cauchysimilarity.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\chain.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\clipped_linear.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\clone.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\concatenate.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\dish.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\dropout.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\embed.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\expand_window.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\gelu.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\hard_swish.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\hard_swish_mobilenet.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\hashembed.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\layernorm.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\linear.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\list2array.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\list2padded.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\list2ragged.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\logistic.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\lstm.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\map_list.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\maxout.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\mish.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\multisoftmax.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\mxnetwrapper.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\noop.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\padded2list.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\parametricattention.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\parametricattention_v2.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\pytorchwrapper.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\ragged2list.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\reduce_first.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\reduce_last.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\reduce_max.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\reduce_mean.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\reduce_sum.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\relu.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\remap_ids.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\residual.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\resizable.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\siamese.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\sigmoid.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\sigmoid_activation.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\softmax.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\softmax_activation.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\strings2arrays.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\swish.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\tensorflowwrapper.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\torchscriptwrapper.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\tuplify.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\uniqued.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\with_array.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\with_array2d.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\with_cpu.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\with_debug.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\with_flatten.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\with_flatten_v2.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\with_getitem.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\with_list.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\with_nvtx_range.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\with_padded.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\with_ragged.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\with_reshape.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\with_signpost_interval.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\__init__.py -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            creating build\\lib.win-amd64-cpython-313\\thinc\\shims\n",
      "            copying thinc\\shims\\mxnet.py -> build\\lib.win-amd64-cpython-313\\thinc\\shims\n",
      "            copying thinc\\shims\\pytorch.py -> build\\lib.win-amd64-cpython-313\\thinc\\shims\n",
      "            copying thinc\\shims\\pytorch_grad_scaler.py -> build\\lib.win-amd64-cpython-313\\thinc\\shims\n",
      "            copying thinc\\shims\\shim.py -> build\\lib.win-amd64-cpython-313\\thinc\\shims\n",
      "            copying thinc\\shims\\tensorflow.py -> build\\lib.win-amd64-cpython-313\\thinc\\shims\n",
      "            copying thinc\\shims\\torchscript.py -> build\\lib.win-amd64-cpython-313\\thinc\\shims\n",
      "            copying thinc\\shims\\__init__.py -> build\\lib.win-amd64-cpython-313\\thinc\\shims\n",
      "            creating build\\lib.win-amd64-cpython-313\\thinc\\tests\n",
      "            copying thinc\\tests\\conftest.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\n",
      "            copying thinc\\tests\\enable_mxnet.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\n",
      "            copying thinc\\tests\\enable_tensorflow.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\n",
      "            copying thinc\\tests\\strategies.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\n",
      "            copying thinc\\tests\\test_config.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\n",
      "            copying thinc\\tests\\test_examples.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\n",
      "            copying thinc\\tests\\test_import__all__.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\n",
      "            copying thinc\\tests\\test_indexing.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\n",
      "            copying thinc\\tests\\test_initializers.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\n",
      "            copying thinc\\tests\\test_loss.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\n",
      "            copying thinc\\tests\\test_optimizers.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\n",
      "            copying thinc\\tests\\test_schedules.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\n",
      "            copying thinc\\tests\\test_serialize.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\n",
      "            copying thinc\\tests\\test_types.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\n",
      "            copying thinc\\tests\\test_util.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\n",
      "            copying thinc\\tests\\util.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\n",
      "            copying thinc\\tests\\__init__.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\n",
      "            creating build\\lib.win-amd64-cpython-313\\thinc\\extra\\tests\n",
      "            copying thinc\\extra\\tests\\__init__.py -> build\\lib.win-amd64-cpython-313\\thinc\\extra\\tests\n",
      "            creating build\\lib.win-amd64-cpython-313\\thinc\\tests\\backends\n",
      "            copying thinc\\tests\\backends\\test_mem.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\backends\n",
      "            copying thinc\\tests\\backends\\test_ops.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\backends\n",
      "            copying thinc\\tests\\backends\\__init__.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\backends\n",
      "            creating build\\lib.win-amd64-cpython-313\\thinc\\tests\\extra\n",
      "            copying thinc\\tests\\extra\\test_beam_search.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\extra\n",
      "            copying thinc\\tests\\extra\\__init__.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\extra\n",
      "            creating build\\lib.win-amd64-cpython-313\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_basic_tagger.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_combinators.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_feed_forward.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_hash_embed.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_layers_api.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_linear.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_lstm.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_mappers.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_mnist.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_mxnet_wrapper.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_parametric_attention_v2.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_pytorch_wrapper.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_reduce.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_resizable.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_shim.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_softmax.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_sparse_linear.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_tensorflow_wrapper.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_torchscriptwrapper.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_transforms.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_uniqued.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_with_debug.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_with_flatten.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\test_with_transforms.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\layers\n",
      "            copying thinc\\tests\\layers\\__init__.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\layers\n",
      "            creating build\\lib.win-amd64-cpython-313\\thinc\\tests\\model\n",
      "            copying thinc\\tests\\model\\test_model.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\model\n",
      "            copying thinc\\tests\\model\\test_validation.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\model\n",
      "            copying thinc\\tests\\model\\__init__.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\model\n",
      "            creating build\\lib.win-amd64-cpython-313\\thinc\\tests\\mypy\n",
      "            copying thinc\\tests\\mypy\\test_mypy.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\mypy\n",
      "            copying thinc\\tests\\mypy\\__init__.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\mypy\n",
      "            creating build\\lib.win-amd64-cpython-313\\thinc\\tests\\regression\n",
      "            copying thinc\\tests\\regression\\test_issue208.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\regression\n",
      "            copying thinc\\tests\\regression\\test_issue564.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\regression\n",
      "            copying thinc\\tests\\regression\\__init__.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\regression\n",
      "            creating build\\lib.win-amd64-cpython-313\\thinc\\tests\\shims\n",
      "            copying thinc\\tests\\shims\\test_pytorch_grad_scaler.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\shims\n",
      "            copying thinc\\tests\\shims\\__init__.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\shims\n",
      "            creating build\\lib.win-amd64-cpython-313\\thinc\\tests\\mypy\\modules\n",
      "            copying thinc\\tests\\mypy\\modules\\fail_no_plugin.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\mypy\\modules\n",
      "            copying thinc\\tests\\mypy\\modules\\fail_plugin.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\mypy\\modules\n",
      "            copying thinc\\tests\\mypy\\modules\\success_no_plugin.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\mypy\\modules\n",
      "            copying thinc\\tests\\mypy\\modules\\success_plugin.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\mypy\\modules\n",
      "            copying thinc\\tests\\mypy\\modules\\__init__.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\mypy\\modules\n",
      "            creating build\\lib.win-amd64-cpython-313\\thinc\\tests\\regression\\issue519\n",
      "            copying thinc\\tests\\regression\\issue519\\program.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\regression\\issue519\n",
      "            copying thinc\\tests\\regression\\issue519\\test_issue519.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\regression\\issue519\n",
      "            copying thinc\\tests\\regression\\issue519\\__init__.py -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\regression\\issue519\n",
      "            running egg_info\n",
      "            writing thinc.egg-info\\PKG-INFO\n",
      "            writing dependency_links to thinc.egg-info\\dependency_links.txt\n",
      "            writing entry points to thinc.egg-info\\entry_points.txt\n",
      "            writing requirements to thinc.egg-info\\requires.txt\n",
      "            writing top-level names to thinc.egg-info\\top_level.txt\n",
      "            dependency C:\\Python313\\Include\\Python.h won't be automatically included in the manifest: the path must be relative\n",
      "            dependency C:\\Users\\jizhe\\AppData\\Local\\Temp\\pip-build-env-q157pph0\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "            dependency C:\\Users\\jizhe\\AppData\\Local\\Temp\\pip-build-env-q157pph0\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "            dependency C:\\Users\\jizhe\\AppData\\Local\\Temp\\pip-build-env-q157pph0\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "            dependency C:\\Users\\jizhe\\AppData\\Local\\Temp\\pip-build-env-q157pph0\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "            dependency C:\\Users\\jizhe\\AppData\\Local\\Temp\\pip-build-env-q157pph0\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "            dependency C:\\Python313\\Include\\Python.h won't be automatically included in the manifest: the path must be relative\n",
      "            dependency C:\\Users\\jizhe\\AppData\\Local\\Temp\\pip-build-env-q157pph0\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "            dependency C:\\Users\\jizhe\\AppData\\Local\\Temp\\pip-build-env-q157pph0\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\arrayscalars.h won't be automatically included in the manifest: the path must be relative\n",
      "            dependency C:\\Users\\jizhe\\AppData\\Local\\Temp\\pip-build-env-q157pph0\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarrayobject.h won't be automatically included in the manifest: the path must be relative\n",
      "            dependency C:\\Users\\jizhe\\AppData\\Local\\Temp\\pip-build-env-q157pph0\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ndarraytypes.h won't be automatically included in the manifest: the path must be relative\n",
      "            dependency C:\\Users\\jizhe\\AppData\\Local\\Temp\\pip-build-env-q157pph0\\overlay\\Lib\\site-packages\\numpy\\_core\\include\\numpy\\ufuncobject.h won't be automatically included in the manifest: the path must be relative\n",
      "            reading manifest file 'thinc.egg-info\\SOURCES.txt'\n",
      "            reading manifest template 'MANIFEST.in'\n",
      "            no previously-included directories found matching 'tmp'\n",
      "            warning: no previously-included files matching '*.cpp' found under directory 'thinc'\n",
      "            adding license file 'LICENSE'\n",
      "            writing manifest file 'thinc.egg-info\\SOURCES.txt'\n",
      "            C:\\Users\\jizhe\\AppData\\Local\\Temp\\pip-build-env-q157pph0\\overlay\\Lib\\site-packages\\setuptools\\command\\build_py.py:212: _Warning: Package 'thinc.backends' is absent from the `packages` configuration.\n",
      "            !!\n",
      "      \n",
      "                    ********************************************************************************\n",
      "                    ############################\n",
      "                    # Package would be ignored #\n",
      "                    ############################\n",
      "                    Python recognizes 'thinc.backends' as an importable package[^1],\n",
      "                    but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "                    This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "                    package, please make sure that 'thinc.backends' is explicitly added\n",
      "                    to the `packages` configuration field.\n",
      "      \n",
      "                    Alternatively, you can also rely on setuptools' discovery methods\n",
      "                    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "                    instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "                    You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "                    - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "                    If you don't want 'thinc.backends' to be distributed and are\n",
      "                    already explicitly excluding 'thinc.backends' via\n",
      "                    `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "                    you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "                    combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "                    You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "                    - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "                    [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                          even if it does not contain any `.py` files.\n",
      "                          On the other hand, currently there is no concept of package data\n",
      "                          directory, all directories are treated like packages.\n",
      "                    ********************************************************************************\n",
      "      \n",
      "            !!\n",
      "              check.warn(importable)\n",
      "            C:\\Users\\jizhe\\AppData\\Local\\Temp\\pip-build-env-q157pph0\\overlay\\Lib\\site-packages\\setuptools\\command\\build_py.py:212: _Warning: Package 'thinc.extra' is absent from the `packages` configuration.\n",
      "            !!\n",
      "      \n",
      "                    ********************************************************************************\n",
      "                    ############################\n",
      "                    # Package would be ignored #\n",
      "                    ############################\n",
      "                    Python recognizes 'thinc.extra' as an importable package[^1],\n",
      "                    but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "                    This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "                    package, please make sure that 'thinc.extra' is explicitly added\n",
      "                    to the `packages` configuration field.\n",
      "      \n",
      "                    Alternatively, you can also rely on setuptools' discovery methods\n",
      "                    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "                    instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "                    You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "                    - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "                    If you don't want 'thinc.extra' to be distributed and are\n",
      "                    already explicitly excluding 'thinc.extra' via\n",
      "                    `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "                    you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "                    combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "                    You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "                    - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "                    [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                          even if it does not contain any `.py` files.\n",
      "                          On the other hand, currently there is no concept of package data\n",
      "                          directory, all directories are treated like packages.\n",
      "                    ********************************************************************************\n",
      "      \n",
      "            !!\n",
      "              check.warn(importable)\n",
      "            C:\\Users\\jizhe\\AppData\\Local\\Temp\\pip-build-env-q157pph0\\overlay\\Lib\\site-packages\\setuptools\\command\\build_py.py:212: _Warning: Package 'thinc.layers' is absent from the `packages` configuration.\n",
      "            !!\n",
      "      \n",
      "                    ********************************************************************************\n",
      "                    ############################\n",
      "                    # Package would be ignored #\n",
      "                    ############################\n",
      "                    Python recognizes 'thinc.layers' as an importable package[^1],\n",
      "                    but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "                    This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "                    package, please make sure that 'thinc.layers' is explicitly added\n",
      "                    to the `packages` configuration field.\n",
      "      \n",
      "                    Alternatively, you can also rely on setuptools' discovery methods\n",
      "                    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "                    instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "                    You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "                    - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "                    If you don't want 'thinc.layers' to be distributed and are\n",
      "                    already explicitly excluding 'thinc.layers' via\n",
      "                    `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "                    you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "                    combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "                    You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "                    - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "                    [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                          even if it does not contain any `.py` files.\n",
      "                          On the other hand, currently there is no concept of package data\n",
      "                          directory, all directories are treated like packages.\n",
      "                    ********************************************************************************\n",
      "      \n",
      "            !!\n",
      "              check.warn(importable)\n",
      "            C:\\Users\\jizhe\\AppData\\Local\\Temp\\pip-build-env-q157pph0\\overlay\\Lib\\site-packages\\setuptools\\command\\build_py.py:212: _Warning: Package 'thinc.tests.mypy.configs' is absent from the `packages` configuration.\n",
      "            !!\n",
      "      \n",
      "                    ********************************************************************************\n",
      "                    ############################\n",
      "                    # Package would be ignored #\n",
      "                    ############################\n",
      "                    Python recognizes 'thinc.tests.mypy.configs' as an importable package[^1],\n",
      "                    but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "                    This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "                    package, please make sure that 'thinc.tests.mypy.configs' is explicitly added\n",
      "                    to the `packages` configuration field.\n",
      "      \n",
      "                    Alternatively, you can also rely on setuptools' discovery methods\n",
      "                    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "                    instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "                    You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "                    - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "                    If you don't want 'thinc.tests.mypy.configs' to be distributed and are\n",
      "                    already explicitly excluding 'thinc.tests.mypy.configs' via\n",
      "                    `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "                    you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "                    combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "                    You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "                    - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "                    [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                          even if it does not contain any `.py` files.\n",
      "                          On the other hand, currently there is no concept of package data\n",
      "                          directory, all directories are treated like packages.\n",
      "                    ********************************************************************************\n",
      "      \n",
      "            !!\n",
      "              check.warn(importable)\n",
      "            C:\\Users\\jizhe\\AppData\\Local\\Temp\\pip-build-env-q157pph0\\overlay\\Lib\\site-packages\\setuptools\\command\\build_py.py:212: _Warning: Package 'thinc.tests.mypy.outputs' is absent from the `packages` configuration.\n",
      "            !!\n",
      "      \n",
      "                    ********************************************************************************\n",
      "                    ############################\n",
      "                    # Package would be ignored #\n",
      "                    ############################\n",
      "                    Python recognizes 'thinc.tests.mypy.outputs' as an importable package[^1],\n",
      "                    but it is absent from setuptools' `packages` configuration.\n",
      "      \n",
      "                    This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "                    package, please make sure that 'thinc.tests.mypy.outputs' is explicitly added\n",
      "                    to the `packages` configuration field.\n",
      "      \n",
      "                    Alternatively, you can also rely on setuptools' discovery methods\n",
      "                    (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "                    instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "                    You can read more about \"package discovery\" on setuptools documentation page:\n",
      "      \n",
      "                    - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "      \n",
      "                    If you don't want 'thinc.tests.mypy.outputs' to be distributed and are\n",
      "                    already explicitly excluding 'thinc.tests.mypy.outputs' via\n",
      "                    `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "                    you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "                    combination with a more fine grained `package-data` configuration.\n",
      "      \n",
      "                    You can read more about \"package data files\" on setuptools documentation page:\n",
      "      \n",
      "                    - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "      \n",
      "      \n",
      "                    [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "                          even if it does not contain any `.py` files.\n",
      "                          On the other hand, currently there is no concept of package data\n",
      "                          directory, all directories are treated like packages.\n",
      "                    ********************************************************************************\n",
      "      \n",
      "            !!\n",
      "              check.warn(importable)\n",
      "            copying thinc\\__init__.pxd -> build\\lib.win-amd64-cpython-313\\thinc\n",
      "            copying thinc\\py.typed -> build\\lib.win-amd64-cpython-313\\thinc\n",
      "            copying thinc\\backends\\cblas.cpp -> build\\lib.win-amd64-cpython-313\\thinc\\backends\n",
      "            copying thinc\\backends\\cpu_kernels.hh -> build\\lib.win-amd64-cpython-313\\thinc\\backends\n",
      "            copying thinc\\backends\\linalg.cpp -> build\\lib.win-amd64-cpython-313\\thinc\\backends\n",
      "            copying thinc\\backends\\numpy_ops.cpp -> build\\lib.win-amd64-cpython-313\\thinc\\backends\n",
      "            copying thinc\\extra\\search.cpp -> build\\lib.win-amd64-cpython-313\\thinc\\extra\n",
      "            copying thinc\\layers\\premap_ids.cpp -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\sparselinear.cpp -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\backends\\__init__.pxd -> build\\lib.win-amd64-cpython-313\\thinc\\backends\n",
      "            copying thinc\\backends\\_custom_kernels.cu -> build\\lib.win-amd64-cpython-313\\thinc\\backends\n",
      "            copying thinc\\backends\\_murmur3.cu -> build\\lib.win-amd64-cpython-313\\thinc\\backends\n",
      "            copying thinc\\backends\\cblas.pxd -> build\\lib.win-amd64-cpython-313\\thinc\\backends\n",
      "            copying thinc\\backends\\cblas.pyx -> build\\lib.win-amd64-cpython-313\\thinc\\backends\n",
      "            copying thinc\\backends\\linalg.pxd -> build\\lib.win-amd64-cpython-313\\thinc\\backends\n",
      "            copying thinc\\backends\\linalg.pyx -> build\\lib.win-amd64-cpython-313\\thinc\\backends\n",
      "            copying thinc\\backends\\numpy_ops.pxd -> build\\lib.win-amd64-cpython-313\\thinc\\backends\n",
      "            copying thinc\\backends\\numpy_ops.pyx -> build\\lib.win-amd64-cpython-313\\thinc\\backends\n",
      "            copying thinc\\extra\\__init__.pxd -> build\\lib.win-amd64-cpython-313\\thinc\\extra\n",
      "            copying thinc\\extra\\search.pxd -> build\\lib.win-amd64-cpython-313\\thinc\\extra\n",
      "            copying thinc\\extra\\search.pyx -> build\\lib.win-amd64-cpython-313\\thinc\\extra\n",
      "            copying thinc\\layers\\premap_ids.pyx -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\layers\\sparselinear.pyx -> build\\lib.win-amd64-cpython-313\\thinc\\layers\n",
      "            copying thinc\\extra\\tests\\c_test_search.pyx -> build\\lib.win-amd64-cpython-313\\thinc\\extra\\tests\n",
      "            creating build\\lib.win-amd64-cpython-313\\thinc\\tests\\mypy\\configs\n",
      "            copying thinc\\tests\\mypy\\configs\\mypy-default.ini -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\mypy\\configs\n",
      "            copying thinc\\tests\\mypy\\configs\\mypy-plugin.ini -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\mypy\\configs\n",
      "            creating build\\lib.win-amd64-cpython-313\\thinc\\tests\\mypy\\outputs\n",
      "            copying thinc\\tests\\mypy\\outputs\\fail-no-plugin.txt -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\mypy\\outputs\n",
      "            copying thinc\\tests\\mypy\\outputs\\fail-plugin.txt -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\mypy\\outputs\n",
      "            copying thinc\\tests\\mypy\\outputs\\success-no-plugin.txt -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\mypy\\outputs\n",
      "            copying thinc\\tests\\mypy\\outputs\\success-plugin.txt -> build\\lib.win-amd64-cpython-313\\thinc\\tests\\mypy\\outputs\n",
      "            running build_ext\n",
      "            building 'thinc.backends.cblas' extension\n",
      "            creating build\\temp.win-amd64-cpython-313\\Release\\thinc\\backends\n",
      "            \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.43.34808\\bin\\HostX86\\x64\\cl.exe\" /c /nologo /O2 /W3 /GL /DNDEBUG /MD -IC:\\Users\\jizhe\\AppData\\Local\\Temp\\pip-build-env-q157pph0\\overlay\\Lib\\site-packages\\numpy\\_core\\include -IC:\\Python313\\Include -Ic:\\Users\\jizhe\\.virtualenvs\\lang-chain-wYHJBg1W\\include -IC:\\Python313\\include -IC:\\Python313\\Include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.43.34808\\include\" \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Auxiliary\\VS\\include\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.22621.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\winrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\cppwinrt\" /EHsc /Tpthinc/backends/cblas.cpp /Fobuild\\temp.win-amd64-cpython-313\\Release\\thinc\\backends\\cblas.obj /Ox /EHsc\n",
      "            cblas.cpp\n",
      "            thinc/backends/cblas.cpp(871): warning C4996: 'Py_UNICODE': deprecated in 3.13\n",
      "            thinc/backends/cblas.cpp(872): warning C4996: 'Py_UNICODE': deprecated in 3.13\n",
      "            thinc/backends/cblas.cpp(1908): error C3861: 鈥淿PyList_Extend鈥\\x9d: 鎵句笉鍒版爣璇嗙\\xac\\xa6\n",
      "            thinc/backends/cblas.cpp(1946): error C3861: 鈥淿PyInterpreterState_GetConfig鈥\\x9d: 鎵句笉鍒版爣璇嗙\\xac\\xa6\n",
      "            thinc/backends/cblas.cpp(20354): error C2660: 鈥淿PyLong_AsByteArray鈥\\x9d: 鍑芥暟涓嶆帴鍙\\x97 5 涓\\xaa鍙傛暟\n",
      "            C:\\Python313\\Include\\cpython/longobject.h(111): note: 鍙傝\\xa7佲\\x80淿PyLong_AsByteArray鈥濈殑澹版槑\n",
      "            thinc/backends/cblas.cpp(20354): note: 灏濊瘯鍖归厤鍙傛暟鍒楄〃鈥\\x9c(PyLongObject *, unsigned char *, size_t, int, bool)鈥濇椂\n",
      "            thinc/backends/cblas.cpp(20550): error C2660: 鈥淿PyLong_AsByteArray鈥\\x9d: 鍑芥暟涓嶆帴鍙\\x97 5 涓\\xaa鍙傛暟\n",
      "            C:\\Python313\\Include\\cpython/longobject.h(111): note: 鍙傝\\xa7佲\\x80淿PyLong_AsByteArray鈥濈殑澹版槑\n",
      "            thinc/backends/cblas.cpp(20550): note: 灏濊瘯鍖归厤鍙傛暟鍒楄〃鈥\\x9c(PyLongObject *, unsigned char *, size_t, int, bool)鈥濇椂\n",
      "            thinc/backends/cblas.cpp(20822): error C2660: 鈥淿PyLong_AsByteArray鈥\\x9d: 鍑芥暟涓嶆帴鍙\\x97 5 涓\\xaa鍙傛暟\n",
      "            C:\\Python313\\Include\\cpython/longobject.h(111): note: 鍙傝\\xa7佲\\x80淿PyLong_AsByteArray鈥濈殑澹版槑\n",
      "            thinc/backends/cblas.cpp(20822): note: 灏濊瘯鍖归厤鍙傛暟鍒楄〃鈥\\x9c(PyLongObject *, unsigned char *, size_t, int, bool)鈥濇椂\n",
      "            error: command 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\2022\\\\BuildTools\\\\VC\\\\Tools\\\\MSVC\\\\14.43.34808\\\\bin\\\\HostX86\\\\x64\\\\cl.exe' failed with exit code 2\n",
      "            [end of output]\n",
      "      \n",
      "        note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "        ERROR: Failed building wheel for thinc\n",
      "      Successfully built preshed\n",
      "      Failed to build thinc\n",
      "      ERROR: Failed to build installable wheels for some pyproject.toml based projects (thinc)\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× pip subprocess to install build dependencies did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "# 安装依赖\n",
    "%pip install doctran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载文档\n",
    "with open(file=\"./sources/test.txt\", encoding=\"utf-8\") as f:\n",
    "    content = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'doctran'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m OPENAI_MODEL = \u001b[33m\"\u001b[39m\u001b[33mgpt-3.5-turbo-16k\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     12\u001b[39m OPENAI_TOKEN_LIMIT = \u001b[32m8000\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdoctran\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Doctran\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Doctran是对openai的一层封装\u001b[39;00m\n\u001b[32m     17\u001b[39m doctrans = Doctran(\n\u001b[32m     18\u001b[39m     openai_api_key=OPENAI_API_KEY,\n\u001b[32m     19\u001b[39m     openai_model=OPENAI_MODEL,\n\u001b[32m     20\u001b[39m     openai_token_limit=OPENAI_TOKEN_LIMIT,\n\u001b[32m     21\u001b[39m )\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'doctran'"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "API_BASE = os.getenv(\"OPENAI_API_BASE_URL\")\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "MODEL_NAME = os.getenv(\"MODEL_NAME\")\n",
    "OPENAI_TOKEN_LIMIT = 8000\n",
    "\n",
    "from doctran import Doctran\n",
    "\n",
    "# Doctran是对openai的一层封装\n",
    "doctrans = Doctran(\n",
    "    openai_api_key=API_KEY,\n",
    "    openai_model=MODEL_NAME,\n",
    "    openai_token_limit=OPENAI_TOKEN_LIMIT,\n",
    ")\n",
    "\n",
    "documents = doctrans.parse(content=content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 总结文档, token_limit参数是总结后的字数限制\n",
    "summary = documents.summarize(token_limit=100).execute()\n",
    "print(summary.transformed_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 翻译问答\n",
    "translation = documents.translate(language=\"chinese\").execute()\n",
    "print(translation.transformed_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 精炼文档，删除除了某主题或关键词之外的内容，仅保留与主体相关的内容\n",
    "# 指定主题来进行精炼\n",
    "refined = documents.refine(topics=[\"marketing\",\"Development\"]).execute()\n",
    "print(refined.transformed_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang-chain-wYHJBg1W",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
