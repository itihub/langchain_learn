{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lost in then middle:长上下文精度问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装依赖，用于句式转换\n",
    "%pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain,StuffDocumentsChain\n",
    "from langchain_community.document_transformers import (\n",
    "    # 长上下文记录器\n",
    "    LongContextReorder\n",
    ")\n",
    "# 词嵌入\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "# Chroma 是一个开源的嵌入式向量数据库。它可以存储和检索向量化后的数据，非常适合用于语义搜索和相似性查找。\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# 准备文本数据，模拟切割后结果\n",
    "text = [\n",
    "    \"篮球是一项伟大的运动。\",\n",
    "    \"带我飞往月球是我最喜欢的歌曲之一。\",\n",
    "    \"凯尔特人队是我最喜欢的球队。\",\n",
    "    \"这是一篇关于波士顿凯尔特人的文件。\",\n",
    "    \"我非常喜欢去看电影。\",\n",
    "    \"波士顿凯尔特人队以20分的优势赢得了比赛。\",\n",
    "    \"这只是一段随机的文字。\",\n",
    "    \"《艾尔登之环》是过去15年最好的游戏之一。\",\n",
    "    \"L.科内特是凯尔特人队最好的球员之一。\",\n",
    "    \"拉里.伯德是一位标志性的NBA球员。\"\n",
    "]\n",
    "\n",
    "# 使用HuggingFace模型托管平台，使用托管的开源LLM来做词嵌入，MiniLM-L6-v2是一个较小的LLM \n",
    "embeddings = HuggingFaceBgeEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# 将文本向量化，并存储到 Chroma 向量数据库中\n",
    "# 给定的文本列表 (texts) 和嵌入模型 (embeddings) 创建一个 Chroma 向量数据库实例\n",
    "# as_retriever():这个方法将 Chroma 向量数据库实例转换为一个检索器（retriever）对象\n",
    "retrieval = Chroma.from_texts(text, embeddings).as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    # 返回最相关的10条结果\n",
    "    search_kwargs={\"k\": 10, \"fetch_k\": 200, \"lambda_mult\": 0},\n",
    ")\n",
    "\n",
    "# 根据相关性返回文本块\n",
    "query = \"关于凯尔特人队你知道什么?\"\n",
    "docs = retrieval.get_relevant_documents(query)\n",
    "print(docs)\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对检索结果进行重新排序，根据论文的方案\n",
    "# 问题相关性越低的内容块放在中间\n",
    "# 问题相关性越高的内容块放在头尾\n",
    "# 来解决长文本的切分后精度下降的问题\n",
    "\n",
    "# 用于长上下文记录器，对文档进行重新排序\n",
    "reordering = LongContextReorder()\n",
    "reo_docs = reordering.transform_documents(docs)\n",
    "\n",
    "# 头尾共有4个高相关性内容块\n",
    "reo_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# 主要作用是从一个名为 .env 的文件中加载环境变量到你的 Python 程序中\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "api_base = os.getenv(\"OPENAI_API_BASE_URL\")\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model_name = os.getenv(\"MODEL_NAME\")\n",
    "\n",
    "print(api_base)\n",
    "print(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检测下这种方案的精度效果\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import OpenAI\n",
    "\n",
    "#设置llm\n",
    "llm = OpenAI(\n",
    "    # openai_api_base=openai_api_base,\n",
    "    openai_api_key=api_key,\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# 构建提示词模板\n",
    "document_prompt = PromptTemplate(\n",
    "    input_variables=[\"page_content\"],\n",
    "    template=\"{page_content}\",\n",
    ")\n",
    "\n",
    "\n",
    "stuff_prompt_override =\"\"\"Given this text extracts:\n",
    "----------------------------------------\n",
    "{context}\n",
    "----------------------------------------\n",
    "Please answer the following questions:\n",
    "{query}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=stuff_prompt_override,\n",
    "    input_variables=[\"context\", \"query\"]\n",
    ")\n",
    "\n",
    "# 创建一个 LLMChain 实例，它将 LLM 和提示词模板连接起来。\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "# 创建一个 StuffDocumentsChain 实例，它负责将多个文档组合成一个上下文，并将其传递给 llm_chain\n",
    "WorkChain = StuffDocumentsChain(\n",
    "    llm_chain=llm_chain,\n",
    "    document_prompt=document_prompt,\n",
    "    document_variable_name=\"context\", # 定将组合后的文档内容存储在 context 变量中。\n",
    ")\n",
    "\n",
    "# 链调用\n",
    "WorkChain.run(\n",
    "    input_documents=reo_docs, # 将 reo_docs 列表中的文档作为输入。\n",
    "    query=\"我最喜欢做什么事情？\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang-chain-wYHJBg1W",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
