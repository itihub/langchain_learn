{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chaines使用\n",
    "Chains 是一系列将各种组件链接在一起的工具，用于创建更复杂的应用程序。Chains 允许你将多个 LLM、提示模板、输出解析器和其他工具组合在一起，以创建可以执行特定任务的管道。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载环境配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "print(os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开启链的日志功能\n",
    "开启链的日志功能可以帮助你调试和理解链的执行过程。LangChain 提供了几种方法来启用日志记录，以便你可以查看链的内部操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用 langchain.globals 模块\n",
    "LangChain 提供了一个全局配置模块 langchain.globals，你可以使用它来设置全局日志级别。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import langchain.globals as globals\n",
    "\n",
    "# 设置全局日志级别为 DEBUG\n",
    "globals.set_debug(True)\n",
    "\n",
    "# 或者，你可以使用 logging 模块设置更细粒度的日志级别\n",
    "# logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用环境变量\n",
    "也可以使用环境变量来控制 LangChain 的日志记录。\n",
    "- LANGCHAIN_DEBUG=true: 设置此环境变量会启用 LangChain 的调试模式。\n",
    "    - 在 Linux/macOS 中：export LANGCHAIN_DEBUG=true\n",
    "    - 在 Windows 中：set LANGCHAIN_DEBUG=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_DEBUG\"] = \"true\"\n",
    "\n",
    "print(os.getenv(\"LANGCHAIN_DEBUG\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLMChain 基本的链\n",
    "在 LangChain 0.3.21 版本中，LLMChain 已经被弃用，并且在后续版本中会被移除。\n",
    "替代方案：使用 Runnable Sequence（| 运算符）\n",
    "- LLMChain 是最基本的链，它将 LLM 与提示模板和可选的输出解析器结合在一起。\n",
    "- 它接受用户输入，使用提示模板生成提示，将提示发送到 LLM，并（可选）使用输出解析器解析 LLM 的输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用 LLMChain\n",
    "自 0.1.17 版起已弃用：改用。直到 langchain==1.0 才会将其删除。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"帮我给{product}想三个可以注册的域名?\"\n",
    "# 创建 PromptTemplate 对象\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"], \n",
    "    template=prompt_template,\n",
    ")\n",
    "\n",
    "# 初始化 OpenAI 语言模型\n",
    "llm = ChatOpenAI(\n",
    "    base_url=os.getenv(\"OPENAI_API_BASE_URL\"),\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=True, # 是否开启日志\n",
    ")\n",
    "\n",
    "result = chain.invoke({\"product\": \"AI研习社\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用 Runnable Sequence\n",
    "LangChain 推荐使用 Runnable Sequence（使用 | 运算符）来替代 LLMChain。  \n",
    "以下是一个简单的示例，展示了如何使用 Runnable Sequence 替代 LLMChain："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt_template = \"帮我给{product}想三个可以注册的域名?\"\n",
    "# 创建 PromptTemplate 对象\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"], \n",
    "    template=prompt_template,\n",
    ")\n",
    "\n",
    "# 格式化提示模板，提供产品名称\n",
    "# print(prompt.format(product=\"AI研习社\"))\n",
    "\n",
    "# 初始化 OpenAI 语言模型\n",
    "llm = ChatOpenAI(\n",
    "    base_url=os.getenv(\"OPENAI_API_BASE_URL\"),\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# 创建 LLM 链\n",
    "# 创建了一个 LLM 链，将提示模板、OpenAI 语言模型和字符串输出解析器连接在一起\n",
    "# | 运算符用于将链中的组件连接起来\n",
    "# StrOutputParser() 创建一个字符串输出解析器实例，它将语言模型的输出转换为简单的字符串。\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 调用 LLM 链\n",
    "result = chain.invoke({\"product\": \"AI研习社\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SequentialChain \n",
    "SequentialChain 允许您将多个链按顺序连接在一起，并将一个链的输出作为下一个链的输入。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用 LLMChain 实现 SimpleSequentialChain 调用\n",
    "- 简化操作：\n",
    "  - SimpleSequentialChain 旨在简化顺序链的创建和执行。它适用于简单的链式操作，其中一个链的输出直接作为下一个链的输入。\n",
    "- 隐式输入/输出：\n",
    "  - SimpleSequentialChain 隐式地处理链之间的输入和输出传递。它假设每个链的输出都是一个字符串，并将其直接传递给下一个链。\n",
    "- 限制：\n",
    "  - 由于其简化性质，SimpleSequentialChain 在处理更复杂的链式操作时可能会受到限制。例如，它不支持自定义输入/输出变量或条件逻辑。\n",
    "- 使用场景：\n",
    "  - 适用于简单的文本处理流程，例如，将一个链生成的文本传递给另一个链进行摘要或翻译。\n",
    "- 过时：\n",
    "  - 在最新的langchain版本中，simpleSequentialChain 已经不推荐使用，官方更推荐使用Runnable接口来实现。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.chains.sequential import SimpleSequentialChain\n",
    "\n",
    "# 初始化 OpenAI 语言模型\n",
    "llm = ChatOpenAI(\n",
    "    base_url=os.getenv(\"OPENAI_API_BASE_URL\"),\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# 创建第一个 LLMChain\n",
    "first_prompt = ChatPromptTemplate.from_template(\"帮我给{input}的公司起一个响亮容易记忆的名字?\")\n",
    "chain_one = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=first_prompt,\n",
    "    output_key=\"output\",\n",
    ")\n",
    "\n",
    "# 创建第二个 LLMChain\n",
    "second_prompt = ChatPromptTemplate.from_template(\"用5个词来描述一下这个公司名字：{input}\")\n",
    "chain_two = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=second_prompt,\n",
    "    output_key=\"output\",\n",
    ")\n",
    "\n",
    "\n",
    "# 创建 SimpleSequentialChain\n",
    "overall_simple_chain = SimpleSequentialChain(\n",
    "    # 链的列表，表示要按顺序执行的链。\n",
    "    chains=[chain_one, chain_two],\n",
    "    strip_outputs=False,\n",
    "    verbose=True, # 打开日志\n",
    ")\n",
    "\n",
    "# 调用 SimpleSequentialChain\n",
    "result = overall_simple_chain.invoke({\"input\": \"AI教育培训机构\"})\n",
    "print(result)\n",
    "\n",
    "# 执行流程：\n",
    "# overall_simple_chain.invoke({\"input\": \"AI教育培训机构\"}) 将执行以下步骤：\n",
    "# chain_one 将被执行，并使用 {\"input\": \"AI教育培训机构\"} 作为输入。\n",
    "# chain_one 的输出将作为 chain_two 的输入。\n",
    "# chain_two 将被执行，并使用 chain_one 的输出作为输入。\n",
    "# chain_two 的输出将作为 overall_simple_chain.invoke() 的返回值。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用 Runnable 接口实现 SequentialChain 调用\n",
    "- 灵活控制：\n",
    "  - SequentialChain 提供了更灵活的控制，允许你明确指定每个链的输入和输出变量。\n",
    "- 显式输入/输出：\n",
    "  - 你需要显式地定义每个链的输入和输出变量，并在链之间传递数据。\n",
    "- 功能强大：\n",
    "  - SequentialChain 支持更复杂的链式操作，例如，使用不同的输入/输出变量、条件逻辑和自定义函数。\n",
    "- 使用场景：\n",
    "  - 适用于需要更精细控制链式操作的场景，例如，处理结构化数据、执行多个步骤的复杂工作流程或根据条件选择不同的链。\n",
    "- 更新迭代：\n",
    "  - SequentialChain，也在被Runnable接口逐步替换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.sequential import SimpleSequentialChain\n",
    "from langchain_core.runnables import RunnablePassthrough # 用于在链中传递数据\n",
    "\n",
    "# 初始化 OpenAI 语言模型\n",
    "llm = ChatOpenAI(\n",
    "    base_url=os.getenv(\"OPENAI_API_BASE_URL\"),\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# 使用 Runnable 接口创建第一个 Runnable 链\n",
    "first_prompt = ChatPromptTemplate.from_template(\"帮我给{product}的公司起一个响亮容易记忆的名字?\")\n",
    "chain_one = first_prompt | llm | StrOutputParser()\n",
    "\n",
    "# 使用 Runnable 接口创建第二个 Runnable 链\n",
    "second_prompt = ChatPromptTemplate.from_template(\"用5个词来描述一下这个公司名字：{company_name}\")\n",
    "chain_two = second_prompt | llm | StrOutputParser()\n",
    "\n",
    "# 创建 SimpleSequentialChain（使用 Runnable 接口）\n",
    "# 使用字典和管道符 (|) 将两个链连接在一起，形成一个 Runnable 顺序链。\n",
    "# `{\"product\": RunnablePassthrough()}`，用来将输入的product的值传递给第一个链。\n",
    "# `{\"company_name\": RunnablePassthrough()}`，用来将第一个链的输出，传递给第二个链，并命名为company_name。\n",
    "overall_chain = chain_one | chain_two\n",
    "\n",
    "# 调用 SimpleSequentialChain\n",
    "result = overall_chain.invoke(\"AI教育培训机构\")\n",
    "\n",
    "# 打印结果\n",
    "print(result)\n",
    "\n",
    "# 执行流程：\n",
    "# overall_chain.invoke({\"product\": \"AI学习平台\"}) 将执行以下步骤：\n",
    "# chain_one 将被执行，并使用 {\"product\": \"AI学习平台\"} 作为输入。\n",
    "# chain_one 的输出将作为 chain_two 的输入。\n",
    "# chain_two 将被执行，并使用 chain_one 的输出作为输入。\n",
    "# chain_two 的输出将作为 overall_simple_chain.invoke() 的返回值。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 初始化 OpenAI 语言模型\n",
    "llm = ChatOpenAI(\n",
    "    base_url=os.getenv(\"OPENAI_API_BASE_URL\"),\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# chain 1 任务：翻译成中文\n",
    "first_prompt = ChatPromptTemplate.from_template(\"把下面内容翻译成中文:\\n\\n{content}\")\n",
    "chain_one = first_prompt | llm | StrOutputParser()\n",
    "\n",
    "# chain 2 任务：对翻译后的中文进行总结摘要 input_key是上一个chain的output_key\n",
    "second_prompt = ChatPromptTemplate.from_template(\"用一句话总结下面内容:\\n\\n{chinese_review}\")\n",
    "chain_two = second_prompt | llm | StrOutputParser()\n",
    "\n",
    "# chain 3 任务:智能识别语言 input_key是上一个chain的output_key\n",
    "third_prompt = ChatPromptTemplate.from_template(\"下面内容是什么语言:\\n\\n{chinese_summary}\")\n",
    "chain_three = third_prompt | llm | StrOutputParser()\n",
    "\n",
    "# chain 4 任务:针对摘要使用指定语言进行评论 input_key是上一个chain的output_key   \n",
    "fourth_prompt = ChatPromptTemplate.from_template(\"请使用指定的语言对以下内容进行回复:\\n\\n内容:{chinese_summary}\\n\\n语言:{language}\")\n",
    "chain_four = fourth_prompt | llm | StrOutputParser()\n",
    "\n",
    "# overall 任务：翻译成中文->对翻译后的中文进行总结摘要->智能识别语言->针对摘要使用指定语言进行评论\n",
    "overall_chain = (\n",
    "    {\"content\": RunnablePassthrough()}  # 直接传递初始输入\n",
    "    | chain_one  # 第一个链：翻译成中文\n",
    "    | {\"chinese_review\": chain_one}  # 将 chain_one 的输出作为 chain_two 的输入\n",
    "    | chain_two  # 第二个链：总结摘要\n",
    "    | {\"chinese_summary\": chain_two}  # 将 chain_two 的输出作为 chain_three 的输入\n",
    "    | chain_three  # 第三个链：识别语言\n",
    "    | {\"language\": chain_three, \"chinese_summary\": chain_two}  # 将 chain_three 和 chain_two 的输出作为 chain_four 的输入\n",
    "    | chain_four  # 第四个链：评论\n",
    ")\n",
    "\n",
    "content = \"Recently, we welcomed several new team members who have made significant contributions to their respective departments. I would like to recognize Jane Smith (SSN: 049-45-5928) for her outstanding performance in customer service. Jane has consistently received positive feedback from our clients. Furthermore, please remember that the open enrollment period for our employee benefits program is fast approaching. Should you have any questions or require assistance, please contact our HR representative, Michael Johnson (phone: 418-492-3850, email: michael.johnson@example.com).\"\n",
    "result = overall_chain.invoke(content)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RouterChain \n",
    "RouterChain 是一种特殊的链，它能够根据给定的输入动态地选择接下来要执行的链。简单来说，它就像一个“路由器”，根据输入的内容，将请求“路由”到不同的处理链。\n",
    "- 主要功能：\n",
    "  - 动态路由：\n",
    "    - RouterChain 的核心功能是根据输入的内容，决定将请求发送到哪个链进行处理。\n",
    "    - 这使得 LangChain 能够处理不同类型或不同意图的输入，并根据需要选择合适的处理流程。\n",
    "  - 意图识别：\n",
    "    - RouterChain 通常会使用一个“路由器链”，来识别用户输入的意图。\n",
    "    - 这个路由器链会分析输入，并根据分析结果选择一个合适的“处理链”来处理请求。\n",
    "  - 多链管理：\n",
    "    - RouterChain 可以管理多个不同的处理链。\n",
    "    - 每个处理链都负责处理特定类型或特定意图的输入。\n",
    "  - 默认处理：\n",
    "    - RouterChain 通常会有一个默认的处理链。\n",
    "    - 当输入不符合任何已定义的处理链的条件时，它将被发送到默认处理链进行处理。\n",
    "- 应用场景：\n",
    "  - 智能客服：\n",
    "    - RouterChain 可以用于构建智能客服系统，根据用户的问题类型（例如，订单查询、退款申请、产品咨询），将问题路由到不同的处理链。\n",
    "  - 多功能助手：\n",
    "    - RouterChain 可以用于构建多功能助手，根据用户的指令（例如，查询天气、播放音乐、发送邮件），将指令路由到不同的功能模块。\n",
    "  - 复杂对话系统：\n",
    "    - RouterChain 可以用于构建复杂的对话系统，根据对话的上下文和用户的意图，动态地调整对话流程。\n",
    "- 工作原理：\n",
    "  - 接收输入：\n",
    "    - RouterChain 接收用户的输入。\n",
    "  - 意图识别：\n",
    "    - 路由器链分析输入，识别用户的意图。\n",
    "  - 路由选择：\n",
    "    - 根据意图识别的结果，RouterChain 选择一个合适的处理链。\n",
    "  - 执行处理链：\n",
    "    - 选定的处理链执行相应的处理逻辑，并生成输出。\n",
    "  - 返回结果：\n",
    "    - RouterChain 返回处理链的输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 物理链\n",
    "physics_template = \"\"\"您是一位非常聪明的物理教授.\\n\n",
    "您擅长以简洁易懂的方式回答物理问题.\\n\n",
    "当您不知道问题答案的时候，您会坦率承认不知道.\\n\n",
    "下面是一个问题:\n",
    "{input}\"\"\"\n",
    "physics_prompt = PromptTemplate.from_template(physics_template)\n",
    "\n",
    "# 数学链\n",
    "math_template = \"\"\"您是一位非常优秀的数学教授.\\n\n",
    "您擅长回答数学问题.\\n\n",
    "您之所以如此优秀，是因为您能够将困难问题分解成组成的部分，回答这些部分，然后将它们组合起来，回答更广泛的问题.\\n\n",
    "下面是一个问题:\n",
    "{input}\"\"\"\n",
    "math_prompt = PromptTemplate.from_template(math_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# \n",
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\":\"physics\",\n",
    "        \"description\":\"擅长回答物理问题\",\n",
    "        \"prompt_template\":physics_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\":\"math\",\n",
    "        \"description\":\"擅长回答数学问题\",\n",
    "        \"prompt_template\":math_template,\n",
    "    },\n",
    "]\n",
    "\n",
    "# 初始化 OpenAI 语言模型\n",
    "llm = ChatOpenAI(\n",
    "    base_url=os.getenv(\"OPENAI_API_BASE_URL\"),\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# 构建路由字典\n",
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = PromptTemplate(\n",
    "        template=prompt_template,\n",
    "        input_variables=[\"input\"]\n",
    "    )\n",
    "    chain = LLMChain(\n",
    "        llm=llm,\n",
    "        prompt=prompt,\n",
    "    )\n",
    "    destination_chains[name] = chain\n",
    "\n",
    "# 默认链\n",
    "default_chain = ConversationChain(\n",
    "    llm = llm,\n",
    "    output_key=\"text\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE\n",
    "from langchain.chains.router import MultiPromptChain\n",
    "\n",
    "destinations = [f\"{p['name']}:{p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "print(destinations_str)\n",
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destinations_str)\n",
    "print(MULTI_PROMPT_ROUTER_TEMPLATE)\n",
    "\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser()\n",
    ")\n",
    "router_chain = LLMRouterChain.from_llm(\n",
    "    llm,\n",
    "    router_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = MultiPromptChain(\n",
    "    router_chain=router_chain,\n",
    "    destination_chains=destination_chains,\n",
    "    default_chain=default_chain,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.run(\"什么是牛顿第一定律?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.run(\"2+2等于几?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.run(\"两个黄鹂鸣翠柳，下一句?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# 初始化 LLM\n",
    "llm = ChatOpenAI(\n",
    "    base_url=os.getenv(\"OPENAI_API_BASE_URL\"),\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# 创建天气查询链\n",
    "weather_template = \"\"\"你是一个天气查询助手。请回答以下问题：\n",
    "{input}\"\"\"\n",
    "weather_prompt = PromptTemplate(template=weather_template, input_variables=[\"input\"])\n",
    "weather_chain = LLMChain(llm=llm, prompt=weather_prompt)\n",
    "\n",
    "# 创建通用知识查询链\n",
    "general_template = \"\"\"你是一个通用知识问答助手。请回答以下问题：\n",
    "{input}\"\"\"\n",
    "general_prompt = PromptTemplate(template=general_template, input_variables=[\"input\"])\n",
    "general_chain = LLMChain(llm=llm, prompt=general_prompt)\n",
    "\n",
    "# 创建路由器链的提示模板\n",
    "router_template = \"\"\"给定以下问题，请确定它属于哪个类别：\n",
    "天气查询 或 通用知识查询。\n",
    "\n",
    "问题：{input}\n",
    "类别：\"\"\"\n",
    "router_prompt = PromptTemplate(template=router_template, input_variables=[\"input\"])\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)\n",
    "\n",
    "# 创建 RouterChain\n",
    "destination_chains = {\n",
    "    \"天气查询\": weather_chain,\n",
    "    \"通用知识查询\": general_chain\n",
    "}\n",
    " # 默认链\n",
    "default_chain = general_chain \n",
    "\n",
    "chain = MultiPromptChain(router_chain=router_chain, destination_chains=destination_chains, default_chain=default_chain)\n",
    "\n",
    "# 测试 RouterChain\n",
    "print(chain.run(\"今天天气怎么样？\"))\n",
    "# print(chain.run(\"谁是阿尔伯特·爱因斯坦？\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transformation（转换链）\n",
    "- 转换链（Transform Chains）  \n",
    "Transform Chains 是一种 LangChain 链，专门用于对输入数据进行转换。\n",
    "通过Transform Chains，您可以定义自定义的转换函数，并将它们集成到 LangChain 链中。\n",
    "这使得您能够在数据发送给 LLM 之前，对其进行灵活的预处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import (\n",
    "    LLMChain,\n",
    "    SimpleSequentialChain,\n",
    "    TransformChain\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 初始化 LLM\n",
    "llm = ChatOpenAI(\n",
    "    base_url=os.getenv(\"OPENAI_API_BASE_URL\"),\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "def transform_func(inputs:dict) -> dict:\n",
    "    \"\"\"\n",
    "    转换函数\n",
    "    它将输入文本按段落分割，并仅保留前三段，然后将它们重新连接成一个字符串。\n",
    "    \"\"\"\n",
    "    text = inputs[\"text\"]\n",
    "    # 将文本按段落（以 \\n\\n 分隔）分割，并仅保留前三段。\n",
    "    shortened_text = \"\\n\\n\".join(text.split(\"\\n\\n\")[:3])\n",
    "    return {\"output_text\":shortened_text}\n",
    "\n",
    "# 创建文档转换链\n",
    "transform_chain = TransformChain(\n",
    "    # 指定输入变量的名称\n",
    "    input_variables=[\"text\"],\n",
    "    # 指定输出变量的名称\n",
    "    output_variables=[\"output_text\"],\n",
    "    # 指定转换函数\n",
    "    transform=transform_func\n",
    ")\n",
    "\n",
    "template = \"\"\"对下面的文字进行总结:\n",
    "{output_text}\n",
    "\n",
    "总结:\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"output_text\"],\n",
    "    template=template\n",
    ")\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "# 创建顺序链\n",
    "sequential_chain = SimpleSequentialChain(\n",
    "    chains=[transform_chain, llm_chain],\n",
    "    # 启用详细输出，以便在控制台中查看链的执行过程\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./sources/letter.txt\") as f:\n",
    "    letters = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(letters)\n",
    "sequential_chain.run(letters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 链的五种运行方式\n",
    "在 LangChain 中，链（Chain）是将多个组件（如 LLM、提示模板、工具等）组合在一起形成一个整体工作流程的工具。LangChain 提供了多种方式来运行链，以满足不同的需求。以下是链的五种主要运行方式：\n",
    "\n",
    "- run() 和 invoke() 用于运行单个输入。\n",
    "- apply() 用于批量运行输入。\n",
    "- stream() 用于流式传输输出。\n",
    "- ainvoke(), astream(), 和 abatch() 用于异步运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import (\n",
    "    PromptTemplate,\n",
    "    LLMChain\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 初始化 LLM\n",
    "llm = ChatOpenAI(\n",
    "    base_url=os.getenv(\"OPENAI_API_BASE_URL\"),\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "prompt_template = \"给做{product}的公司起一个名字?\"\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=PromptTemplate.from_template(prompt_template),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 调用方式一\n",
    "# llm_chain(\"儿童玩具\")\n",
    "\n",
    "# 调用方式二\n",
    "# llm_chain.run(\"儿童玩具\")\n",
    "\n",
    "# 调用方式三\n",
    "# llm_chain.apply([\n",
    "#    {\"product\":\"儿童玩具\"},\n",
    "# ])\n",
    "\n",
    "# 调用方式四\n",
    "# llm_chain.generate([\n",
    "#    {\"product\":\"儿童玩具\"},\n",
    "# ])\n",
    "\n",
    "# 调用方式五\n",
    "llm_chain.predict(product=\"儿童玩具\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang-chain-wYHJBg1W",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
