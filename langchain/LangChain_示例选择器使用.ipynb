{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cc037c0",
   "metadata": {},
   "source": [
    "## 示例选择器使用\n",
    "- 根据长度动态选择\n",
    "- 根据语义相似度动态选择（最大余弦）\n",
    "- 使用最大边际相关性进行选择（MMR）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fbffca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 加载 .env 文件中的环境变量\n",
    "load_dotenv(override=True)  # 使用 override=True 确保加载最新的 .env 数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845e5e9f",
   "metadata": {},
   "source": [
    "### 根据长度动态选择\n",
    "根据用户的输入、提示词总长度结合模型窗口大小来动态计算可以容纳的示例个数\n",
    "原理：\n",
    "    根据示例的长度来选择。你可以选择那些长度最短的示例（如果提示词长度有限），或者最长的示例（如果需要更全面的上下文）。\n",
    "场景：\n",
    "    当你需要确保整个提示词的总长度不超过 LLM 的上下文窗口限制时，这种方法非常有用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d849496b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['input'] input_types={} partial_variables={} example_selector=LengthBasedExampleSelector(examples=[{'input': 'happy', 'output': 'sad'}, {'input': 'tired', 'output': 'sleepy'}, {'input': 'frustrated', 'output': 'bored'}, {'input': 'sick', 'output': 'healthy'}, {'input': 'hungry', 'output': 'full'}, {'input': 'lonely', 'output': 'connected'}, {'input': 'angry', 'output': 'calm'}, {'input': 'stressed', 'output': 'calm'}, {'input': 'excited', 'output': 'calm'}, {'input': 'scared', 'output': 'calm'}, {'input': '高兴', 'output': '悲伤'}], example_prompt=PromptTemplate(input_variables=['input', 'output'], input_types={}, partial_variables={}, template='原词: {input}\\n反义词: {output}'), get_text_length=<function _get_length_based at 0x750335c0ec00>, max_length=25, example_text_lengths=[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]) example_prompt=PromptTemplate(input_variables=['input', 'output'], input_types={}, partial_variables={}, template='原词: {input}\\n反义词: {output}') suffix='原词: {input}\\n反义词:' prefix='请给出输入的反义词'\n",
      "请给出输入的反义词\n",
      "\n",
      "原词: happy\n",
      "反义词: sad\n",
      "\n",
      "原词: tired\n",
      "反义词: sleepy\n",
      "\n",
      "原词: frustrated\n",
      "反义词: bored\n",
      "\n",
      "原词: sick\n",
      "反义词: healthy\n",
      "\n",
      "原词: hungry\n",
      "反义词: full\n",
      "\n",
      "原词: lonely\n",
      "反义词: connected\n",
      "\n",
      "原词: sad\n",
      "反义词:\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.example_selectors import LengthBasedExampleSelector\n",
    "from langchain_core.prompts import PromptTemplate, FewShotPromptTemplate\n",
    "\n",
    "# 假设已经有的提示词示例组，示例是大模型的输入输出\n",
    "examples = [\n",
    "    {\"input\": \"happy\", \"output\": \"sad\"},\n",
    "    {\"input\": \"tired\", \"output\": \"sleepy\"},\n",
    "    {\"input\": \"frustrated\", \"output\": \"bored\"},\n",
    "    {\"input\": \"sick\", \"output\": \"healthy\"},\n",
    "    {\"input\": \"hungry\", \"output\": \"full\"},\n",
    "    {\"input\": \"lonely\", \"output\": \"connected\"},\n",
    "    {\"input\": \"angry\", \"output\": \"calm\"},\n",
    "    {\"input\": \"stressed\", \"output\": \"calm\"},\n",
    "    {\"input\": \"excited\", \"output\": \"calm\"},\n",
    "    {\"input\": \"scared\", \"output\": \"calm\"},\n",
    "    {\"input\": \"高兴\", \"output\": \"悲伤\"},\n",
    "]\n",
    "\n",
    "# 构建提示词模板\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"原词: {input}\\n反义词: {output}\",\n",
    ")\n",
    "\n",
    "# 调用长度示例选择器\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,  # 传入提示词示例组\n",
    "    example_prompt=example_prompt,  # 传入提示词模板\n",
    "    max_length=25,  # 设置格式化后的提示词最大长度\n",
    "    # 设置获取长度的方法，不设置默认使用get_text_length，如果默认分词器计算不满足，可以自己扩展\n",
    "    # get_text_length=lambda x: len(x),  # 设置获取文本长度的函数\n",
    ")\n",
    "\n",
    "\n",
    "# 使用示例提示词模板来实现动态示例选择器的调用\n",
    "dynmic_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,  # 使用示例选择器\n",
    "    example_prompt=example_prompt,  # 使用示例提示词模板\n",
    "    prefix=\"请给出输入的反义词\",  # 设置前缀提示词\n",
    "    suffix=\"原词: {input}\\n反义词:\",  # 设置后缀提示词\n",
    "    input_variables=[\"input\"],  # 设置输入变量\n",
    ")\n",
    "\n",
    "# 打印调用示例选择器之后的模板\n",
    "print(dynmic_prompt)\n",
    "\n",
    "# 格式化提示词\n",
    "print(dynmic_prompt.format(input=\"sad\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71782ae",
   "metadata": {},
   "source": [
    "### 根据语义相似度动态选择\n",
    "筛选示例组中与输入的语义相似度最高的示例\n",
    "本质：将问题与示例嵌入向量空间后进行搜索比对\n",
    "依赖：向量数据库\n",
    "\n",
    "原理：\n",
    "    这是最常用、最强大的方法。它将用户输入和示例库中的所有示例都转换为向量嵌入（Vector Embeddings），然后计算向量之间的相似度。它会选择与用户输入最相似的几个示例。\n",
    "场景：\n",
    "    当你希望 LLM 能够根据最相关的上下文进行推理时，这种方法最有效。例如，在问答任务中，它能找到与当前问题最相似的过往问答示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76eb448c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: chromadb==0.4.15 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (0.4.15)\n",
      "Requirement already satisfied: requests>=2.28 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from chromadb==0.4.15) (2.32.5)\n",
      "Requirement already satisfied: pydantic>=1.9 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from chromadb==0.4.15) (2.11.7)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from chromadb==0.4.15) (0.7.3)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from chromadb==0.4.15) (0.116.1)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.15) (0.35.0)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from chromadb==0.4.15) (6.7.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from chromadb==0.4.15) (4.14.1)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from chromadb==0.4.15) (3.8.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from chromadb==0.4.15) (1.22.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from chromadb==0.4.15) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from chromadb==0.4.15) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from chromadb==0.4.15) (1.36.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from chromadb==0.4.15) (0.22.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from chromadb==0.4.15) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from chromadb==0.4.15) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from chromadb==0.4.15) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from chromadb==0.4.15) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from chromadb==0.4.15) (1.74.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from chromadb==0.4.15) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from chromadb==0.4.15) (0.17.3)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from chromadb==0.4.15) (33.1.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from chromadb==0.4.15) (9.1.2)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from chromadb==0.4.15) (2.3.2)\n",
      "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from fastapi>=0.95.2->chromadb==0.4.15) (0.47.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from pydantic>=1.9->chromadb==0.4.15) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from pydantic>=1.9->chromadb==0.4.15) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from pydantic>=1.9->chromadb==0.4.15) (0.4.1)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from starlette<0.48.0,>=0.40.0->fastapi>=0.95.2->chromadb==0.4.15) (4.10.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi>=0.95.2->chromadb==0.4.15) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi>=0.95.2->chromadb==0.4.15) (1.3.1)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (2025.8.3)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (2.9.0.post0)\n",
      "Requirement already satisfied: pyyaml>=5.4.1 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (6.0.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (2.40.3)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (3.3.1)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (2.5.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb==0.4.15) (0.10)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.15) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.15) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.15) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.15) (0.6.1)\n",
      "Requirement already satisfied: coloredlogs in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.15) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.15) (25.2.10)\n",
      "Requirement already satisfied: packaging in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.15) (25.0)\n",
      "Requirement already satisfied: protobuf in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.15) (6.32.0)\n",
      "Requirement already satisfied: sympy in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.15) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb==0.4.15) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb==0.4.15) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.15) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.36.0 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.15) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.36.0 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.15) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from opentelemetry-sdk>=1.2.0->chromadb==0.4.15) (0.57b0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb==0.4.15) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb==0.4.15) (1.9.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from requests>=2.28->chromadb==0.4.15) (3.4.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from tokenizers>=0.13.2->chromadb==0.4.15) (0.34.4)\n",
      "Requirement already satisfied: filelock in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb==0.4.15) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb==0.4.15) (2025.7.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb==0.4.15) (1.1.9)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from typer>=0.9.0->chromadb==0.4.15) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from typer>=0.9.0->chromadb==0.4.15) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from typer>=0.9.0->chromadb==0.4.15) (14.1.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb==0.4.15) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb==0.4.15) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb==0.4.15) (0.1.2)\n",
      "Requirement already satisfied: h11>=0.8 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb==0.4.15) (0.16.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.15) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.15) (1.1.1)\n",
      "Requirement already satisfied: uvloop>=0.15.1 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.15) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.15) (1.1.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.15) (15.0.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.4.15) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.4.15) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# 选择chromadb向量数据库进行向量化和向量比较\n",
    "! pip install chromadb==0.4.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28534af8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for OpenAIEmbeddings\nmodel\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m base_url = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mTONGYI_API_BASE\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m api_key = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mTONGYI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m embeddings = \u001b[43mOpenAIEmbeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mopenai_api_base\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mopenai_api_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# 构建提示词模板\u001b[39;00m\n\u001b[32m     24\u001b[39m example_prompt = PromptTemplate(\n\u001b[32m     25\u001b[39m     input_variables=[\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     26\u001b[39m     template=\u001b[33m\"\u001b[39m\u001b[33m原词: \u001b[39m\u001b[38;5;132;01m{input}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m反义词: \u001b[39m\u001b[38;5;132;01m{output}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     27\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/python/langchain_learn/.venv/lib/python3.12/site-packages/pydantic/main.py:253\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    252\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    255\u001b[39m     warnings.warn(\n\u001b[32m    256\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    257\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    259\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    260\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for OpenAIEmbeddings\nmodel\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type"
     ]
    }
   ],
   "source": [
    "# 使用最大余弦相似度来检索相关示例，以便示例尽量贴近于输入的内容\n",
    "# 在向量空间中查找最近的\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.example_selectors import (\n",
    "    SemanticSimilarityExampleSelector,\n",
    ")\n",
    "from langchain_core.prompts import PromptTemplate, FewShotPromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import TongyiEmbeddings\n",
    "\n",
    "model = os.environ.get(\"TONGYI_MODEL\")\n",
    "base_url = os.environ.get(\"TONGYI_API_BASE\")\n",
    "api_key = os.environ.get(\"TONGYI_API_KEY\")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=model,\n",
    "    openai_api_base=base_url,\n",
    "    openai_api_key=api_key,\n",
    ")\n",
    "\n",
    "\n",
    "# 构建提示词模板\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"原词: {input}\\n反义词: {output}\",\n",
    ")\n",
    "\n",
    "# 一组包含各种性质的反义词示例\n",
    "examples = [\n",
    "    {\"input\": \"happy\", \"output\": \"sad\"},\n",
    "    {\"input\": \"tired\", \"output\": \"sleepy\"},\n",
    "    {\"input\": \"frustrated\", \"output\": \"bored\"},\n",
    "    {\"input\": \"sick\", \"output\": \"healthy\"},\n",
    "    {\"input\": \"hungry\", \"output\": \"full\"},\n",
    "    {\"input\": \"lonely\", \"output\": \"connected\"},\n",
    "    {\"input\": \"angry\", \"output\": \"calm\"},\n",
    "    {\"input\": \"stressed\", \"output\": \"calm\"},\n",
    "    {\"input\": \"excited\", \"output\": \"calm\"},\n",
    "    {\"input\": \"scared\", \"output\": \"calm\"},\n",
    "    {\"input\": \"高兴\", \"output\": \"悲伤\"},\n",
    "]\n",
    "\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    examples=examples,  # 设置示例组\n",
    "    embeddings=embeddings,  # 向量化使用的嵌入模型\n",
    "    vectorstore_cls=Chroma,  # 设置向量库\n",
    "    k=1,  # 获取相似度最高的数量\n",
    ")\n",
    "\n",
    "# 使用示例提示词模板来实现动态示例选择器的调用\n",
    "dynmic_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,  # 使用示例选择器\n",
    "    example_prompt=example_prompt,  # 使用示例提示词模板\n",
    "    prefix=\"请给出输入的反义词\",  # 设置前缀提示词\n",
    "    suffix=\"原词: {input}\\n反义词:\",  # 设置后缀提示词\n",
    "    input_variables=[\"input\"],  # 设置输入变量\n",
    ")\n",
    "\n",
    "# 使用\n",
    "print(dynmic_prompt.format(input=\"sad\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be90e96d",
   "metadata": {},
   "source": [
    "### 按最大边际相关性选择（Maximal Marginal Relevance, MMR）\n",
    "原理：\n",
    "    MMR 是一种更高级的相似性选择。它不仅考虑示例与用户输入的相似性，还考虑被选中的示例之间的差异性。MMR 试图在相关性和多样性之间找到平衡，以避免选择多个内容高度相似的示例。\n",
    "    MMR 是一种在信息检索中常用的方法，它的目标是在相关性和多样性之间找到一个平衡。MMR会首先找出与输入最相似（即余弦相似度最大）的样本。然后在迭代添加样本的过程中，对于与已选择样本过于接近（即相似度过高）的样本惩罚。MMR既能确保选出来的样本于输入高度相关，又能保证选出的样本之间有足够的多样性。关注如何在相关性和多样性之间找到平衡。\n",
    "场景：\n",
    "    当你需要提供一组多样化但又都与问题相关的示例时，MMR 效果最好。这可以防止模型过拟合于某个特定的示例类型。\n",
    "依赖：向量数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d00f850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting faiss-cpu\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/4c/c9/be4e52fd96be601fefb313c26e1259ac2e6b556fb08cc392db641baba8c7/faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m813.7 kB/s\u001b[0m  \u001b[33m0:00:37\u001b[0m0:00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<3.0,>=1.25.0 in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from faiss-cpu) (2.3.2)\n",
      "Requirement already satisfied: packaging in /home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages (from faiss-cpu) (25.0)\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.12.0\n"
     ]
    }
   ],
   "source": [
    "# 这里采用FAISS向量数据库进行向量化和向量比较\n",
    "! pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f3161e",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m      9\u001b[39m examples = [\n\u001b[32m     10\u001b[39m     {\n\u001b[32m     11\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m我在哪里可以找到我的行李？\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m     },\n\u001b[32m     31\u001b[39m ]\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# 示例选择器\u001b[39;00m\n\u001b[32m     34\u001b[39m example_selector = MaxMarginalRelevanceExampleSelector.from_examples(\n\u001b[32m     35\u001b[39m     \u001b[38;5;66;03m# 示例列表\u001b[39;00m\n\u001b[32m     36\u001b[39m     examples,\n\u001b[32m     37\u001b[39m     \u001b[38;5;66;03m# 嵌入模型\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[43mOpenAIEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# 向量数据库\u001b[39;00m\n\u001b[32m     40\u001b[39m     Chroma,\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# 要返回的示例数量\u001b[39;00m\n\u001b[32m     42\u001b[39m     k=\u001b[32m2\u001b[39m,\n\u001b[32m     43\u001b[39m     \u001b[38;5;66;03m# diversity_score 越高，选择的示例差异越大\u001b[39;00m\n\u001b[32m     44\u001b[39m     diversity_score_threshold=\u001b[32m0.5\u001b[39m,\n\u001b[32m     45\u001b[39m )\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# 构建提示词模板\u001b[39;00m\n\u001b[32m     48\u001b[39m example_prompt = PromptTemplate(\n\u001b[32m     49\u001b[39m     input_variables=[\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m\"\u001b[39m], template=\u001b[33m\"\u001b[39m\u001b[33m输入: \u001b[39m\u001b[38;5;132;01m{input}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m输出: \u001b[39m\u001b[38;5;132;01m{output}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     50\u001b[39m )\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/python/langchain_learn/.venv/lib/python3.12/site-packages/langchain_openai/embeddings/base.py:328\u001b[39m, in \u001b[36mOpenAIEmbeddings.validate_environment\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    326\u001b[39m         \u001b[38;5;28mself\u001b[39m.http_client = httpx.Client(proxy=\u001b[38;5;28mself\u001b[39m.openai_proxy)\n\u001b[32m    327\u001b[39m     sync_specific = {\u001b[33m\"\u001b[39m\u001b[33mhttp_client\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.http_client}\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     \u001b[38;5;28mself\u001b[39m.client = \u001b[43mopenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mclient_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msync_specific\u001b[49m\u001b[43m)\u001b[49m.embeddings  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.async_client:\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.openai_proxy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.http_async_client:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/python/langchain_learn/.venv/lib/python3.12/site-packages/openai/_client.py:132\u001b[39m, in \u001b[36mOpenAI.__init__\u001b[39m\u001b[34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m    130\u001b[39m     api_key = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    133\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    134\u001b[39m     )\n\u001b[32m    135\u001b[39m \u001b[38;5;28mself\u001b[39m.api_key = api_key\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mOpenAIError\u001b[39m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "from langchain_core.example_selectors import (\n",
    "    MaxMarginalRelevanceExampleSelector,\n",
    ")\n",
    "from langchain_core.prompts import PromptTemplate, FewShotPromptTemplate\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "\n",
    "# 示例库\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"我在哪里可以找到我的行李？\",\n",
    "        \"output\": \"请提供您的航班号，以便我查询您的行李。\",\n",
    "    },\n",
    "    {\"input\": \"我的行李丢了怎么办？\", \"output\": \"请立即联系机场失物招领处。\"},\n",
    "    {\n",
    "        \"input\": \"我想报告一件丢失的物品。\",\n",
    "        \"output\": \"请说明丢失的物品，以及是在哪个航站楼或登机口丢失的。\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"我的包不见了，怎么办？\",\n",
    "        \"output\": \"请向工作人员报告，他们将协助您寻找。\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"我能带我的宠物上飞机吗？\",\n",
    "        \"output\": \"这取决于您的航空公司，请提供您的航空公司名称。\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"我想知道关于宠物旅行的规定。\",\n",
    "        \"output\": \"请提供您的航空公司名称，我们将为您查询相关的旅行规定。\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# 示例选择器\n",
    "example_selector = MaxMarginalRelevanceExampleSelector.from_examples(\n",
    "    # 示例列表\n",
    "    examples,\n",
    "    # 嵌入模型\n",
    "    OpenAIEmbeddings(),\n",
    "    # 向量数据库\n",
    "    FAISS,\n",
    "    # 要返回的示例数量\n",
    "    k=2,\n",
    "    # diversity_score 越高，选择的示例差异越大\n",
    "    diversity_score_threshold=0.5,\n",
    ")\n",
    "\n",
    "# 构建提示词模板\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"], template=\"输入: {input}\\n输出: {output}\\n\"\n",
    ")\n",
    "\n",
    "# 使用选择器创建 Few-Shot Prompt\n",
    "mmr_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"请根据以下示例回答问题。\\n\\n\",\n",
    "    suffix=\"输入: {input}\\n输出:\",\n",
    "    input_variables=[\"input\"],\n",
    ")\n",
    "\n",
    "# 测试示例选择器\n",
    "print(mmr_prompt.format(input=\"我的行李箱在哪里？\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2c66326",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'NGramOverlapExampleSelector' from 'langchain_core.example_selectors' (/home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages/langchain_core/example_selectors/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexample_selectors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      2\u001b[39m     NGramOverlapExampleSelector,\n\u001b[32m      3\u001b[39m )\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprompts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PromptTemplate, FewShotPromptTemplate\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# 示例库\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'NGramOverlapExampleSelector' from 'langchain_core.example_selectors' (/home/jizhe/projects/python/langchain_learn/.venv/lib/python3.12/site-packages/langchain_core/example_selectors/__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain_core.example_selectors import (\n",
    "    NGramOverlapExampleSelector,\n",
    ")\n",
    "from langchain_core.prompts import PromptTemplate, FewShotPromptTemplate\n",
    "\n",
    "# 示例库\n",
    "examples = [\n",
    "    {\"input\": \"苹果是一种水果。\", \"output\": \"是。\"},\n",
    "    {\"input\": \"香蕉是一种水果。\", \"output\": \"是。\"},\n",
    "    {\"input\": \"梨子是一种水果。\", \"output\": \"是。\"},\n",
    "    {\"input\": \"汽车是一种水果。\", \"output\": \"否。\"},\n",
    "    {\"input\": \"飞机是一种交通工具。\", \"output\": \"是。\"},\n",
    "]\n",
    "\n",
    "# 示例选择器\n",
    "example_selector = NGramOverlapExampleSelector.from_examples(\n",
    "    # 示例列表\n",
    "    examples,\n",
    "    # 词语重叠度的 n 值\n",
    "    n=2,\n",
    "    # k 是要返回的示例数量\n",
    "    k=2,\n",
    ")\n",
    "\n",
    "# 构建示例选择器模板\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"], template=\"输入: {input}\\n输出: {output}\\n\"\n",
    ")\n",
    "\n",
    "# 使用选择器创建 Few-Shot Prompt\n",
    "ngram_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"请判断以下句子是否正确。\\n\\n\",\n",
    "    suffix=\"输入: {input}\\n输出:\",\n",
    "    input_variables=[\"input\"],\n",
    ")\n",
    "\n",
    "# 测试示例选择器\n",
    "print(ngram_prompt.format(input=\"橙子是一种水果。\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
