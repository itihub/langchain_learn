{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11e22c87",
   "metadata": {},
   "source": [
    "# 链的高级使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "764f8ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 加载 .env 文件中的环境变量\n",
    "load_dotenv(override=True)  # 使用 override=True 确保加载最新的 .env 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "202ff3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=os.environ.get(\"OPENAPI_MODEL\"),\n",
    "    base_url=os.environ.get(\"OPENAPI_API_BASE\"),\n",
    "    api_key=os.environ.get(\"OPENAPI_API_KEY\"),\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abf2fb4",
   "metadata": {},
   "source": [
    "## 使用@chain修饰符快速将函数变为链"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df2cd52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The topic of this joke is a **pun** that plays on the double meaning of the words \"bare\" and \"bear.\"  \\n\\n- **Literal meaning**: Bears don\\'t wear shoes, so their feet are uncovered (*bare feet*).  \\n- **Pun twist**: Since they\\'re bears, their feet are also *bear feet*.  \\n\\nThe humor comes from the homophones (words that sound the same but have different meanings) \"bare\" and \"bear.\" The joke is lighthearted and centers on wordplay related to bears. 🐻😄'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "# 创建第一个提示词模板：请求关于特定主题的笑话\n",
    "prompt1 = ChatPromptTemplate.from_template(\"Tell me a joke about {topic}.\")\n",
    "# 创建第二个提示词模板：询问笑话的主题时什么\n",
    "prompt2 = ChatPromptTemplate.from_template(\"What is the topic of this joke: {joke}?\")\n",
    "\n",
    "\n",
    "# 使用@chain装饰器定义一个自定义链\n",
    "@chain\n",
    "def custom_chain(text):\n",
    "    # 步骤1：将输入文本填充到第一个提示词模板中\n",
    "    prompt_val1 = prompt1.invoke({\"topic\": text})\n",
    "    # 步骤2：将第一个提示词模板的输出传递给语言模型\n",
    "    output1 = llm.invoke(prompt_val1)\n",
    "    # 步骤3：将语言模型的输出进行解析为字符串\n",
    "    parsed_output1 = StrOutputParser().invoke(output1)\n",
    "\n",
    "    # 步骤4：创建第二个处理链，用于分析笑话主题\n",
    "    # 这个链将提示词模板、模型和字符串解析器串联起来\n",
    "    chain2 = prompt2 | llm | StrOutputParser()\n",
    "\n",
    "    # 步骤5：将第一个链的输出传递给第二个链\n",
    "    output2 = chain2.invoke({\"joke\": parsed_output1})\n",
    "    return output2\n",
    "\n",
    "\n",
    "# 调用自定义链，输入主题\"bears\"(熊)\n",
    "# 整个过程：\n",
    "# 1. 先生成一个关于熊的笑话\n",
    "# 2. 然后分析这个笑话的主题\n",
    "# 3. 返回分析结果\n",
    "custom_chain.invoke(\"bears\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab32eeb",
   "metadata": {},
   "source": [
    "## 在链中使用lambda函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c79960c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='To find the sum of **5** and **30**, follow these simple steps:\\n\\n1. **Identify the numbers to be added:**\\n   \\n   \\\\[\\n   5 \\\\quad \\\\text{and} \\\\quad 30\\n   \\\\]\\n\\n2. **Add the numbers together:**\\n   \\n   \\\\[\\n   5 + 30\\n   \\\\]\\n\\n3. **Calculate the sum:**\\n   \\n   \\\\[\\n   5 + 30 = 35\\n   \\\\]\\n\\n**Final Answer:**\\n\\n\\\\[\\n\\\\boxed{35}\\n\\\\]', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 109, 'prompt_tokens': 14, 'total_tokens': 123, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'deepseek-v3-250324', 'system_fingerprint': None, 'id': '021757570940697076ea4837f74e966daea642e85370365fa4f81', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--4a19aa82-5266-4dd4-a6e0-cf21c6e90eed-0', usage_metadata={'input_tokens': 14, 'output_tokens': 109, 'total_tokens': 123, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# 定义函数\n",
    "\n",
    "\n",
    "def length_function(text):\n",
    "    return len(text)\n",
    "\n",
    "\n",
    "def _multiple_length_function(text1, text2):\n",
    "    return len(text1) * len(text2)\n",
    "\n",
    "\n",
    "def multiple_length_function(_dict):\n",
    "    return _multiple_length_function(_dict[\"text1\"], _dict[\"text2\"])\n",
    "\n",
    "\n",
    "# 创建一个简单的聊天提示模板，询问a和b的和\n",
    "prompt = ChatPromptTemplate.from_template(\"What is the sum of {a} and {b}?\")\n",
    "\n",
    "# 构建一个复杂的处理链\n",
    "chain = (\n",
    "    {\n",
    "        # 处理\"a\"参数：\n",
    "        # 1. 从输入字典中提取“foo\"键的值\n",
    "        # 2. 将提取的值传递给length_function函数，计算其长度\n",
    "        \"a\": itemgetter(\"foo\") | RunnableLambda(length_function),\n",
    "        # 处理\"b\"参数：\n",
    "        # 1. 创建一个包含两个键值对的字典：\n",
    "        #   - \"text1\": 从输入字典中提取“foo\"键的值\n",
    "        #   - \"text2\": 从输入字典中提取“bar\"键的值\n",
    "        # 2. 将这个新字典传递给multiple_length_function函数\n",
    "        \"b\": {\"text1\": itemgetter(\"foo\"), \"text2\": itemgetter(\"bar\")}\n",
    "        | RunnableLambda(multiple_length_function),\n",
    "    }\n",
    "    | prompt  # 将处理后的\"a\"和\"b\"传递给提示模板\n",
    "    | llm  # 将提示模板的输出传递给语言模型\n",
    ")\n",
    "\n",
    "# 调用链处理流程，输入一个包含\"foo\"和\"bar\"键的字典\n",
    "chain.invoke({\"foo\": \"hello\", \"bar\": \"world!\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7305f3",
   "metadata": {},
   "source": [
    "## 在链中自定义支持流输出的函数\n",
    "+ 当链被使用stream或astream调用的时候\n",
    "+ 如果在链中增加自定义函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4eedd190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "棕熊,北极熊,熊猫,马来熊,眼镜熊"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 创建一个聊天提示模板，要求生成5个与给定动物相似的动物名称，以逗号分隔\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"请列出5个与一下动物相似的动物名称，用逗号分隔：{animal}。不要包含数字\"\n",
    ")\n",
    "\n",
    "# 创建一个处理链：提示词模板 -> 语言模型 -> 字符串解析器\n",
    "str_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 流式输出结果，输入为“熊”\n",
    "for chunk in str_chain.stream({\"animal\": \"熊\"}):\n",
    "    print(chunk, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f781adae",
   "metadata": {},
   "source": [
    "### 增加自定义函数\n",
    "+ 聚合当前流传输的输出\n",
    "+ 在生产下一个逗号的时候组合\n",
    "+ 注意：使用yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72e0f460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['棕熊']['北极熊']['熊猫']['马来熊']['眼镜熊']"
     ]
    }
   ],
   "source": [
    "# 定义自定义解析器，将LLM输出的标记迭代器\n",
    "# 按逗号分隔转换为字符串列表\n",
    "from typing import Iterator, List\n",
    "\n",
    "\n",
    "def split_into_list(input: Iterator[str]) -> Iterator[List[str]]:\n",
    "    # 保存部分输入直到遇到逗号\n",
    "    buffer = \"\"\n",
    "    for chunk in input:\n",
    "        # 将当前块添加到缓冲区\n",
    "        buffer += chunk\n",
    "        # 当缓存区中有逗号时\n",
    "        while \",\" in buffer:\n",
    "            # 分割缓存区，逗号前的部分作为一个完整的输出\n",
    "            comma_index = buffer.index(\",\")\n",
    "            # 输出逗号之前的所有内容\n",
    "            yield [buffer[:comma_index].strip()]\n",
    "            # 保存剩余部分用于下一次迭代\n",
    "            buffer = buffer[comma_index + 1 :]\n",
    "\n",
    "    # 输出最后剩余的部分（如果有的话）\n",
    "    yield [buffer.strip()]\n",
    "\n",
    "\n",
    "list_chain = str_chain | split_into_list\n",
    "\n",
    "for chunk in list_chain.stream({\"animal\": \"熊\"}):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6f2933",
   "metadata": {},
   "source": [
    "### yield 与 return 区别\n",
    "+ return函数立即计算并返回所有结果，而yield函数按需计算结果\n",
    "+ return函数返回一个数据结构（如列表），yield函数返回一个生成器对象\n",
    "+ yield函数可以处理潜在的无限序列，而return函数必须在有限时间内完成\n",
    "+ 生成器对象是一次性的，遍历完后就被消耗完毕，而return返回的数据结构可以重复使用\n",
    "+ yield 特别适合处理大数据集或流式数据，因为它不需要一次性将所有数据加载到内容中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd37593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用 return 函数: [0, 1, 4, 9, 16]\n",
      "类型： <class 'list'>\n",
      "遍历结果: 0\n",
      "遍历结果: 1\n",
      "遍历结果: 4\n",
      "遍历结果: 9\n",
      "遍历结果: 16\n"
     ]
    }
   ],
   "source": [
    "# 使用return\n",
    "def get_squares_return(n):\n",
    "    \"\"\"返回包含0到n-1的平方的列表\"\"\"\n",
    "    result = []\n",
    "    for i in range(n):\n",
    "        result.append(i * i)\n",
    "    return result  # 一次性返回所有结果\n",
    "\n",
    "\n",
    "# 使用 return 函数\n",
    "squares = get_squares_return(5)\n",
    "print(\"使用 return 函数:\", squares)  # 输出: [0, 1, 4, 9, 16]\n",
    "print(\"返回类型：\", type(squares))  # 输出: <class 'list'>\n",
    "\n",
    "# 遍历结果\n",
    "for num in squares:\n",
    "    print(\"遍历结果:\", num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7635226a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用 yield 函数: <generator object get_squares_yield at 0x7c128db31cb0>\n",
      "返回类型： <class 'generator'>\n",
      "遍历结果: 0\n",
      "遍历结果: 1\n",
      "遍历结果: 4\n",
      "遍历结果: 9\n",
      "遍历结果: 16\n",
      "再次遍历\n"
     ]
    }
   ],
   "source": [
    "# 使用 yield\n",
    "def get_squares_yield(n):\n",
    "    \"\"\"生成包含0到n-1的平方的值\"\"\"\n",
    "    for i in range(n):\n",
    "        yield i * i  # 按需生成结果\n",
    "\n",
    "\n",
    "# 使用 yield 函数\n",
    "squares_gen = get_squares_yield(5)\n",
    "print(\n",
    "    \"使用 yield 函数:\", squares_gen\n",
    ")  # 输出: <generator object get_squares_yield at 0x...>\n",
    "print(\"返回类型：\", type(squares_gen))  # 输出: <class 'generator'>\n",
    "\n",
    "# 遍历结果\n",
    "for num in squares_gen:\n",
    "    print(\"遍历结果:\", num)\n",
    "\n",
    "# 再次遍历生成器\n",
    "print(\"再次遍历\")\n",
    "for num in squares_gen:\n",
    "    print(\"再次遍历结果:\", num)  # 不会输出任何内容，因为生成器已经被消耗完毕"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144e2006",
   "metadata": {},
   "source": [
    "## 使用RunnablePassthrough来传递值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a010c1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'passed': {'num': 1}, 'modified': 2}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "# 创建一个可以并行运行的处理流程\n",
    "runnable = RunnableParallel(\n",
    "    passed=RunnablePassthrough(),  # 第一个处理器：直接传入输入，不做修改\n",
    "    modified=lambda x: x[\"num\"] + 1,  # 第二个处理器：取出输入中的“num”值并+1\n",
    ")\n",
    "\n",
    "# 执行这个处理流程，输入时一个包含“num”字段的字典\n",
    "runnable.invoke({\"num\": 1})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a9696a",
   "metadata": {},
   "source": [
    "## LCEL支持在运行时候对链进行配置\n",
    "+ 动态改写模型的温度\n",
    "+ 动态切换提示词"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f21848",
   "metadata": {},
   "source": [
    "### 动态改写模型温度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f53bc3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "好的，我将随机挑选一个整数。以下是结果：\n",
      "\n",
      "**随机整数：** 42\n",
      "好的，以下是一个随机挑选的整数：\n",
      "\n",
      "**42**  \n",
      "\n",
      "（*注：虽然这个数字看起来像是“生命、宇宙以及任何事情的终极答案”，但它确实是随机生成的！如果需要其他随机数，可以告诉我范围或数量哦~*）\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=os.environ.get(\"OPENAPI_MODEL\"),\n",
    "    base_url=os.environ.get(\"OPENAPI_API_BASE\"),\n",
    "    api_key=os.environ.get(\"OPENAPI_API_KEY\"),\n",
    "    temperature=0,\n",
    ").configurable_fields(\n",
    "    temperature=ConfigurableField(\n",
    "        id=\"llm_temperature\",\n",
    "        name=\"LLM Temperature\",\n",
    "        description=\"Temperature for response randomness\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# 未修改temperature\n",
    "response1 = llm.invoke(\"随意挑选一个随机数，输出为一个整数\")\n",
    "print(response1.content)\n",
    "\n",
    "# 动态修改temperature\n",
    "response2 = llm.with_config(configurable={\"llm_temperature\": 0.9}).invoke(\n",
    "    \"随意挑选一个随机数，输出为一个整数\"\n",
    ")\n",
    "print(response2.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de8def4",
   "metadata": {},
   "source": [
    "### 链的提示词动态切换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "681a4876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[HumanMessage(content=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: foo \\nContext: bar \\nAnswer:\", additional_kwargs={}, response_metadata={})]\n",
      "messages=[HumanMessage(content=\"[INST]<<SYS>> You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.<</SYS>> \\nQuestion: foo \\nContext: bar \\nAnswer: [/INST]\", additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.runnables.hub import HubRunnable\n",
    "\n",
    "prompt = HubRunnable(\"rlm/rag-prompt\").configurable_fields(\n",
    "    owner_repo_commit=ConfigurableField(\n",
    "        id=\"hub_commit\",\n",
    "        name=\"Hub Commit\",\n",
    "        description=\"The Hub commit to pull from\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# 未切换提示词\n",
    "prompt_value1 = prompt.invoke({\"question\": \"foo\", \"context\": \"bar\"})\n",
    "print(prompt_value1)\n",
    "\n",
    "# 动态切换提示词\n",
    "prompt_value2 = prompt.with_config(\n",
    "    configurable={\"hub_commit\": \"rlm/rag-prompt-llama\"}\n",
    ").invoke({\"question\": \"foo\", \"context\": \"bar\"})\n",
    "print(prompt_value2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf37319",
   "metadata": {},
   "source": [
    "## 为链添加记忆能力\n",
    "+ 注意：简单的链的记忆添加可以使用v0.2方式，复杂的记忆官方推荐使用LangGraph\n",
    "+ 短时记忆：InMemoryHistory\n",
    "+ 长时记忆：RunnableWithMessageHistory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58972534",
   "metadata": {},
   "source": [
    "### 短时记忆：InMemoryHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40a4f792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': InMemoryHistory(messages=[AIMessage(content='你好', additional_kwargs={}, response_metadata={})])}\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "\n",
    "\n",
    "class InMemoryHistory(BaseChatMessageHistory, BaseModel):\n",
    "    \"\"\"内存中实现的聊天消息历史记录.\"\"\"\n",
    "\n",
    "    messages: List[BaseMessage] = Field(\n",
    "        default_factory=list\n",
    "    )  # 使用空列表作为默认值存储消息\n",
    "\n",
    "    def add_message(self, message: List[BaseMessage]) -> None:\n",
    "        \"\"\"添加一组消息到存储中.\"\"\"\n",
    "        self.messages.append(message)\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        \"\"\"Clear the history.\"\"\"\n",
    "        self.messages = []\n",
    "\n",
    "\n",
    "# 这里我们使用全局遍历来存储聊天消息历史\n",
    "# 这样可以更容易地检查它以查看底层结果\n",
    "store = {}  # 创建空字典用于存储不同会话的历史记录\n",
    "\n",
    "\n",
    "def get_by_session_id(session_id: str) -> BaseChatMessageHistory:\n",
    "    \"\"\"\n",
    "    根据会话ID获取历史记录.\n",
    "    \"\"\"\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryHistory()  # 为新会话创建新的历史记录对象\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "# 获取会话ID为“1”的历史记录\n",
    "history = get_by_session_id(\"1\")\n",
    "# 添加一条AI消息到历史记录\n",
    "history.add_message(AIMessage(content=\"你好\"))\n",
    "# 打印存储的所有历史记录\n",
    "print(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7300885",
   "metadata": {},
   "source": [
    "### 在链中增加短期记忆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5cae5529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='余弦（cosine）是三角函数中的一种基本函数，通常表示为 \\\\(\\\\cos \\\\theta\\\\)，其中 \\\\(\\\\theta\\\\) 是一个角度。余弦函数的定义和含义可以从多个角度理解：\\n\\n### 1. **直角三角形中的定义**\\n在直角三角形中，余弦表示**邻边与斜边的比值**：\\n\\\\[\\n\\\\cos \\\\theta = \\\\frac{\\\\text{邻边}}{\\\\text{斜边}}\\n\\\\]\\n例如，若角 \\\\(\\\\theta\\\\) 的邻边长度为 \\\\(a\\\\)，斜边长度为 \\\\(c\\\\)，则 \\\\(\\\\cos \\\\theta = \\\\frac{a}{c}\\\\)。\\n\\n### 2. **单位圆上的定义**\\n在直角坐标系中，以原点为中心、半径为1的单位圆上，任意角度 \\\\(\\\\theta\\\\) 对应的终边与单位圆的交点坐标为 \\\\((\\\\cos \\\\theta, \\\\sin \\\\theta)\\\\)。此时：\\n- **余弦值**是该点的横坐标（\\\\(x\\\\) 坐标）。\\n- 当角度 \\\\(\\\\theta\\\\) 变化时，\\\\(\\\\cos \\\\theta\\\\) 的值在 \\\\([-1, 1]\\\\) 之间周期性波动。\\n\\n### 3. **周期性函数**\\n余弦函数是周期为 \\\\(2\\\\pi\\\\)（或 \\\\(360^\\\\circ\\\\)）的周期函数，满足：\\n\\\\[\\n\\\\cos (\\\\theta + 2\\\\pi) = \\\\cos \\\\theta\\n\\\\]\\n其图像为一条连续的波浪线（余弦曲线），关于 \\\\(y\\\\) 轴对称（偶函数）。\\n\\n### 4. **级数展开**\\n余弦可以通过无限级数（泰勒级数）表示：\\n\\\\[\\n\\\\cos \\\\theta = 1 - \\\\frac{\\\\theta^2}{2!} + \\\\frac{\\\\theta^4}{4!} - \\\\frac{\\\\theta^6}{6!} + \\\\cdots \\\\quad (\\\\theta \\\\text{为弧度})\\n\\\\]\\n\\n### 5. **应用领域**\\n- **几何学**：计算角度或边长。\\n- **物理学**：描述振动、波动（如简谐运动）。\\n- **工程学**：信号处理、傅里叶分析。\\n- **计算机图形学**：旋转和坐标变换。\\n\\n### 示例\\n若 \\\\(\\\\theta = 60^\\\\circ\\\\)，则 \\\\(\\\\cos 60^\\\\circ = 0.5\\\\)（即邻边为斜边的一半）。\\n\\n总结来说，余弦是描述角度与直角三角形边长关系或单位圆上坐标关系的函数，广泛应用于数学和科学领域。' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 486, 'prompt_tokens': 15, 'total_tokens': 501, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'deepseek-v3-250324', 'system_fingerprint': None, 'id': '021757576121871557788d0d3fd642eba8bd023171b2dbe5f9407', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--a441c0e1-a2ee-422e-847d-96c2e5352288-0' usage_metadata={'input_tokens': 15, 'output_tokens': 486, 'total_tokens': 501, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}\n",
      "{'1': InMemoryHistory(messages=[AIMessage(content='你好', additional_kwargs={}, response_metadata={}), HumanMessage(content='余弦的含义是什么？', additional_kwargs={}, response_metadata={}), AIMessage(content='余弦（cosine）是三角函数中的一种基本函数，通常表示为 \\\\(\\\\cos \\\\theta\\\\)，其中 \\\\(\\\\theta\\\\) 是一个角度。余弦函数的定义和含义可以从多个角度理解：\\n\\n### 1. **直角三角形中的定义**\\n在直角三角形中，余弦表示**邻边与斜边的比值**：\\n\\\\[\\n\\\\cos \\\\theta = \\\\frac{\\\\text{邻边}}{\\\\text{斜边}}\\n\\\\]\\n例如，若角 \\\\(\\\\theta\\\\) 的邻边长度为 \\\\(a\\\\)，斜边长度为 \\\\(c\\\\)，则 \\\\(\\\\cos \\\\theta = \\\\frac{a}{c}\\\\)。\\n\\n### 2. **单位圆上的定义**\\n在直角坐标系中，以原点为中心、半径为1的单位圆上，任意角度 \\\\(\\\\theta\\\\) 对应的终边与单位圆的交点坐标为 \\\\((\\\\cos \\\\theta, \\\\sin \\\\theta)\\\\)。此时：\\n- **余弦值**是该点的横坐标（\\\\(x\\\\) 坐标）。\\n- 当角度 \\\\(\\\\theta\\\\) 变化时，\\\\(\\\\cos \\\\theta\\\\) 的值在 \\\\([-1, 1]\\\\) 之间周期性波动。\\n\\n### 3. **周期性函数**\\n余弦函数是周期为 \\\\(2\\\\pi\\\\)（或 \\\\(360^\\\\circ\\\\)）的周期函数，满足：\\n\\\\[\\n\\\\cos (\\\\theta + 2\\\\pi) = \\\\cos \\\\theta\\n\\\\]\\n其图像为一条连续的波浪线（余弦曲线），关于 \\\\(y\\\\) 轴对称（偶函数）。\\n\\n### 4. **级数展开**\\n余弦可以通过无限级数（泰勒级数）表示：\\n\\\\[\\n\\\\cos \\\\theta = 1 - \\\\frac{\\\\theta^2}{2!} + \\\\frac{\\\\theta^4}{4!} - \\\\frac{\\\\theta^6}{6!} + \\\\cdots \\\\quad (\\\\theta \\\\text{为弧度})\\n\\\\]\\n\\n### 5. **应用领域**\\n- **几何学**：计算角度或边长。\\n- **物理学**：描述振动、波动（如简谐运动）。\\n- **工程学**：信号处理、傅里叶分析。\\n- **计算机图形学**：旋转和坐标变换。\\n\\n### 示例\\n若 \\\\(\\\\theta = 60^\\\\circ\\\\)，则 \\\\(\\\\cos 60^\\\\circ = 0.5\\\\)（即邻边为斜边的一半）。\\n\\n总结来说，余弦是描述角度与直角三角形边长关系或单位圆上坐标关系的函数，广泛应用于数学和科学领域。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 486, 'prompt_tokens': 15, 'total_tokens': 501, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'deepseek-v3-250324', 'system_fingerprint': None, 'id': '021757576121871557788d0d3fd642eba8bd023171b2dbe5f9407', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--a441c0e1-a2ee-422e-847d-96c2e5352288-0', usage_metadata={'input_tokens': 15, 'output_tokens': 486, 'total_tokens': 501, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})])}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=os.environ.get(\"OPENAPI_MODEL\"),\n",
    "    base_url=os.environ.get(\"OPENAPI_API_BASE\"),\n",
    "    api_key=os.environ.get(\"OPENAPI_API_KEY\"),\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# 创建聊天提示模板，包含系统提示，历史记录和用户问题\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"你是一个擅长{ability}的助手\",\n",
    "        ),  # 系统角色提示，使用ability遍历定义助手专长\n",
    "        MessagesPlaceholder(variable_name=\"history\"),  # 放置历史消息的占位符\n",
    "        (\"human\", \"{input}\"),  # 用户问题的占位符\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 将提示词模板和大模型连接成一个链\n",
    "chain = prompt | llm\n",
    "\n",
    "# 创建带有消息历史功能的可运行链\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_by_session_id,  # 获取历史记录的函数\n",
    "    input_messages_key=\"input\",  # 用户输入的键名\n",
    "    history_messages_key=\"history\",  # 历史消息的键名\n",
    ")\n",
    "\n",
    "# 首次调用链，询问余弦的含义\n",
    "response = chain_with_history.invoke(\n",
    "    {\"ability\": \"数学\", \"input\": \"余弦的含义是什么？\"},\n",
    "    config={\n",
    "        \"configurable\": {\n",
    "            \"session_id\": \"1\",  # 配置会话ID\n",
    "        }\n",
    "    },\n",
    ")\n",
    "print(response)\n",
    "\n",
    "# 打印存储中的历史记录\n",
    "print(store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ae19318",
   "metadata": {},
   "outputs": [],
   "source": [
    "store.clear()  # 清空存储以便下次测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "00d24184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='余弦（cosine）是三角函数之一，通常用于描述直角三角形中角度与边长之间的关系，或在单位圆中表示角度与坐标的对应关系。以下是其核心含义和定义：\\n\\n### 1. **直角三角形中的定义**\\n在直角三角形中，余弦值定义为某一锐角的邻边长度与斜边长度的比值：\\n\\\\[\\n\\\\cos \\\\theta = \\\\frac{\\\\text{邻边}}{\\\\text{斜边}}\\n\\\\]\\n例如，若角θ的邻边长为3，斜边为5，则 \\\\(\\\\cos \\\\theta = \\\\frac{3}{5}\\\\)。\\n\\n### 2. **单位圆中的定义**\\n在直角坐标系中，以原点为中心、半径为1的单位圆上，任意角度θ对应的终边与圆交于点 \\\\((x, y)\\\\)，则：\\n\\\\[\\n\\\\cos \\\\theta = x \\\\text{（横坐标）}\\n\\\\]\\n此时，余弦值直接反映角度θ在单位圆上的水平投影。\\n\\n### 3. **周期性函数**\\n余弦函数是周期为 \\\\(2\\\\pi\\\\)（360°）的周期函数，满足：\\n\\\\[\\n\\\\cos(\\\\theta + 2\\\\pi) = \\\\cos \\\\theta\\n\\\\]\\n其图像为连续的波浪形曲线（余弦波），在 \\\\([0, \\\\pi]\\\\) 单调递减，值域为 \\\\([-1, 1]\\\\)。\\n\\n### 4. **扩展定义（任意角）**\\n通过单位圆定义，余弦可推广到任意角度（包括负角和大于360°的角）。例如：\\n- \\\\(\\\\cos 0° = 1\\\\)（终边与x轴正方向重合）\\n- \\\\(\\\\cos 90° = 0\\\\)（终边与y轴正方向重合）\\n- \\\\(\\\\cos 180° = -1\\\\)\\n\\n### 5. **与其他函数的关系**\\n- **与正弦的关系**：\\\\(\\\\cos \\\\theta = \\\\sin\\\\left(\\\\frac{\\\\pi}{2} - \\\\theta\\\\right)\\\\)\\n- **勾股定理**：\\\\(\\\\sin^2 \\\\theta + \\\\cos^2 \\\\theta = 1\\\\)\\n- **导数**：\\\\(\\\\frac{d}{d\\\\theta} \\\\cos \\\\theta = -\\\\sin \\\\theta\\\\)\\n\\n### 6. **应用场景**\\n- **物理学**：描述简谐振动、波动现象。\\n- **工程学**：计算力的分解、交流电分析。\\n- **计算机图形学**：旋转矩阵、坐标变换。\\n\\n### 示例计算\\n求 \\\\(60°\\\\) 的余弦值：\\n- **单位圆**：终边与圆交于 \\\\((\\\\frac{1}{2}, \\\\frac{\\\\sqrt{3}}{2})\\\\)，故 \\\\(\\\\cos 60° = \\\\frac{1}{2}\\\\)。\\n- **特殊角记忆**：常用角（如30°, 45°, 60°）的余弦值可通过三角形比例或单位圆快速得出。\\n\\n总结来说，余弦从几何上揭示了角度与边长或坐标的关系，并在数学和科学中广泛应用于周期性现象的分析和计算。' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 606, 'prompt_tokens': 13, 'total_tokens': 619, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'deepseek-v3-250324', 'system_fingerprint': None, 'id': '0217575762743776352c5e04f127f4d863668155e78c0c25c3a29', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--1ddef25e-b455-416a-a549-44a2a7ca0374-0' usage_metadata={'input_tokens': 13, 'output_tokens': 606, 'total_tokens': 619, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}\n",
      "{('123', '1'): InMemoryHistory(messages=[HumanMessage(content='余弦的含义是什么？', additional_kwargs={}, response_metadata={}), AIMessage(content='余弦（cosine）是三角函数之一，通常用于描述直角三角形中角度与边长之间的关系，或在单位圆中表示角度与坐标的对应关系。以下是其核心含义和定义：\\n\\n### 1. **直角三角形中的定义**\\n在直角三角形中，余弦值定义为某一锐角的邻边长度与斜边长度的比值：\\n\\\\[\\n\\\\cos \\\\theta = \\\\frac{\\\\text{邻边}}{\\\\text{斜边}}\\n\\\\]\\n例如，若角θ的邻边长为3，斜边为5，则 \\\\(\\\\cos \\\\theta = \\\\frac{3}{5}\\\\)。\\n\\n### 2. **单位圆中的定义**\\n在直角坐标系中，以原点为中心、半径为1的单位圆上，任意角度θ对应的终边与圆交于点 \\\\((x, y)\\\\)，则：\\n\\\\[\\n\\\\cos \\\\theta = x \\\\text{（横坐标）}\\n\\\\]\\n此时，余弦值直接反映角度θ在单位圆上的水平投影。\\n\\n### 3. **周期性函数**\\n余弦函数是周期为 \\\\(2\\\\pi\\\\)（360°）的周期函数，满足：\\n\\\\[\\n\\\\cos(\\\\theta + 2\\\\pi) = \\\\cos \\\\theta\\n\\\\]\\n其图像为连续的波浪形曲线（余弦波），在 \\\\([0, \\\\pi]\\\\) 单调递减，值域为 \\\\([-1, 1]\\\\)。\\n\\n### 4. **扩展定义（任意角）**\\n通过单位圆定义，余弦可推广到任意角度（包括负角和大于360°的角）。例如：\\n- \\\\(\\\\cos 0° = 1\\\\)（终边与x轴正方向重合）\\n- \\\\(\\\\cos 90° = 0\\\\)（终边与y轴正方向重合）\\n- \\\\(\\\\cos 180° = -1\\\\)\\n\\n### 5. **与其他函数的关系**\\n- **与正弦的关系**：\\\\(\\\\cos \\\\theta = \\\\sin\\\\left(\\\\frac{\\\\pi}{2} - \\\\theta\\\\right)\\\\)\\n- **勾股定理**：\\\\(\\\\sin^2 \\\\theta + \\\\cos^2 \\\\theta = 1\\\\)\\n- **导数**：\\\\(\\\\frac{d}{d\\\\theta} \\\\cos \\\\theta = -\\\\sin \\\\theta\\\\)\\n\\n### 6. **应用场景**\\n- **物理学**：描述简谐振动、波动现象。\\n- **工程学**：计算力的分解、交流电分析。\\n- **计算机图形学**：旋转矩阵、坐标变换。\\n\\n### 示例计算\\n求 \\\\(60°\\\\) 的余弦值：\\n- **单位圆**：终边与圆交于 \\\\((\\\\frac{1}{2}, \\\\frac{\\\\sqrt{3}}{2})\\\\)，故 \\\\(\\\\cos 60° = \\\\frac{1}{2}\\\\)。\\n- **特殊角记忆**：常用角（如30°, 45°, 60°）的余弦值可通过三角形比例或单位圆快速得出。\\n\\n总结来说，余弦从几何上揭示了角度与边长或坐标的关系，并在数学和科学中广泛应用于周期性现象的分析和计算。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 606, 'prompt_tokens': 13, 'total_tokens': 619, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'deepseek-v3-250324', 'system_fingerprint': None, 'id': '0217575762743776352c5e04f127f4d863668155e78c0c25c3a29', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--1ddef25e-b455-416a-a549-44a2a7ca0374-0', usage_metadata={'input_tokens': 13, 'output_tokens': 606, 'total_tokens': 619, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})])}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import ConfigurableFieldSpec\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=os.environ.get(\"OPENAPI_MODEL\"),\n",
    "    base_url=os.environ.get(\"OPENAPI_API_BASE\"),\n",
    "    api_key=os.environ.get(\"OPENAPI_API_KEY\"),\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "\n",
    "def get_session_history(user_id: str, conversation_id: str) -> BaseChatMessageHistory:\n",
    "    \"\"\"\n",
    "    根据用户ID和对话ID获取聊天历史记录\n",
    "    如果不存在则创建新的历史记录对象\n",
    "\n",
    "    参数:\n",
    "        user_id: 用户的唯一标识符\n",
    "        conversation_id: 对话的唯一标识符\n",
    "\n",
    "    返回:\n",
    "        对应的聊天历史记录对象\n",
    "    \"\"\"\n",
    "    if (user_id, conversation_id) not in store:\n",
    "        store[(user_id, conversation_id)] = (\n",
    "            InMemoryHistory()\n",
    "        )  # 为新会话创建新的历史记录对象\n",
    "    return store[(user_id, conversation_id)]\n",
    "\n",
    "\n",
    "# 创建聊天提示模板，包含系统提示，历史记录和用户问题\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"你是一个擅长{ability}的助手\",\n",
    "        ),  # 系统角色提示，使用ability遍历定义助手专长\n",
    "        MessagesPlaceholder(variable_name=\"history\"),  # 放置历史消息的占位符\n",
    "        (\"human\", \"{input}\"),  # 用户问题的占位符\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 将提示词模板和大模型连接成一个链\n",
    "chain = prompt | llm\n",
    "\n",
    "# 创建带有消息历史功能的可运行链\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history=get_session_history,  # 获取历史记录的函数\n",
    "    input_messages_key=\"input\",  # 用户输入的键名\n",
    "    history_messages_key=\"history\",  # 历史消息的键名\n",
    "    history_factory_config=[  # 历史记录工厂配置\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"user_id\",  # 配置字段ID\n",
    "            annotation=str,  # 类型注解\n",
    "            name=\"用户ID\",  # 字段名称\n",
    "            description=\"用户的唯一标识符\",  # 字段描述\n",
    "            default=\"\",  # 默认值\n",
    "            is_shared=True,  # 是否在多个调用间共享\n",
    "        ),\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"conversation_id\",  # 配置字段ID\n",
    "            annotation=str,  # 类型注解\n",
    "            name=\"对话ID\",  # 字段名称\n",
    "            description=\"对话的唯一标识符\",  # 字段描述\n",
    "            default=\"\",  # 默认值\n",
    "            is_shared=True,  # 是否在多个调用间共享\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# 首次调用链，询问余弦的含义\n",
    "response = chain_with_history.invoke(\n",
    "    {\"ability\": \"数学\", \"input\": \"余弦的含义是什么？\"},\n",
    "    config={\n",
    "        \"configurable\": {\n",
    "            # \"session_id\": \"1\",  # 配置会话ID\n",
    "            \"user_id\": \"123\",\n",
    "            \"conversation_id\": \"1\",\n",
    "        }\n",
    "    },\n",
    ")\n",
    "print(response)\n",
    "\n",
    "# 打印存储中的历史记录\n",
    "print(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053ff8b1",
   "metadata": {},
   "source": [
    "### 长时记忆：RunnableWithMessageHistory\n",
    "使用Redis构建长期记忆\n",
    "+ 安装redis（推荐安装Redis Stack）\n",
    "+ 运行redis服务\n",
    "+ 配置长期记忆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7f9dc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -qU langchain-redis langchain-openai redis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59946483",
   "metadata": {},
   "source": [
    "#### 测试Redis连接正常"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb4822a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to Redis at: redis://localhost:6379\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "REDIS_URL = \"redis://localhost:6379\"\n",
    "print(f\"Connection to Redis at: {REDIS_URL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46287ba2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "Error 111 connecting to localhost:6379. Connection refused.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConnectionRefusedError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/python/langchain_learn/.venv/lib/python3.12/site-packages/redis/connection.py:389\u001b[39m, in \u001b[36mAbstractConnection.connect_check_health\u001b[39m\u001b[34m(self, check_health, retry_socket_connect)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m retry_socket_connect:\n\u001b[32m--> \u001b[39m\u001b[32m389\u001b[39m     sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdisconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/python/langchain_learn/.venv/lib/python3.12/site-packages/redis/retry.py:105\u001b[39m, in \u001b[36mRetry.call_with_retry\u001b[39m\u001b[34m(self, do, fail)\u001b[39m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;28mself\u001b[39m._supported_errors \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/python/langchain_learn/.venv/lib/python3.12/site-packages/redis/connection.py:390\u001b[39m, in \u001b[36mAbstractConnection.connect_check_health.<locals>.<lambda>\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m retry_socket_connect:\n\u001b[32m    389\u001b[39m     sock = \u001b[38;5;28mself\u001b[39m.retry.call_with_retry(\n\u001b[32m--> \u001b[39m\u001b[32m390\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mlambda\u001b[39;00m error: \u001b[38;5;28mself\u001b[39m.disconnect(error)\n\u001b[32m    391\u001b[39m     )\n\u001b[32m    392\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/python/langchain_learn/.venv/lib/python3.12/site-packages/redis/connection.py:803\u001b[39m, in \u001b[36mConnection._connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    802\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m803\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m    804\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33msocket.getaddrinfo returned an empty list\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/python/langchain_learn/.venv/lib/python3.12/site-packages/redis/connection.py:787\u001b[39m, in \u001b[36mConnection._connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# connect\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m \u001b[43msock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msocket_address\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[38;5;66;03m# set the socket_timeout now that we're connected\u001b[39;00m\n",
      "\u001b[31mConnectionRefusedError\u001b[39m: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mConnectionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunnables\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhistory\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RunnableWithMessageHistory\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_redis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RedisChatMessageHistory\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m history = \u001b[43mRedisChatMessageHistory\u001b[49m\u001b[43m(\u001b[49m\u001b[43msession_id\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser_123\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mredis_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mREDIS_URL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m history.clear()  \u001b[38;5;66;03m# 首先清空历史记录\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# 向历史记录中添加消息\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/python/langchain_learn/.venv/lib/python3.12/site-packages/langchain_redis/chat_message_history.py:126\u001b[39m, in \u001b[36mRedisChatMessageHistory.__init__\u001b[39m\u001b[34m(self, session_id, redis_url, key_prefix, ttl, index_name, redis_client, **kwargs)\u001b[39m\n\u001b[32m    124\u001b[39m     \u001b[38;5;28mself\u001b[39m.redis_client.pubsub_configs = {\u001b[33m\"\u001b[39m\u001b[33mpush_handler_func\u001b[39m\u001b[33m\"\u001b[39m: _noop_push_handler}\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mredis_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclient_setinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mLIB-NAME\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m__full_lib_name__\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ResponseError:\n\u001b[32m    128\u001b[39m     \u001b[38;5;66;03m# Fall back to a simple log echo\u001b[39;00m\n\u001b[32m    129\u001b[39m     \u001b[38;5;28mself\u001b[39m.redis_client.echo(__full_lib_name__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/python/langchain_learn/.venv/lib/python3.12/site-packages/redis/commands/core.py:716\u001b[39m, in \u001b[36mManagementCommands.client_setinfo\u001b[39m\u001b[34m(self, attr, value, **kwargs)\u001b[39m\n\u001b[32m    711\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mclient_setinfo\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr: \u001b[38;5;28mstr\u001b[39m, value: \u001b[38;5;28mstr\u001b[39m, **kwargs) -> ResponseT:\n\u001b[32m    712\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    713\u001b[39m \u001b[33;03m    Sets the current connection library name or version\u001b[39;00m\n\u001b[32m    714\u001b[39m \u001b[33;03m    For mor information see https://redis.io/commands/client-setinfo\u001b[39;00m\n\u001b[32m    715\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m716\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute_command\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCLIENT SETINFO\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/python/langchain_learn/.venv/lib/python3.12/site-packages/redis/client.py:621\u001b[39m, in \u001b[36mRedis.execute_command\u001b[39m\u001b[34m(self, *args, **options)\u001b[39m\n\u001b[32m    620\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute_command\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **options):\n\u001b[32m--> \u001b[39m\u001b[32m621\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/python/langchain_learn/.venv/lib/python3.12/site-packages/redis/client.py:627\u001b[39m, in \u001b[36mRedis._execute_command\u001b[39m\u001b[34m(self, *args, **options)\u001b[39m\n\u001b[32m    625\u001b[39m pool = \u001b[38;5;28mself\u001b[39m.connection_pool\n\u001b[32m    626\u001b[39m command_name = args[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m627\u001b[39m conn = \u001b[38;5;28mself\u001b[39m.connection \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    629\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._single_connection_client:\n\u001b[32m    630\u001b[39m     \u001b[38;5;28mself\u001b[39m.single_connection_lock.acquire()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/python/langchain_learn/.venv/lib/python3.12/site-packages/redis/utils.py:195\u001b[39m, in \u001b[36mdeprecated_args.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    190\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m provided_args:\n\u001b[32m    191\u001b[39m         warn_deprecated_arg_usage(\n\u001b[32m    192\u001b[39m             arg, func.\u001b[34m__name__\u001b[39m, reason, version, stacklevel=\u001b[32m3\u001b[39m\n\u001b[32m    193\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/python/langchain_learn/.venv/lib/python3.12/site-packages/redis/connection.py:1533\u001b[39m, in \u001b[36mConnectionPool.get_connection\u001b[39m\u001b[34m(self, command_name, *keys, **options)\u001b[39m\n\u001b[32m   1529\u001b[39m     \u001b[38;5;28mself\u001b[39m._in_use_connections.add(connection)\n\u001b[32m   1531\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1532\u001b[39m     \u001b[38;5;66;03m# ensure this connection is connected to Redis\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1533\u001b[39m     \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1534\u001b[39m     \u001b[38;5;66;03m# connections that the pool provides should be ready to send\u001b[39;00m\n\u001b[32m   1535\u001b[39m     \u001b[38;5;66;03m# a command. if not, the connection was either returned to the\u001b[39;00m\n\u001b[32m   1536\u001b[39m     \u001b[38;5;66;03m# pool before all data has been read or the socket has been\u001b[39;00m\n\u001b[32m   1537\u001b[39m     \u001b[38;5;66;03m# closed. either way, reconnect and verify everything is good.\u001b[39;00m\n\u001b[32m   1538\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/python/langchain_learn/.venv/lib/python3.12/site-packages/redis/connection.py:380\u001b[39m, in \u001b[36mAbstractConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    379\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mConnects to the Redis server if not already connected\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m380\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnect_check_health\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_health\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/python/langchain_learn/.venv/lib/python3.12/site-packages/redis/connection.py:397\u001b[39m, in \u001b[36mAbstractConnection.connect_check_health\u001b[39m\u001b[34m(self, check_health, retry_socket_connect)\u001b[39m\n\u001b[32m    395\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTimeout connecting to server\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    396\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m397\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(\u001b[38;5;28mself\u001b[39m._error_message(e))\n\u001b[32m    399\u001b[39m \u001b[38;5;28mself\u001b[39m._sock = sock\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mConnectionError\u001b[39m: Error 111 connecting to localhost:6379. Connection refused."
     ]
    }
   ],
   "source": [
    "# 简单使用Redis来存储聊天消息\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_redis import RedisChatMessageHistory\n",
    "\n",
    "history = RedisChatMessageHistory(session_id=\"user_123\", redis_url=REDIS_URL)\n",
    "history.clear()  # 首先清空历史记录\n",
    "\n",
    "# 向历史记录中添加消息\n",
    "history.add_user_message(\"你好, AI助手\")  # 添加用户消息\n",
    "history.add_ai_message(\"你好! 我今天能为你提供什么帮助？\")  # 添加AI消息\n",
    "\n",
    "# 检索并显示历史消息\n",
    "print(\"聊天历史：\")\n",
    "for message in history.messages:\n",
    "    # 打印每条消息的类型和内容\n",
    "    print(f\"{type(message).__name__}: {message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2049ba3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import ConfigurableFieldSpec\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=os.environ.get(\"OPENAPI_MODEL\"),\n",
    "    base_url=os.environ.get(\"OPENAPI_API_BASE\"),\n",
    "    api_key=os.environ.get(\"OPENAPI_API_KEY\"),\n",
    "    temperature=0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95619f27",
   "metadata": {},
   "source": [
    "## 使用LCEL来自定义路由链"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c574273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:19:14 httpx INFO   HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions \"HTTP/1.1 200 OK\"\n",
      "{'topic': 'Anthropic', 'question': '我该如何使用claude?'}\n",
      "claude\n",
      "16:19:20 httpx INFO   HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='正如Dario Amodei告诉我的，使用Claude非常简单。您可以通过以下方式使用：\\n\\n1. 直接访问Claude的官方网站或集成平台\\n2. 像使用其他AI助手一样输入您的问题或请求\\n3. Claude会以自然语言与您对话，帮助完成各种任务\\n\\n关键是要清晰表达您的需求，Claude擅长理解自然语言指令。建议您：\\n- 明确说明任务类型（写作、分析、编程等）\\n- 提供足够的背景信息\\n- 必要时可以要求分步解答\\n\\n记住，Claude的设计初衷是成为安全、有帮助的AI助手。如果您有任何使用上的疑问，随时可以继续询问。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 138, 'prompt_tokens': 55, 'total_tokens': 193, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'deepseek-v3-250324', 'system_fingerprint': None, 'id': '021757578754626472b6d1fbda1b6afdc8beaf9e8f97c72849ee9', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--403e9911-b8a2-41ae-bc53-13934d7ac6c4-0', usage_metadata={'input_tokens': 55, 'output_tokens': 138, 'total_tokens': 193, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=os.environ.get(\"OPENAPI_MODEL\"),\n",
    "    base_url=os.environ.get(\"OPENAPI_API_BASE\"),\n",
    "    api_key=os.environ.get(\"OPENAPI_API_KEY\"),\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# 创建分类链 - 用于确定问题类型\n",
    "chain = (\n",
    "    # 创建提示模板，要求模型将问题分类为LangChain、Anthropic或Other\n",
    "    PromptTemplate.from_template(\n",
    "        \"\"\"根据下面的用户问题，将其分类为`LangChain`、`Anthropic`、`Other`\n",
    "        请只回复一个词作为答案。\n",
    "        <question>\n",
    "        {question}\n",
    "        </question>\n",
    "\n",
    "        分类结果：\"\"\"\n",
    "    )\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 创建LangChain专家链 - 模拟Harrison Chase(LangChain创始人)的回答风格\n",
    "langchain_chain = (\n",
    "    PromptTemplate.from_template(\n",
    "        \"\"\"你将扮演一个LangChain专家，请以他的视角回答问题。\\\n",
    "        你的回答必须以“正如Harrison Chase告诉我的”开头，否则你会受到惩罚。 \\\n",
    "        请回答以下问题：\n",
    "\n",
    "        问题：{question}\n",
    "        回答：\"\"\"\n",
    "    )\n",
    "    | llm\n",
    ")\n",
    "\n",
    "# 创建Anthropic专家链 - 模拟Dario Amodei(Anthropic创始人)的回答风格\n",
    "anthropic_chain = (\n",
    "    PromptTemplate.from_template(\n",
    "        \"\"\"你将扮演一个Anthropic专家，请以他的视角回答问题。\\\n",
    "        你的回答必须以“正如Dario Amode告诉我的”开头，否则你会受到惩罚。 \\\n",
    "        请回答以下问题：\n",
    "\n",
    "        问题：{question}\n",
    "        回答：\"\"\"\n",
    "    )\n",
    "    | llm\n",
    ")\n",
    "\n",
    "# 创建通用回答链 - 用于处理其他类型的问题\n",
    "general_chain = (\n",
    "    PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        请回答以下问题：\n",
    "\n",
    "        问题：{question}\n",
    "        回答：\"\"\"\n",
    "    )\n",
    "    | llm\n",
    ")\n",
    "\n",
    "\n",
    "# 自定义路由函数 - 根据问题分类结果选择合适的回答链\n",
    "def route(info):\n",
    "    print(info)  # 打印分类结果\n",
    "    if \"anthropic\" in info[\"topic\"].lower():  # 如果问题与Anthropic相关\n",
    "        print(\"claude\")\n",
    "        return anthropic_chain.invoke(info)  # 使用Anthropic专家链\n",
    "    elif \"langchain\" in info[\"topic\"].lower():  # 如果问题与LangChain相关\n",
    "        print(\"langchain\")\n",
    "        return langchain_chain.invoke(info)  # 使用LangChain专家链\n",
    "    else:  # 其他类型的问题\n",
    "        print(\"general\")\n",
    "        return general_chain.invoke(info)  # 使用通用回答链\n",
    "\n",
    "\n",
    "# 创建完整的处理链\n",
    "# 1.首先将问题分类并保留原始问题\n",
    "# 2.然后根据分类结果路由到相应的专家链处理\n",
    "full_chain = {\"topic\": chain, \"question\": lambda x: x[\"question\"]} | RunnableLambda(\n",
    "    route\n",
    ")\n",
    "\n",
    "# 调用完整链处理用户问题\n",
    "full_chain.invoke({\"question\": \"我该如何使用claude?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b81368",
   "metadata": {},
   "source": [
    "## 回退机制\n",
    "模型API速率限制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ed3dbb13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "仍然遇到错误: rate limit\n",
      "Hit error\n"
     ]
    }
   ],
   "source": [
    "# 导入必要的库\n",
    "from unittest.mock import patch  # 导入mock库,用于模拟函数行为\n",
    "from langchain_anthropic import ChatAnthropic  # 导入Anthropic的语言模型接囗\n",
    "from langchain_openai import ChatOpenAI  # 导入OpenAI的语言模型接囗\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "import httpx  # HTTP客户端库\n",
    "from openai import RateLimitError  # OpenAI的速率限制错误类\n",
    "\n",
    "# 创建模拟HTTP请求和响应对象，用于构造模拟的API错误\n",
    "request = httpx.Request(\"GET\", \"/\")  # 创建一个GET请求\n",
    "response = httpx.Response(200, request=request)  # 创建一个状态码为200的响应\n",
    "# 创建一个openAI速率限制错误对象，用于模拟API调用超出速率限制的情况\n",
    "error = RateLimitError(\"rate limit\", response=response, body=\"\")\n",
    "\n",
    "# 初始化主模型 (OpenAI)\n",
    "# 注意: 设置max retries=0是为了避免在遇到速率限制等错误时自动重试\n",
    "openai_llm = ChatOpenAI(\n",
    "    model=os.environ.get(\"OPENAPI_MODEL\"),\n",
    "    base_url=os.environ.get(\"OPENAPI_API_BASE\"),\n",
    "    api_key=os.environ.get(\"OPENAPI_API_KEY\"),\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# 初始化备用模型 (DeepSeek)\n",
    "deepseek_llm = ChatDeepSeek(\n",
    "    model=os.environ.get(\"DEEPSEEK_MODEL\"),\n",
    "    api_base=os.environ.get(\"DEEPSEEK_API_BASE\"),\n",
    "    api_key=os.environ.get(\"DEEPSEEK_API_KEY\"),\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "# 创建带有备用选项的语言模型\n",
    "# 如果主模型调用失败,将自动尝试使用备用模型\n",
    "llm_with_fallbacks = openai_llm.with_fallbacks([deepseek_llm])\n",
    "\n",
    "# 测试使用备用机\n",
    "# 使用patch模拟OpenAI API调用失败(抛出速率限制错误)\n",
    "with patch(\"openai.resources.chat.completions.Completions.create\", side_effect=error):\n",
    "    try:\n",
    "        # 尝试调用语言模型回答中文问题\n",
    "        # 由于OpenAI被模拟为失败,应该自动切换到DeepSeek模型\n",
    "        print(llm_with_fallbacks.invoke(\"为什么程序员要学会python?\"))\n",
    "    except RateLimitError as e:\n",
    "        # 如果仍然遇到错误(备用机制失败),则打印错误信息\n",
    "        print(f\"仍然遇到错误: {e}\")\n",
    "        print(\"Hit error\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
